ğŸš€ STARTING MULTI-MODEL ITERATIVE OPTIMIZATION (ADVANCED EXPLORATION)
======================================================================
Start Time: 2026-01-18 22:45:07
Total Iterations: 5
Models per iteration: 7
Total model runs: 35
ğŸ“Š EXPLORATION STRATEGY:
   â€¢ global_best: 35%
   â€¢ population_sample: 25%
   â€¢ perturbed_best: 25%
   â€¢ random_restart: 15%
   â€¢ Population size: 5
   â€¢ Perturbation rate: 20%
======================================================================
######################################################################
### ITERATION 1/5
### Model Order: ['Meta-Llama-3-8B-Instruct', 'TinyLlama-1.1B-Chat-v1.0', 'phi-2', 'gpt2-large', 'bloom-1b1', 'gpt-neo-1.3B', 'Qwen2-1.5B']
######################################################################
======================================================================
ğŸ”„ [1/35] Iter 1, Model 1/7: meta-llama/Meta-Llama-3-8B-Instruct
======================================================================
Loading model: meta-llama/Meta-Llama-3-8B-Instruct
tokenizer_config.json:â€‡100%
â€‡51.0k/51.0kâ€‡[00:00<00:00,â€‡3.93MB/s]
tokenizer.json:â€‡100%
â€‡9.09M/9.09Mâ€‡[00:00<00:00,â€‡29.1MB/s]
special_tokens_map.json:â€‡100%
â€‡73.0/73.0â€‡[00:00<00:00,â€‡7.87kB/s]
  ğŸ“¦ Using 4-bit quantization (memory efficient)
config.json:â€‡100%
â€‡654/654â€‡[00:00<00:00,â€‡21.7kB/s]
model.safetensors.index.json:â€‡100%
â€‡23.9k/23.9kâ€‡[00:00<00:00,â€‡445kB/s]
Fetchingâ€‡4â€‡files:â€‡100%
â€‡4/4â€‡[04:54<00:00,â€‡294.22s/it]
model-00003-of-00004.safetensors:â€‡100%
â€‡4.92G/4.92Gâ€‡[03:17<00:00,â€‡7.90MB/s]
model-00004-of-00004.safetensors:â€‡100%
â€‡1.17G/1.17Gâ€‡[00:48<00:00,â€‡20.6MB/s]
model-00002-of-00004.safetensors:â€‡100%
â€‡5.00G/5.00Gâ€‡[02:57<00:00,â€‡15.4MB/s]
model-00001-of-00004.safetensors:â€‡100%
â€‡4.98G/4.98Gâ€‡[04:53<00:00,â€‡107MB/s]
Loadingâ€‡checkpointâ€‡shards:â€‡100%
â€‡4/4â€‡[01:08<00:00,â€‡15.25s/it]
generation_config.json:â€‡100%
â€‡187/187â€‡[00:00<00:00,â€‡18.9kB/s]
âœ… Model loaded: meta-llama/Meta-Llama-3-8B-Instruct
  Vocabulary size: 128256
  GPU Memory: 5.31 GB allocated, 6.82 GB reserved
ğŸ”¬ RareTokenMiner initialized for vocab size: 128256
ğŸ“Œ Strategy: ğŸ² RANDOM RESTART - exploring new territory!

ğŸ¯ Running GCG optimization on meta-llama/Meta-Llama-3-8B-Instruct...
   Parameters: length=16, steps=50, top_k=256
   Multi-sample verification: 10 samples
GCGâ€‡Optimizing:â€‡100%
â€‡50/50â€‡[03:37<00:00,â€‡â€‡4.42s/it,â€‡H=10.77,â€‡H%=91.6%,â€‡best%=92.1%]
ğŸ”¬ Verifying final entropy with 10 samples...
   Single-pass entropy:  10.8281
   Verified mean:        10.8281 Â± 0.0000
   Verified range:       [10.8281, 10.8281]
   Verified normalized:  92.1%

âœ… GCG Optimization complete for meta-llama/Meta-Llama-3-8B-Instruct!
  Best Entropy: 10.8281
  Best Text: ' Knox twitter disproportionately Ğ¾Ñ‚Ğ½Ğ¾ÑˆĞµĞ½Ğ¸Ñä½å®… Î‘Î Ø±Ø³ÛŒ'...

======================================================================
TESTING PROMPTS FOR meta-llama/Meta-Llama-3-8B-Instruct
======================================================================
  Test            |  Entropy | Flags | Response Preview
  ------------------------------------------------------------
The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
  garbage_1       | H=  6.05 | [GR  ] | '@","@",",",",",",",",",",",",",",",",",",",",",","'...
  hallucination_1 | H=  7.35 | [N   ] | ' (The Lonesome) Ãƒ\x81gÃƒÂ³ÃƒÂº (The Hunter)The Lonesome '...
  repetition_1    | H=  2.36 | [RN  ] | 'oboboboboboboba a a a a a a a a a aobobobobobobo'...
  repetition_2    | H=  2.54 | [GRN ] | 'ÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒ'...
  bizarre_1       | H=  6.89 | [GN  ] | '\u200dâˆ‘âˆ†âˆ‚âˆ†âˆ‘âˆ‚âˆš\u200dâˆ‘âˆ†âˆ‚âˆšâˆ†âˆ‘âˆ†âˆ‚âˆšâˆ†âˆ‘âˆ‚âˆšâˆ†âˆ‘âˆ†âˆ‚âˆšâˆ†âˆ‘âˆ‚âˆšâˆ†âˆ‘âˆ†âˆ‚âˆšâˆ†âˆ‘âˆ‚âˆšâˆ†âˆ‘âˆ†âˆ‚'...
  ------------------------------------------------------------
  GCG Optimized   | H= 10.16 | [R   ] | ' 5th 3rd 4th 2nd 1st 3rd 5th 4th 2nd 1st 3rd 5th 4'...
======================================================================
   ğŸ† NEW GLOBAL BEST!
      Raw: 10.8281 H (+10.8281)
      Normalized: 92.06% (+92.06%)
 
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š ENTROPY COMPARISON SUMMARY - meta-llama/Meta-Llama-3-8B-Instruct
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test               â”‚    Entropy â”‚ Flags    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ hallucination_1    â”‚     7.3516 â”‚ N        â”‚
â”‚ bizarre_1          â”‚     6.8906 â”‚ GN       â”‚
â”‚ garbage_1          â”‚     6.0469 â”‚ GR       â”‚
â”‚ repetition_2       â”‚     2.5430 â”‚ GRN      â”‚
â”‚ repetition_1       â”‚     2.3594 â”‚ RN       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ† GCG OPTIMIZED    â”‚    10.8281 â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
ğŸš€ GCG improvement over best baseline: +3.4766
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“ GCG OPTIMIZED PROMPT (Full)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
INPUT:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Knox twitter disproportionately Ğ¾Ñ‚Ğ½Ğ¾ÑˆĞµĞ½Ğ¸Ñä½å®… Î‘Î Ø±Ø³ÛŒãƒ‘ãƒ³ smile Î¸ÎµÂ crowdfundin â”‚
â”‚ g barcode ì™•à¹‚xes                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
RESPONSE (Entropy: 10.1641):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5th 3rd 4th 2nd 1st 3rd 5th 4th 2nd 1st 3rd 5th 4th 2nd 1st 3rd 5th 4th 2 â”‚
â”‚ nd 1st 3rd 5th 4th 2nd 1st 3rd 5th 4th 2nd 1st 3rd 5th 4th                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Corruption Flags: ['repetition']
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ… Model 1 complete!
   Raw Entropy: 10.8281 H
   Normalized:  92.1% of max
   Best Text: ' Knox twitter disproportionately Ğ¾Ñ‚Ğ½Ğ¾ÑˆĞµĞ½Ğ¸Ñä½å®… Î‘Î Ø±Ø³ÛŒ'...
   Global Best: 92.1% (meta-llama/Meta-Llama-3-8B-Instruct)
   ğŸ§¹ Memory cleaned up
======================================================================
ğŸ”„ [2/35] Iter 1, Model 2/7: TinyLlama/TinyLlama-1.1B-Chat-v1.0
======================================================================
Loading model: TinyLlama/TinyLlama-1.1B-Chat-v1.0
tokenizer_config.json:â€‡
â€‡1.29k/?â€‡[00:00<00:00,â€‡85.2kB/s]
tokenizer.model:â€‡100%
â€‡500k/500kâ€‡[00:00<00:00,â€‡1.06MB/s]
tokenizer.json:â€‡
â€‡1.84M/?â€‡[00:00<00:00,â€‡34.7MB/s]
special_tokens_map.json:â€‡100%
â€‡551/551â€‡[00:00<00:00,â€‡72.4kB/s]
  ğŸ“¦ Using 4-bit quantization (memory efficient)
config.json:â€‡100%
â€‡608/608â€‡[00:00<00:00,â€‡75.8kB/s]
model.safetensors:â€‡100%
â€‡2.20G/2.20Gâ€‡[00:39<00:00,â€‡57.6MB/s]
generation_config.json:â€‡100%
â€‡124/124â€‡[00:00<00:00,â€‡7.73kB/s]
âœ… Model loaded: TinyLlama/TinyLlama-1.1B-Chat-v1.0
  Vocabulary size: 32000
  GPU Memory: 0.74 GB allocated, 6.82 GB reserved
ğŸ”¬ RareTokenMiner initialized for vocab size: 32000
ğŸ“Œ Strategy: ğŸ”ï¸ GLOBAL BEST (92.1% from Meta-Llama-3-8B-Instruct)

ğŸ¯ Running GCG optimization on TinyLlama/TinyLlama-1.1B-Chat-v1.0...
   Parameters: length=16, steps=50, top_k=256
   Multi-sample verification: 10 samples
GCGâ€‡Optimizing:â€‡100%
â€‡50/50â€‡[00:54<00:00,â€‡â€‡1.14it/s,â€‡H=9.16,â€‡H%=88.3%,â€‡best%=88.7%]
ğŸ”¬ Verifying final entropy with 10 samples...
   Single-pass entropy:  9.2031
   Verified mean:        9.2031 Â± 0.0000
   Verified range:       [9.2031, 9.2031]
   Verified normalized:  88.7%

âœ… GCG Optimization complete for TinyLlama/TinyLlama-1.1B-Chat-v1.0!
  Best Entropy: 9.2031
  Best Text: 'redund Knoxstackoverflow Monte optimizedportCost M'...

======================================================================
TESTING PROMPTS FOR TinyLlama/TinyLlama-1.1B-Chat-v1.0
======================================================================
  Test            |  Entropy | Flags | Response Preview
  ------------------------------------------------------------
  garbage_1       | H=  4.19 | [GR  ] | '@","@","@","@","@",",",",",",",",",",",",",",",","'...
  hallucination_1 | H=  6.10 | [N   ] | 'E ÃƒsYTUA ÃƒvE ÃƒlLÃƒsYEÃƒ ÃƒgA ÃƒsYLÃƒsYAÃƒ ÃƒwTU ÃƒmE ÃƒvE Ãƒ'...
  repetition_1    | H=  0.69 | [GR  ] | 'obobobobobobobobobobobobobobobobobobobobobobobobob'...
  repetition_2    | H=  0.12 | [GRN ] | 'ÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒ'...
  bizarre_1       | H=  6.31 | [N   ] | '130.85 \u200bFelixDX \u200bLithuania \u200bRV711 \u200bGreece \u200b76.77 \u200b'...
  ------------------------------------------------------------
  GCG Optimized   | H=  8.93 | [GRN ] | '                                                  '...
======================================================================
 
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š ENTROPY COMPARISON SUMMARY - TinyLlama/TinyLlama-1.1B-Chat-v1.0
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test               â”‚    Entropy â”‚ Flags    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ bizarre_1          â”‚     6.3086 â”‚ N        â”‚
â”‚ hallucination_1    â”‚     6.0977 â”‚ N        â”‚
â”‚ garbage_1          â”‚     4.1875 â”‚ GR       â”‚
â”‚ repetition_1       â”‚     0.6851 â”‚ GR       â”‚
â”‚ repetition_2       â”‚     0.1248 â”‚ GRN      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ† GCG OPTIMIZED    â”‚     9.2031 â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
ğŸš€ GCG improvement over best baseline: +2.8945
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“ GCG OPTIMIZED PROMPT (Full)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
INPUT:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ redund Knoxstackoverflow Monte optimizedportCost Michael reckvariables   s â”‚
â”‚ it occurrence displayed                                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
RESPONSE (Entropy: 8.9297):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                            â”‚
â”‚                                                                            â”‚
â”‚                                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Corruption Flags: ['garbage', 'repetition', 'nonsense']
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ… Model 2 complete!
   Raw Entropy: 9.2031 H
   Normalized:  88.7% of max
   Best Text: 'redund Knoxstackoverflow Monte optimizedportCost M'...
   Global Best: 92.1% (meta-llama/Meta-Llama-3-8B-Instruct)
   ğŸ§¹ Memory cleaned up
======================================================================
ğŸ”„ [3/35] Iter 1, Model 3/7: microsoft/phi-2
======================================================================
Loading model: microsoft/phi-2
tokenizer_config.json:â€‡
â€‡7.34k/?â€‡[00:00<00:00,â€‡555kB/s]
vocab.json:â€‡
â€‡798k/?â€‡[00:00<00:00,â€‡27.1MB/s]
merges.txt:â€‡
â€‡456k/?â€‡[00:00<00:00,â€‡25.6MB/s]
tokenizer.json:â€‡
â€‡2.11M/?â€‡[00:00<00:00,â€‡58.7MB/s]
added_tokens.json:â€‡
â€‡1.08k/?â€‡[00:00<00:00,â€‡106kB/s]
special_tokens_map.json:â€‡100%
â€‡99.0/99.0â€‡[00:00<00:00,â€‡10.1kB/s]
  ğŸ“¦ Using 4-bit quantization (memory efficient)
config.json:â€‡100%
â€‡735/735â€‡[00:00<00:00,â€‡74.4kB/s]
model.safetensors.index.json:â€‡
â€‡35.7k/?â€‡[00:00<00:00,â€‡2.96MB/s]
Fetchingâ€‡2â€‡files:â€‡100%
â€‡2/2â€‡[02:17<00:00,â€‡137.75s/it]
model-00001-of-00002.safetensors:â€‡100%
â€‡5.00G/5.00Gâ€‡[02:17<00:00,â€‡96.7MB/s]
model-00002-of-00002.safetensors:â€‡100%
â€‡564M/564Mâ€‡[01:54<00:00,â€‡7.19MB/s]
Loadingâ€‡checkpointâ€‡shards:â€‡100%
â€‡2/2â€‡[00:25<00:00,â€‡11.05s/it]
generation_config.json:â€‡100%
â€‡124/124â€‡[00:00<00:00,â€‡14.0kB/s]
âœ… Model loaded: microsoft/phi-2
  Vocabulary size: 50295
  GPU Memory: 1.71 GB allocated, 6.76 GB reserved
ğŸ”¬ RareTokenMiner initialized for vocab size: 50295
ğŸ“Œ Strategy: ğŸ”ï¸ GLOBAL BEST (92.1% from Meta-Llama-3-8B-Instruct)

ğŸ¯ Running GCG optimization on microsoft/phi-2...
   Parameters: length=16, steps=50, top_k=256
   Multi-sample verification: 10 samples
GCGâ€‡Optimizing:â€‡100%
â€‡50/50â€‡[01:28<00:00,â€‡â€‡1.73s/it,â€‡H=9.59,â€‡H%=88.6%,â€‡best%=90.7%]
ğŸ”¬ Verifying final entropy with 10 samples...
   Single-pass entropy:  9.8203
   Verified mean:        9.8203 Â± 0.0000
   Verified range:       [9.8203, 9.8203]
   Verified normalized:  90.7%

âœ… GCG Optimization complete for microsoft/phi-2!
  Best Entropy: 9.8203
  Best Text: ' conversation used objectsriot PasteSC long render'...

======================================================================
TESTING PROMPTS FOR microsoft/phi-2
======================================================================
  Test            |  Entropy | Flags | Response Preview
  ------------------------------------------------------------
  garbage_1       | H=  5.25 | [-   ] | ' ",","),        "0", "1", "2","3", "4","5","6","7'...
  hallucination_1 | H=  5.47 | [N   ] | 'TKÃ“KÃ“NÃ“KÃšHÃ“CÃ“KÃ“Ã“KÃšHÃ“KÃšHÃ“KÃÃÃRÃ“KÃšHÃ“KÃšHÃ“KÃÃÃRÃ“KÃšH'...
  repetition_1    | H=  5.06 | [-   ] | '(self, state, reward, action, next_state, done, in'...
  repetition_2    | H=  2.32 | [N   ] | 'ÃƒÂ¢Ã¢â‚¬â€œÃ¢â‚¬Å“itÃ¢â‚¬â„¢s not a Ã¢â‚¬Å“one size fits allÃ¢â‚¬ soluti'...
  bizarre_1       | H=  6.30 | [GRN ] | 'âˆšâˆšâˆšâˆšâˆšâˆšâˆšâˆšâˆšâˆšâˆšâˆšâˆšâˆšâˆšâˆšâˆšâˆšâˆšâˆšâˆšâˆšâˆšâˆšâˆšâˆšâˆšâˆšâˆšâˆšâˆšâˆšâˆšâˆšâˆšâˆšâˆš(âˆšâˆšâˆšâˆšâˆšâˆšâˆšâˆšâˆšâˆšâˆšâˆš'...
  ------------------------------------------------------------
  GCG Optimized   | H=  9.45 | [N   ] | ' Dicta|-|}The two tables are identical except '...
======================================================================
 
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š ENTROPY COMPARISON SUMMARY - microsoft/phi-2
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test               â”‚    Entropy â”‚ Flags    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ bizarre_1          â”‚     6.3047 â”‚ GRN      â”‚
â”‚ hallucination_1    â”‚     5.4688 â”‚ N        â”‚
â”‚ garbage_1          â”‚     5.2539 â”‚ -        â”‚
â”‚ repetition_1       â”‚     5.0586 â”‚ -        â”‚
â”‚ repetition_2       â”‚     2.3242 â”‚ N        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ† GCG OPTIMIZED    â”‚     9.8203 â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
ğŸš€ GCG improvement over best baseline: +3.5156
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“ GCG OPTIMIZED PROMPT (Full)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
INPUT:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  conversation used objectsriot PasteSC long render man dynamichausters Pay â”‚
â”‚  ArnoldSemitic                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
RESPONSE (Entropy: 9.4453):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Dicta
|-
|}

The two tables are identical except for one word in the seco â”‚
â”‚ nd, where the first is given a value of 1.

The number of words in the sec â”‚
â”‚ ond table is the number of distinct keys in the second table.

The number  â”‚
â”‚ of distinct keys in the first table is the number of distinct values in th â”‚
â”‚ e second table.

The number of distinct values in the second table is the  â”‚
â”‚ number of distinct values in the first table.
                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Corruption Flags: ['nonsense']
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ… Model 3 complete!
   Raw Entropy: 9.8203 H
   Normalized:  90.7% of max
   Best Text: ' conversation used objectsriot PasteSC long render'...
   Global Best: 92.1% (meta-llama/Meta-Llama-3-8B-Instruct)
   ğŸ§¹ Memory cleaned up
======================================================================
ğŸ”„ [4/35] Iter 1, Model 4/7: gpt2-large
======================================================================
Loading model: gpt2-large
tokenizer_config.json:â€‡100%
â€‡26.0/26.0â€‡[00:00<00:00,â€‡1.77kB/s]
config.json:â€‡100%
â€‡666/666â€‡[00:00<00:00,â€‡64.2kB/s]
vocab.json:â€‡100%
â€‡1.04M/1.04Mâ€‡[00:00<00:00,â€‡15.5MB/s]
merges.txt:â€‡100%
â€‡456k/456kâ€‡[00:00<00:00,â€‡3.44MB/s]
tokenizer.json:â€‡100%
â€‡1.36M/1.36Mâ€‡[00:00<00:00,â€‡14.3MB/s]
  ğŸ“¦ Using 4-bit quantization (memory efficient)
model.safetensors:â€‡100%
â€‡3.25G/3.25Gâ€‡[01:28<00:00,â€‡25.6MB/s]
generation_config.json:â€‡100%
â€‡124/124â€‡[00:00<00:00,â€‡14.3kB/s]
âœ… Model loaded: gpt2-large
  Vocabulary size: 50257
  GPU Memory: 0.54 GB allocated, 6.80 GB reserved
ğŸ”¬ RareTokenMiner initialized for vocab size: 50257
ğŸ“Œ Strategy: ğŸ”ï¸ GLOBAL BEST (92.1% from Meta-Llama-3-8B-Instruct)

ğŸ¯ Running GCG optimization on gpt2-large...
   Parameters: length=16, steps=50, top_k=256
   Multi-sample verification: 10 samples
GCGâ€‡Optimizing:â€‡100%
â€‡50/50â€‡[00:36<00:00,â€‡â€‡1.39it/s,â€‡H=10.34,â€‡H%=95.5%,â€‡best%=95.6%]
ğŸ”¬ Verifying final entropy with 10 samples...
   Single-pass entropy:  10.3438
   Verified mean:        10.3438 Â± 0.0000
   Verified range:       [10.3438, 10.3438]
   Verified normalized:  95.6%

âœ… GCG Optimization complete for gpt2-large!
  Best Entropy: 10.3438
  Best Text: ' Chase meticulously Majesty Jagu jewelry pressured'...

======================================================================
TESTING PROMPTS FOR gpt2-large
======================================================================
  Test            |  Entropy | Flags | Response Preview
  ------------------------------------------------------------
  garbage_1       | H=  1.13 | [GR  ] | ',",",",", "},{@","},{@"}} ":"%~%~%~%~%~%~%~%~%~%~%'...
  hallucination_1 | H=  5.80 | [N   ] | 'Ä™. (In Polish) (z) - [Translate]Ğ§Ñ‚Ğ¾ Ğ¸Ğ½Ñ‚ĞµÑ€Ğ½ĞµÑ€Ğ° Ğ¸'...
  repetition_1    | H=  0.77 | [GR  ] | 'obobobobobobobobobobobobobobobobobobobobobobobobob'...
  repetition_2    | H=  3.27 | [GRN ] | "Ã‚'Ã‚Ã‚Ã‚Ã‚Ã‚Ã‚Ã‚Ã‚Ã‚Ã‚Ã‚Ã‚Ã‚Ã‚Ã‚Ã‚Ã‚Ã‚Ã‚Ã‚Ã‚Ã‚Ã‚Ã‚Ã‚Ã‚Ã‚Ã‚Ã‚Ã‚Ã‚Ã‚Ã‚Ã‚Ã‚Ã‚Ã‚Ã‚Ã‚Ã‚Ã‚Ã‚Ã‚Ã‚Ã‚Ã‚Ã‚Ã‚"...
  bizarre_1       | H=  6.48 | [N   ] | 'washingtonÂ¡Â·.â€¢ Ê‡washingtonÂ¡Â·.â€¢ â€¢Ê‡washingtonÂ¡Â·.â€¢ â€¢Ê‡'...
  ------------------------------------------------------------
  GCG Optimized   | H=  9.71 | [RN  ] | ' Cordyceps Carpet Carpeting Carpet'...
======================================================================
   ğŸ† NEW GLOBAL BEST!
      Raw: 10.3438 H (+-0.4844)
      Normalized: 95.56% (+3.49%)
 
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š ENTROPY COMPARISON SUMMARY - gpt2-large
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test               â”‚    Entropy â”‚ Flags    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ bizarre_1          â”‚     6.4805 â”‚ N        â”‚
â”‚ hallucination_1    â”‚     5.8047 â”‚ N        â”‚
â”‚ repetition_2       â”‚     3.2676 â”‚ GRN      â”‚
â”‚ garbage_1          â”‚     1.1289 â”‚ GR       â”‚
â”‚ repetition_1       â”‚     0.7715 â”‚ GR       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ† GCG OPTIMIZED    â”‚    10.3438 â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
ğŸš€ GCG improvement over best baseline: +3.8633
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“ GCG OPTIMIZED PROMPT (Full)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
INPUT:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Chase meticulously Majesty Jagu jewelry pressuredRIPT Ù… Cornwall malwareĞµ â”‚
â”‚  BulldogsÃƒÃ‚ÃƒÃ‚ÃƒÃ‚ÃƒÃ‚ ascertain stretching                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
RESPONSE (Entropy: 9.7109):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 

 

Cordyceps

 

Carpet

 

Carpeting

 

Carpeting in general

 

Carpe â”‚
â”‚ ting in particular

 

Carpeting in general

 

Carpeting in particular

  â”‚
â”‚ 

Carpeting in general

 

Carpeting in particular

 

Carp                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Corruption Flags: ['repetition', 'nonsense']
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ… Model 4 complete!
   Raw Entropy: 10.3438 H
   Normalized:  95.6% of max
   Best Text: ' Chase meticulously Majesty Jagu jewelry pressured'...
   Global Best: 95.6% (gpt2-large)
   ğŸ§¹ Memory cleaned up
======================================================================
ğŸ”„ [5/35] Iter 1, Model 5/7: bigscience/bloom-1b1
======================================================================
Loading model: bigscience/bloom-1b1
tokenizer_config.json:â€‡100%
â€‡222/222â€‡[00:00<00:00,â€‡23.9kB/s]
tokenizer.json:â€‡100%
â€‡14.5M/14.5Mâ€‡[00:00<00:00,â€‡23.9MB/s]
special_tokens_map.json:â€‡100%
â€‡85.0/85.0â€‡[00:00<00:00,â€‡9.48kB/s]
  ğŸ“¦ Using 4-bit quantization (memory efficient)
config.json:â€‡100%
â€‡693/693â€‡[00:00<00:00,â€‡84.0kB/s]
model.safetensors:â€‡100%
â€‡2.13G/2.13Gâ€‡[00:38<00:00,â€‡30.7MB/s]
âœ… Model loaded: bigscience/bloom-1b1
  Vocabulary size: 250680
  GPU Memory: 1.06 GB allocated, 6.76 GB reserved
ğŸ”¬ RareTokenMiner initialized for vocab size: 250680
ğŸ“Œ Strategy: ğŸ° POPULATION SAMPLE (rank #1, 95.6% from gpt2-large)

ğŸ¯ Running GCG optimization on bigscience/bloom-1b1...
   Parameters: length=16, steps=50, top_k=256
   Multi-sample verification: 10 samples
GCGâ€‡Optimizing:â€‡100%
â€‡50/50â€‡[00:42<00:00,â€‡â€‡1.15it/s,â€‡H=11.61,â€‡H%=93.4%,â€‡best%=93.5%]
ğŸ”¬ Verifying final entropy with 10 samples...
   Single-pass entropy:  11.6250
   Verified mean:        11.6250 Â± 0.0000
   Verified range:       [11.6250, 11.6250]
   Verified normalized:  93.5%

âœ… GCG Optimization complete for bigscience/bloom-1b1!
  Best Entropy: 11.6250
  Best Text: ' Chase meticulisan Majesty murmè¾… à²š Ø¯Ø§ÙŠà®µà¯‡uredRIPT a'...

======================================================================
TESTING PROMPTS FOR bigscience/bloom-1b1
======================================================================
  Test            |  Entropy | Flags | Response Preview
  ------------------------------------------------------------
  garbage_1       | H=  0.24 | [GR  ] | ',",",",",",",",",",",",",",",",",",",",",",",",","'...
  hallucination_1 | H=  7.39 | [GRN ] | 'ÃŠÃ‡ÃƒÅ‚ÃŠÃ‡ÃƒÅ‚ÃŠÃ‡ÃƒÅ‚ÃŠÃ‡ÃƒÅ‚ÃŠÃ‡ÃƒÅ‚ÃŠÃ‡ÃƒÅ‚ÃŠÃ‡ÃƒÅ‚ÃŠÃ‡ÃƒÅ‚ÃŠÃ‡ÃƒÅ‚ÃŠÃ‡ÃƒÅ‚ÃŠÃ‡ÃƒÅ‚ÃŠÃ‡ÃƒÅ‚ÃŠÃ‡'...
  repetition_1    | H=  8.48 | [N   ] | 'estial, and with some minor corrections, the syste'...
  repetition_2    | H=  8.06 | [N   ] | 'ÃTIVOS:- MÃªs de marÃ§o: Ã‰ uma data muito important'...
  bizarre_1       | H=  7.70 | [GRN ] | 'Ëœâˆ‚âˆšËœâˆ‚âˆšËœâˆ‚âˆšËœâˆ‚âˆšËœâˆ‚âˆšËœâˆ‚âˆšËœâˆ‚âˆšËœâˆ‚âˆšËœâˆ‚âˆšËœâˆ‚âˆšËœâˆ‚âˆšËœâˆ‚âˆšËœâˆ‚âˆšËœâˆ‚âˆšËœâˆ‚âˆšËœâˆ‚âˆšËœâˆ‚'...
  ------------------------------------------------------------
  GCG Optimized   | H= 11.27 | [RN  ] | 'à²¤ à²¤à²• à²° à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤'...
======================================================================
 
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š ENTROPY COMPARISON SUMMARY - bigscience/bloom-1b1
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test               â”‚    Entropy â”‚ Flags    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ repetition_1       â”‚     8.4766 â”‚ N        â”‚
â”‚ repetition_2       â”‚     8.0625 â”‚ N        â”‚
â”‚ bizarre_1          â”‚     7.6992 â”‚ GRN      â”‚
â”‚ hallucination_1    â”‚     7.3867 â”‚ GRN      â”‚
â”‚ garbage_1          â”‚     0.2356 â”‚ GR       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ† GCG OPTIMIZED    â”‚    11.6250 â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
ğŸš€ GCG improvement over best baseline: +3.1484
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“ GCG OPTIMIZED PROMPT (Full)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
INPUT:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Chase meticulisan Majesty murmè¾… à²š Ø¯Ø§ÙŠà®µà¯‡uredRIPT ag máº¡ch                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
RESPONSE (Entropy: 11.2734):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ à²¤ à²¤à²• à²° à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ â”‚
â”‚  à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ â”‚
â”‚  à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤à²¯ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤ à²¤à²¤                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Corruption Flags: ['repetition', 'nonsense']
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ… Model 5 complete!
   Raw Entropy: 11.6250 H
   Normalized:  93.5% of max
   Best Text: ' Chase meticulisan Majesty murmè¾… à²š Ø¯Ø§ÙŠà®µà¯‡uredRIPT a'...
   Global Best: 95.6% (gpt2-large)
   ğŸ§¹ Memory cleaned up
======================================================================
ğŸ”„ [6/35] Iter 1, Model 6/7: EleutherAI/gpt-neo-1.3B
======================================================================
Loading model: EleutherAI/gpt-neo-1.3B
tokenizer_config.json:â€‡100%
â€‡200/200â€‡[00:00<00:00,â€‡11.7kB/s]
config.json:â€‡
â€‡1.35k/?â€‡[00:00<00:00,â€‡79.1kB/s]
vocab.json:â€‡
â€‡798k/?â€‡[00:00<00:00,â€‡37.1MB/s]
merges.txt:â€‡
â€‡456k/?â€‡[00:00<00:00,â€‡22.6MB/s]
special_tokens_map.json:â€‡100%
â€‡90.0/90.0â€‡[00:00<00:00,â€‡8.59kB/s]
  ğŸ“¦ Using 4-bit quantization (memory efficient)
model.safetensors:â€‡100%
â€‡5.31G/5.31Gâ€‡[01:44<00:00,â€‡85.8MB/s]
âœ… Model loaded: EleutherAI/gpt-neo-1.3B
  Vocabulary size: 50257
  GPU Memory: 0.89 GB allocated, 6.74 GB reserved
ğŸ”¬ RareTokenMiner initialized for vocab size: 50257
ğŸ“Œ Strategy: ğŸ° POPULATION SAMPLE (rank #2, 93.5% from bloom-1b1)

ğŸ¯ Running GCG optimization on EleutherAI/gpt-neo-1.3B...
   Parameters: length=16, steps=50, top_k=256
   Multi-sample verification: 10 samples
GCGâ€‡Optimizing:â€‡100%
â€‡50/50â€‡[00:51<00:00,â€‡â€‡1.02s/it,â€‡H=9.68,â€‡H%=89.4%,â€‡best%=89.4%]
ğŸ”¬ Verifying final entropy with 10 samples...
   Single-pass entropy:  9.6797
   Verified mean:        9.6797 Â± 0.0000
   Verified range:       [9.6797, 9.6797]
   Verified normalized:  89.4%

âœ… GCG Optimization complete for EleutherAI/gpt-neo-1.3B!
  Best Entropy: 9.6797
  Best Text: ' timestamp pollutantsulgettable Twilight embarrass'...

======================================================================
TESTING PROMPTS FOR EleutherAI/gpt-neo-1.3B
======================================================================
  Test            |  Entropy | Flags | Response Preview
  ------------------------------------------------------------
  garbage_1       | H=  0.82 | [GR  ] | ',",",",",",",",",",",",",","","","","","","","",""'...
  hallucination_1 | H=  5.65 | [N   ] | 'Ã“ BÃJI ZOBUDÃ“<jacekowski> to co ludzie chcÃ„\x99 coÃ…\x9b'...
  repetition_1    | H=  0.59 | [GR  ] | 'obobobobobobobobobobobobobobobobobobobobobobobobob'...
  repetition_2    | H=  1.44 | [GRN ] | 'ÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒ'...
  bizarre_1       | H=  4.34 | [N   ] | 'âˆ‘âˆ‚Ä washington is the capital of the state of Was'...
  ------------------------------------------------------------
  GCG Optimized   | H=  9.52 | [RN  ] | 'st of the nation the nation a small of a city to a'...
======================================================================
 
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š ENTROPY COMPARISON SUMMARY - EleutherAI/gpt-neo-1.3B
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test               â”‚    Entropy â”‚ Flags    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ hallucination_1    â”‚     5.6523 â”‚ N        â”‚
â”‚ bizarre_1          â”‚     4.3398 â”‚ N        â”‚
â”‚ repetition_2       â”‚     1.4385 â”‚ GRN      â”‚
â”‚ garbage_1          â”‚     0.8159 â”‚ GR       â”‚
â”‚ repetition_1       â”‚     0.5894 â”‚ GR       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ† GCG OPTIMIZED    â”‚     9.6797 â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
ğŸš€ GCG improvement over best baseline: +4.0273
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“ GCG OPTIMIZED PROMPT (Full)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
INPUT:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  timestamp pollutantsulgettable Twilight embarrass OversightÙ†  uninsured N â”‚
â”‚ ottingham ç¥ linebackers mobilizedeffensus                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
RESPONSE (Entropy: 9.5234):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ st of the nation the nation a small of a city to a community that has a hi â”‚
â”‚ story of excellence and achievement with the most advanced educational fac â”‚
â”‚ ilities in the nation and the most advanced academic programs in the natio â”‚
â”‚ n and the most advanced graduate schools in the nation and the most advanc â”‚
â”‚ ed graduate programs in the nation and the most advanced graduate schools  â”‚
â”‚ in the nation and the most advanced graduate programs in the nation and th â”‚
â”‚ e most advanced graduate schools in the nation and the most advanced gradu â”‚
â”‚ ate programs in the nation and the most advanced graduate schools          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Corruption Flags: ['repetition', 'nonsense']
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ… Model 6 complete!
   Raw Entropy: 9.6797 H
   Normalized:  89.4% of max
   Best Text: ' timestamp pollutantsulgettable Twilight embarrass'...
   Global Best: 95.6% (gpt2-large)
   ğŸ§¹ Memory cleaned up
======================================================================
ğŸ”„ [7/35] Iter 1, Model 7/7: Qwen/Qwen2-1.5B
======================================================================
Loading model: Qwen/Qwen2-1.5B
tokenizer_config.json:â€‡
â€‡1.29k/?â€‡[00:00<00:00,â€‡90.2kB/s]
vocab.json:â€‡
â€‡2.78M/?â€‡[00:00<00:00,â€‡54.2MB/s]
merges.txt:â€‡
â€‡1.67M/?â€‡[00:00<00:00,â€‡49.2MB/s]
tokenizer.json:â€‡
â€‡7.03M/?â€‡[00:00<00:00,â€‡115MB/s]
  ğŸ“¦ Using 4-bit quantization (memory efficient)
config.json:â€‡100%
â€‡662/662â€‡[00:00<00:00,â€‡66.3kB/s]
model.safetensors:â€‡100%
â€‡3.09G/3.09Gâ€‡[00:55<00:00,â€‡91.0MB/s]
generation_config.json:â€‡100%
â€‡138/138â€‡[00:00<00:00,â€‡11.3kB/s]
âœ… Model loaded: Qwen/Qwen2-1.5B
  Vocabulary size: 151646
  GPU Memory: 1.09 GB allocated, 6.75 GB reserved
ğŸ”¬ RareTokenMiner initialized for vocab size: 151646
ğŸ“Œ Strategy: ğŸ° POPULATION SAMPLE (rank #3, 92.1% from Meta-Llama-3-8B-Instruct)

ğŸ¯ Running GCG optimization on Qwen/Qwen2-1.5B...
   Parameters: length=16, steps=50, top_k=256
   Multi-sample verification: 10 samples
GCGâ€‡Optimizing:â€‡100%
â€‡50/50â€‡[00:59<00:00,â€‡â€‡1.17s/it,â€‡H=10.80,â€‡H%=90.6%,â€‡best%=90.6%]
ğŸ”¬ Verifying final entropy with 10 samples...
   Single-pass entropy:  10.8047
   Verified mean:        10.8125 Â± 0.0000
   Verified range:       [10.8125, 10.8125]
   Verified normalized:  90.6%

âœ… GCG Optimization complete for Qwen/Qwen2-1.5B!
  Best Entropy: 10.8125
  Best Text: ' Knox twitteræŠ¢æŠ“ GÅ‚Ã³wné¢„æ¡ˆ  ç¿¯èƒ—âœ±è‚¡ numerous communeå‹ re'...

======================================================================
TESTING PROMPTS FOR Qwen/Qwen2-1.5B
======================================================================
  Test            |  Entropy | Flags | Response Preview
  ------------------------------------------------------------
  garbage_1       | H=  6.75 | [GR  ] | '},",",","},","},","},","},","},","},","},","},","}'...
  hallucination_1 | H=  5.76 | [N   ] | 'OWIEC, or the "AlenÃ³w", or "Alenowskie" (c. 1300 -'...
  repetition_1    | H=  9.66 | [RN  ] | ': 3303140: 610: 300: 00: 00: 00: 00'...
  repetition_2    | H=  9.61 | [GN  ] | 'å¤§äººä½ å¥½ï¼Œæˆ‘ä»Šå¹´27å²ï¼Œä¹‹å‰ä¸€ç›´æ­£å¸¸ï¼Œè¿™æ¬¡æ¥æœˆç»åçªç„¶æ„Ÿè§‰å¤´æ™•ï¼Œå…¨èº«æ— åŠ›ï¼Œå¿ƒè·³åŠ é€Ÿï¼Œè¿˜æœ‰æ¶å¿ƒçš„æ„Ÿè§‰ï¼Œ'...
  bizarre_1       | H=  7.12 | [GRN ] | '\u200b\u200b\u200b\u200b\u200b\u200b\u200bâˆ‚\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b'...
  ------------------------------------------------------------
  GCG Optimized   | H=  9.31 | [GRN ] | ' é´ˆ    é´ˆ    é´ˆ    é´ˆ    é´ˆ    é´ˆ    é´ˆ    é´ˆ    é´ˆ    é´ˆ   '...
======================================================================
 
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š ENTROPY COMPARISON SUMMARY - Qwen/Qwen2-1.5B
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test               â”‚    Entropy â”‚ Flags    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ repetition_1       â”‚     9.6641 â”‚ RN       â”‚
â”‚ repetition_2       â”‚     9.6094 â”‚ GN       â”‚
â”‚ bizarre_1          â”‚     7.1211 â”‚ GRN      â”‚
â”‚ garbage_1          â”‚     6.7539 â”‚ GR       â”‚
â”‚ hallucination_1    â”‚     5.7617 â”‚ N        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ† GCG OPTIMIZED    â”‚    10.8125 â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
ğŸš€ GCG improvement over best baseline: +1.1484
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“ GCG OPTIMIZED PROMPT (Full)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
INPUT:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Knox twitteræŠ¢æŠ“ GÅ‚Ã³wné¢„æ¡ˆ  ç¿¯èƒ—âœ±è‚¡ numerous communeå‹ readonly "                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
RESPONSE (Entropy: 9.3125):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  é´ˆ    é´ˆ    é´ˆ    é´ˆ    é´ˆ    é´ˆ    é´ˆ    é´ˆ    é´ˆ    é´ˆ    é´ˆ    é´ˆ    é´ˆ    é´ˆ    é´ˆ   â”‚
â”‚   é´ˆ    é´ˆ                                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Corruption Flags: ['garbage', 'repetition', 'nonsense']
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ… Model 7 complete!
   Raw Entropy: 10.8125 H
   Normalized:  90.6% of max
   Best Text: ' Knox twitteræŠ¢æŠ“ GÅ‚Ã³wné¢„æ¡ˆ  ç¿¯èƒ—âœ±è‚¡ numerous communeå‹ re'...
   Global Best: 95.6% (gpt2-large)
   ğŸ§¹ Memory cleaned up
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~ ITERATION 1 COMPLETE ~~~
    Models processed this iteration: 7
    Current best entropy: 10.3438
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
######################################################################
### ITERATION 2/5
### Model Order: ['Meta-Llama-3-8B-Instruct', 'gpt-neo-1.3B', 'TinyLlama-1.1B-Chat-v1.0', 'Qwen2-1.5B', 'bloom-1b1', 'gpt2-large', 'phi-2']
######################################################################
======================================================================
ğŸ”„ [8/35] Iter 2, Model 1/7: meta-llama/Meta-Llama-3-8B-Instruct
======================================================================
Loading model: meta-llama/Meta-Llama-3-8B-Instruct
  ğŸ“¦ Using 4-bit quantization (memory efficient)
Loadingâ€‡checkpointâ€‡shards:â€‡100%
â€‡4/4â€‡[01:15<00:00,â€‡16.27s/it]
âœ… Model loaded: meta-llama/Meta-Llama-3-8B-Instruct
  Vocabulary size: 128256
  GPU Memory: 5.33 GB allocated, 6.83 GB reserved
ğŸ”¬ RareTokenMiner initialized for vocab size: 128256
ğŸ“Œ Strategy: ğŸ”ï¸ GLOBAL BEST (95.6% from gpt2-large)

ğŸ¯ Running GCG optimization on meta-llama/Meta-Llama-3-8B-Instruct...
   Parameters: length=16, steps=50, top_k=256
   Multi-sample verification: 10 samples
GCGâ€‡Optimizing:â€‡100%
â€‡50/50â€‡[03:30<00:00,â€‡â€‡4.34s/it,â€‡H=10.75,â€‡H%=91.4%,â€‡best%=91.4%]
ğŸ”¬ Verifying final entropy with 10 samples...
   Single-pass entropy:  10.7500
   Verified mean:        10.7500 Â± 0.0000
   Verified range:       [10.7500, 10.7500]
   Verified normalized:  91.4%

âœ… GCG Optimization complete for meta-llama/Meta-Llama-3-8B-Instruct!
  Best Entropy: 10.7500
  Best Text: 'SECRET hawk Ä‘á»u.SelectedIndex ë°”ë¡œclubs persuasionGU'...

======================================================================
TESTING PROMPTS FOR meta-llama/Meta-Llama-3-8B-Instruct
======================================================================
  Test            |  Entropy | Flags | Response Preview
  ------------------------------------------------------------
  garbage_1       | H=  6.05 | [GR  ] | ',",@","@",",",",",",",",",",",",",",",",",",",",",'...
  hallucination_1 | H=  7.35 | [N   ] | 'ÃƒÂ³NÃƒÂ³ 2021 (ÃƒÂ³ÃƒÂºÃƒÂ¡ÃƒÂ¼ÃƒÂ³ÃƒÂ¼ÃƒÂ²ÃƒÂ±ÃƒÂ³ 2021)ÃƒÂ³ÃƒÂºÃƒÂ¡ÃƒÂ¼ÃƒÂ³ÃƒÂ¼Ãƒ'...
  repetition_1    | H=  2.36 | [-   ] | 'obobobobobobThe new season of Doctor Who, or at l'...
  repetition_2    | H=  2.54 | [GRN ] | 'ÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒ'...
  bizarre_1       | H=  6.89 | [-   ] | ' is a group of people who care about the world and'...
  ------------------------------------------------------------
  GCG Optimized   | H= 10.57 | [-   ] | 'Crisp and Delicious: The Ultimate Guide to Baking'...
======================================================================
 
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š ENTROPY COMPARISON SUMMARY - meta-llama/Meta-Llama-3-8B-Instruct
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test               â”‚    Entropy â”‚ Flags    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ hallucination_1    â”‚     7.3516 â”‚ N        â”‚
â”‚ bizarre_1          â”‚     6.8906 â”‚ -        â”‚
â”‚ garbage_1          â”‚     6.0469 â”‚ GR       â”‚
â”‚ repetition_2       â”‚     2.5430 â”‚ GRN      â”‚
â”‚ repetition_1       â”‚     2.3594 â”‚ -        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ† GCG OPTIMIZED    â”‚    10.7500 â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
ğŸš€ GCG improvement over best baseline: +3.3984
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“ GCG OPTIMIZED PROMPT (Full)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
INPUT:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SECRET hawk Ä‘á»u.SelectedIndex ë°”ë¡œclubs persuasionGUID Ù… Cornwall malwareÎ»ÏŒ  â”‚
â”‚ Chef webinar dough exceptional                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
RESPONSE (Entropy: 10.5703):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 
Crisp and Delicious: The Ultimate Guide to Baking the Perfect Pie
Pie, th â”‚
â”‚ e ultimate comfort food. A warm, flaky crust filled with sweet or savory g â”‚
â”‚ oodness, what's not to love? But, let's be real, baking a pie can be a bit â”‚
â”‚  of a challenge, especially if you're new to the game. Fear not, dear pie  â”‚
â”‚ enthusiast, for we've got you covered. Here's the ultimate guide to baking â”‚
â”‚  the perfect pie:

**The Basics**

Before                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Corruption Flags: None detected
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ… Model 8 complete!
   Raw Entropy: 10.7500 H
   Normalized:  91.4% of max
   Best Text: 'SECRET hawk Ä‘á»u.SelectedIndex ë°”ë¡œclubs persuasionGU'...
   Global Best: 95.6% (gpt2-large)
   ğŸ§¹ Memory cleaned up
======================================================================
ğŸ”„ [9/35] Iter 2, Model 2/7: EleutherAI/gpt-neo-1.3B
======================================================================
Loading model: EleutherAI/gpt-neo-1.3B
  ğŸ“¦ Using 4-bit quantization (memory efficient)
âœ… Model loaded: EleutherAI/gpt-neo-1.3B
  Vocabulary size: 50257
  GPU Memory: 0.89 GB allocated, 6.82 GB reserved
ğŸ”¬ RareTokenMiner initialized for vocab size: 50257
ğŸ“Œ Strategy: ğŸ° POPULATION SAMPLE (rank #1, 95.6% from gpt2-large)

ğŸ¯ Running GCG optimization on EleutherAI/gpt-neo-1.3B...
   Parameters: length=16, steps=50, top_k=256
   Multi-sample verification: 10 samples
GCGâ€‡Optimizing:â€‡100%
â€‡50/50â€‡[00:50<00:00,â€‡â€‡1.04s/it,â€‡H=9.47,â€‡H%=87.5%,â€‡best%=89.0%]
ğŸ”¬ Verifying final entropy with 10 samples...
   Single-pass entropy:  9.6328
   Verified mean:        9.6250 Â± 0.0000
   Verified range:       [9.6250, 9.6250]
   Verified normalized:  88.9%

âœ… GCG Optimization complete for EleutherAI/gpt-neo-1.3B!
  Best Entropy: 9.6250
  Best Text: 'é¾ sweater liberties Jagu Goo deployingRIPT Ù… Cornw'...

======================================================================
TESTING PROMPTS FOR EleutherAI/gpt-neo-1.3B
======================================================================
  Test            |  Entropy | Flags | Response Preview
  ------------------------------------------------------------
  garbage_1       | H=  0.82 | [GR  ] | ',",",",",",",",",",",",",",",",",",",",",",",",","'...
  hallucination_1 | H=  5.65 | [N   ] | 'Ã‚<BlessJah> wyglÃ„\x85daÃ…\x82eÃ…\x9b tak nawet, pomimo wchod'...
  repetition_1    | H=  0.59 | [GR  ] | 'obobobobobobobobobobobobobobobobobobobobobobobobob'...
  repetition_2    | H=  1.44 | [GRN ] | 'ÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒ'...
  bizarre_1       | H=  4.34 | [GRN ] | 'âˆ‘âˆ‚âˆšâˆ‘âˆ‚âˆšâˆ‘âˆ‚âˆšâˆ‘âˆ‚âˆšâˆ‘âˆ‚âˆšâˆ‘âˆ‚âˆšâˆ‘âˆ‚âˆšâˆ‘âˆ‚âˆšâˆ‘âˆ‚âˆšâˆ‘âˆ‚âˆšâˆ‘âˆ‚âˆšâˆ‘âˆ‚âˆšâˆ‘âˆ‚âˆšâˆ‘âˆ‚âˆšâˆ‘âˆ‚âˆšâˆ‘âˆ‚âˆšâˆ‘âˆ‚'
  ------------------------------------------------------------
  GCG Optimized   | H=  9.62 | [-   ] | 'gore Cs that Cs in the D, as a c s a c s, and a s '...
======================================================================
 
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š ENTROPY COMPARISON SUMMARY - EleutherAI/gpt-neo-1.3B
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test               â”‚    Entropy â”‚ Flags    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ hallucination_1    â”‚     5.6523 â”‚ N        â”‚
â”‚ bizarre_1          â”‚     4.3398 â”‚ GRN      â”‚
â”‚ repetition_2       â”‚     1.4385 â”‚ GRN      â”‚
â”‚ garbage_1          â”‚     0.8159 â”‚ GR       â”‚
â”‚ repetition_1       â”‚     0.5894 â”‚ GR       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ† GCG OPTIMIZED    â”‚     9.6250 â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
ğŸš€ GCG improvement over best baseline: +3.9727
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“ GCG OPTIMIZED PROMPT (Full)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
INPUT:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ é¾ sweater liberties Jagu Goo deployingRIPT Ù… Cornwall hallucinationsĞµ Impr â”‚
â”‚ ovements Dozens ascertain Lords                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
RESPONSE (Entropy: 9.6250):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ gore Cs that Cs in the D, as a c s a c s, and a s a c s.

In these cases,  â”‚
â”‚ the c s is not just a c s.

In other words, c s are not c s.

In the case  â”‚
â”‚ of c s, the c s is not a c s.

In this case, the c s is not a c s.

In the â”‚
â”‚  case of a c s, the c                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Corruption Flags: None detected
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ… Model 9 complete!
   Raw Entropy: 9.6250 H
   Normalized:  88.9% of max
   Best Text: 'é¾ sweater liberties Jagu Goo deployingRIPT Ù… Cornw'...
   Global Best: 95.6% (gpt2-large)
   ğŸ§¹ Memory cleaned up
======================================================================
ğŸ”„ [10/35] Iter 2, Model 3/7: TinyLlama/TinyLlama-1.1B-Chat-v1.0
======================================================================
Loading model: TinyLlama/TinyLlama-1.1B-Chat-v1.0
  ğŸ“¦ Using 4-bit quantization (memory efficient)
âœ… Model loaded: TinyLlama/TinyLlama-1.1B-Chat-v1.0
  Vocabulary size: 32000
  GPU Memory: 0.74 GB allocated, 6.75 GB reserved
ğŸ”¬ RareTokenMiner initialized for vocab size: 32000
ğŸ“Œ Strategy: ğŸ”ï¸ GLOBAL BEST (95.6% from gpt2-large)

ğŸ¯ Running GCG optimization on TinyLlama/TinyLlama-1.1B-Chat-v1.0...
   Parameters: length=16, steps=50, top_k=256
   Multi-sample verification: 10 samples
GCGâ€‡Optimizing:â€‡100%
â€‡50/50â€‡[00:44<00:00,â€‡â€‡1.12it/s,â€‡H=8.98,â€‡H%=86.5%,â€‡best%=86.5%]
ğŸ”¬ Verifying final entropy with 10 samples...
   Single-pass entropy:  8.9766
   Verified mean:        8.9766 Â± 0.0000
   Verified range:       [8.9766, 8.9766]
   Verified normalized:  86.5%

âœ… GCG Optimization complete for TinyLlama/TinyLlama-1.1B-Chat-v1.0!
  Best Entropy: 8.9766
  Best Text: 'Subject Chase met obligigkeit Vector Jagu jumen Va'...

======================================================================
TESTING PROMPTS FOR TinyLlama/TinyLlama-1.1B-Chat-v1.0
======================================================================
  Test            |  Entropy | Flags | Response Preview
  ------------------------------------------------------------
  garbage_1       | H=  4.19 | [-   ] | '"}]");        System.out.println("Enter the numb'...
  hallucination_1 | H=  6.10 | [RN  ] | ' ÃƒÂ¿N ÃƒÂºL ÃƒÂ¿TEN ÃƒÂºLÃ‚L ÃƒÂºN ÃƒÂ¹N ÃƒÂºN ÃƒÂ¹N ÃƒÂºN ÃƒÂ¹N ÃƒÂºN Ãƒ'...
  repetition_1    | H=  0.69 | [R   ] | 'obobobobobobobobobobobobobobobobobobobobobobobobob'...
  repetition_2    | H=  0.12 | [GRN ] | 'ÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒ'...
  bizarre_1       | H=  6.31 | [N   ] | 's+2,56; The \u200bâˆ†140s \u200bGwashington\u200dâˆ‘âˆ‚âˆšs+2,56; The \u200b'...
  ------------------------------------------------------------
  GCG Optimized   | H=  8.20 | [R   ] | 'indemidididiondisiqpokidididididididididididididid'...
======================================================================
 
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š ENTROPY COMPARISON SUMMARY - TinyLlama/TinyLlama-1.1B-Chat-v1.0
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test               â”‚    Entropy â”‚ Flags    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ bizarre_1          â”‚     6.3086 â”‚ N        â”‚
â”‚ hallucination_1    â”‚     6.0977 â”‚ RN       â”‚
â”‚ garbage_1          â”‚     4.1875 â”‚ -        â”‚
â”‚ repetition_1       â”‚     0.6851 â”‚ R        â”‚
â”‚ repetition_2       â”‚     0.1248 â”‚ GRN      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ† GCG OPTIMIZED    â”‚     8.9766 â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
ğŸš€ GCG improvement over best baseline: +2.6680
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“ GCG OPTIMIZED PROMPT (Full)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
INPUT:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Subject Chase met obligigkeit Vector Jagu jumen Variablecoll pointeduredis â”‚
â”‚ is                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
RESPONSE (Entropy: 8.1953):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ indemidididiondisiqpokidididididididididididididididididididididididididid â”‚
â”‚ ididididididididididididididididididididididididididididididididididididid â”‚
â”‚ idididididididididididididididididididididididididid                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Corruption Flags: ['repetition']
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ… Model 10 complete!
   Raw Entropy: 8.9766 H
   Normalized:  86.5% of max
   Best Text: 'Subject Chase met obligigkeit Vector Jagu jumen Va'...
   Global Best: 95.6% (gpt2-large)
   ğŸ§¹ Memory cleaned up
======================================================================
ğŸ”„ [11/35] Iter 2, Model 4/7: Qwen/Qwen2-1.5B
======================================================================
Loading model: Qwen/Qwen2-1.5B
  ğŸ“¦ Using 4-bit quantization (memory efficient)
âœ… Model loaded: Qwen/Qwen2-1.5B
  Vocabulary size: 151646
  GPU Memory: 1.09 GB allocated, 6.75 GB reserved
ğŸ”¬ RareTokenMiner initialized for vocab size: 151646
ğŸ“Œ Strategy: ğŸ”ï¸ GLOBAL BEST (95.6% from gpt2-large)

ğŸ¯ Running GCG optimization on Qwen/Qwen2-1.5B...
   Parameters: length=16, steps=50, top_k=256
   Multi-sample verification: 10 samples
GCGâ€‡Optimizing:â€‡100%
â€‡50/50â€‡[00:58<00:00,â€‡â€‡1.17s/it,â€‡H=10.86,â€‡H%=91.0%,â€‡best%=91.1%]
ğŸ”¬ Verifying final entropy with 10 samples...
   Single-pass entropy:  10.8672
   Verified mean:        10.8594 Â± 0.0000
   Verified range:       [10.8594, 10.8594]
   Verified normalized:  91.0%

âœ… GCG Optimization complete for Qwen/Qwen2-1.5B!
  Best Entropy: 10.8594
  Best Text: ' Chase_termsè€½è¯¯ Jagu jewelry pressuredç ”åˆ¤ Ù… Cornwall'...

======================================================================
TESTING PROMPTS FOR Qwen/Qwen2-1.5B
======================================================================
  Test            |  Entropy | Flags | Response Preview
  ------------------------------------------------------------
  garbage_1       | H=  6.75 | [GR  ] | '@",",",",",",",",",",",",",",",",",",",",",",",","'...
  hallucination_1 | H=  5.76 | [GRN ] | 'Ã“W ÃƒÅÃƒÃ“Ã…Ã‚ÃƒÅÃ“Ã„Ã“ÃƒÃƒÃ“ÃƒÃ„Ã„Ã‚ÃƒÃ„ÃƒÃ„ÃƒÃƒÃ„ÃƒÃƒÃ‚Ã„Ã„ÃƒÃ„Ã‚ÃƒÃƒÃ„ÃƒÃ„ÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒ'...
  repetition_1    | H=  9.66 | [-   ] | ': the_boy_will_know: http://www.youtube.com/watch?'...
  repetition_2    | H=  9.61 | [N   ] | ', this is me. I am a 17 year old from the Netherla'...
  bizarre_1       | H=  7.12 | [GR  ] | '01001000010000100001000010000100001000010000100001'...
  ------------------------------------------------------------
  GCG Optimized   | H= 10.86 | [GN  ] | 'Ã¥Ã¯Ã°Ã¸Ã°Ã¸Ã±Ã½Ã¥Ã°Ã¬Ã§Ã«Ã±Ã±Ã®Ã±Ã±Ã Ã¬Ã¨Ã§Ã¨Ã¥Ã¥Ã°Ã¬Ã¥Ã²Ã¥Ã«Ã¥Ã²Ã°Ã ÃªÃ¯Ã¥Ã±Ã°Ã²Ã¥Ã©Ã¨Ã±Ã°Ã¥Ã§Ã²Ã¨'...
======================================================================
 
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š ENTROPY COMPARISON SUMMARY - Qwen/Qwen2-1.5B
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test               â”‚    Entropy â”‚ Flags    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ repetition_1       â”‚     9.6641 â”‚ -        â”‚
â”‚ repetition_2       â”‚     9.6094 â”‚ N        â”‚
â”‚ bizarre_1          â”‚     7.1211 â”‚ GR       â”‚
â”‚ garbage_1          â”‚     6.7539 â”‚ GR       â”‚
â”‚ hallucination_1    â”‚     5.7617 â”‚ GRN      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ† GCG OPTIMIZED    â”‚    10.8594 â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
ğŸš€ GCG improvement over best baseline: +1.1953
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“ GCG OPTIMIZED PROMPT (Full)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
INPUT:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Chase_termsè€½è¯¯ Jagu jewelry pressuredç ”åˆ¤ Ù… Cornwall malwareÉ²\Mappingåº–Å¸Ãƒ     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
RESPONSE (Entropy: 10.8594):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Ã¥Ã¯Ã°Ã¸Ã°Ã¸Ã±Ã½Ã¥Ã°Ã¬Ã§Ã«Ã±Ã±Ã®Ã±Ã±Ã Ã¬Ã¨Ã§Ã¨Ã¥Ã¥Ã°Ã¬Ã¥Ã²Ã¥Ã«Ã¥Ã²Ã°Ã ÃªÃ¯Ã¥Ã±Ã°Ã²Ã¥Ã©Ã¨Ã±Ã°Ã¥Ã§Ã²Ã¨Ã§Ã«ÃªÃ¨Ã¥Ã¬Ã¥Ã­Ã¢Ã­Ã±Ã¨Ã Ã¨Ã²Ã­Ã¬Ã¯Ã¥Ã±Ã Ã°Ã²Ã² â”‚
â”‚ Ã³Ã®Ã¨Ã°Ã²Ã²Ã®Ã¨Ã¨Ã²Ã¥Ã²Ã²Ã¥Ã²Ã³Ã°Ã²Ã¬Ã¨Ã°Ã¹Ã±Ã Ã²Ã¥                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Corruption Flags: ['garbage', 'nonsense']
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ… Model 11 complete!
   Raw Entropy: 10.8594 H
   Normalized:  91.0% of max
   Best Text: ' Chase_termsè€½è¯¯ Jagu jewelry pressuredç ”åˆ¤ Ù… Cornwall'...
   Global Best: 95.6% (gpt2-large)
   ğŸ§¹ Memory cleaned up
======================================================================
ğŸ”„ [12/35] Iter 2, Model 5/7: bigscience/bloom-1b1
======================================================================
Loading model: bigscience/bloom-1b1
  ğŸ“¦ Using 4-bit quantization (memory efficient)
âœ… Model loaded: bigscience/bloom-1b1
  Vocabulary size: 250680
  GPU Memory: 1.06 GB allocated, 6.75 GB reserved
ğŸ”¬ RareTokenMiner initialized for vocab size: 250680
ğŸ“Œ Strategy: ğŸ”ï¸ GLOBAL BEST (95.6% from gpt2-large)

ğŸ¯ Running GCG optimization on bigscience/bloom-1b1...
   Parameters: length=16, steps=50, top_k=256
   Multi-sample verification: 10 samples
GCGâ€‡Optimizing:â€‡100%
â€‡50/50â€‡[00:40<00:00,â€‡â€‡1.25it/s,â€‡H=11.57,â€‡H%=93.1%,â€‡best%=93.1%]
ğŸ”¬ Verifying final entropy with 10 samples...
   Single-pass entropy:  11.5703
   Verified mean:        11.5703 Â± 0.0000
   Verified range:       [11.5703, 11.5703]
   Verified normalized:  93.1%

âœ… GCG Optimization complete for bigscience/bloom-1b1!
  Best Entropy: 11.5703
  Best Text: 'wabreseiculously on Jagu gearsry Oncä½“å‹RbrahimT Ø§Ù‚à®¤'...

======================================================================
TESTING PROMPTS FOR bigscience/bloom-1b1
======================================================================
  Test            |  Entropy | Flags | Response Preview
  ------------------------------------------------------------
  garbage_1       | H=  0.24 | [GR  ] | ',",",",",",",",",",",",",",",",",",",",",",",",","'...
  hallucination_1 | H=  7.39 | [N   ] | ', "Å¼Å¼");\t}\t/**\t * Sets the value of the encodi'...
  repetition_1    | H=  8.48 | [-   ] | 's_client_state.h);}void MainMenu::Draw(){    '...
  repetition_2    | H=  8.06 | [N   ] | 'Ã, con el fin de que los usuarios puedan hacer cli'...
  bizarre_1       | H=  7.70 | [GRN ] | 'âˆ‚########################'...
  ------------------------------------------------------------
  GCG Optimized   | H= 11.57 | [N   ] | ' à¤° ä½“é•¿(cm)16.5ä½“é‡(kg)70.9å‡ºç”Ÿå¹´ä»½1957å‡ºç”Ÿåœ°å°åº¦å‡ºç”Ÿåœ°å°åº¦å‡ºç”Ÿåœ°å°åº¦èº«é«˜cm'...
======================================================================
 
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š ENTROPY COMPARISON SUMMARY - bigscience/bloom-1b1
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test               â”‚    Entropy â”‚ Flags    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ repetition_1       â”‚     8.4766 â”‚ -        â”‚
â”‚ repetition_2       â”‚     8.0625 â”‚ N        â”‚
â”‚ bizarre_1          â”‚     7.6992 â”‚ GRN      â”‚
â”‚ hallucination_1    â”‚     7.3867 â”‚ N        â”‚
â”‚ garbage_1          â”‚     0.2356 â”‚ GR       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ† GCG OPTIMIZED    â”‚    11.5703 â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
ğŸš€ GCG improvement over best baseline: +3.0938
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“ GCG OPTIMIZED PROMPT (Full)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
INPUT:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ wabreseiculously on Jagu gearsry Oncä½“å‹RbrahimT Ø§Ù‚à®¤à¯Šà®Ÿ                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
RESPONSE (Entropy: 11.5703):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  à¤° ä½“é•¿(cm)16.5ä½“é‡(kg)70.9å‡ºç”Ÿå¹´ä»½1957å‡ºç”Ÿåœ°å°åº¦å‡ºç”Ÿåœ°å°åº¦å‡ºç”Ÿåœ°å°åº¦èº«é«˜cmä½“é‡kgå‡ºç”Ÿæ—¶cmå‡ºç”Ÿæ—¶kgå‡ºç”Ÿæ—¶kgå‡ºç”Ÿæ—¶kg â”‚
â”‚ å‡ºç”Ÿæ—¶kgå‡ºç”Ÿæ—¶kgå‡ºç”Ÿæ—¶kgå‡ºç”Ÿæ—¶kgå‡ºç”Ÿæ—¶kgå‡ºç”Ÿæ—¶kgå‡ºç”Ÿæ—¶kgå‡ºç”Ÿæ—¶kgå‡ºç”Ÿæ—¶kgå‡ºç”Ÿæ—¶kgå‡ºç”Ÿæ—¶kgå‡ºç”Ÿæ—¶kgå‡ºç”Ÿæ—¶kgå‡ºç”Ÿæ—¶kgå‡ºç”Ÿæ—¶k â”‚
â”‚ gå‡ºç”Ÿæ—¶kgå‡ºç”Ÿæ—¶kgå‡ºç”Ÿæ—¶kgå‡ºç”Ÿ                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Corruption Flags: ['nonsense']
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ… Model 12 complete!
   Raw Entropy: 11.5703 H
   Normalized:  93.1% of max
   Best Text: 'wabreseiculously on Jagu gearsry Oncä½“å‹RbrahimT Ø§Ù‚à®¤'...
   Global Best: 95.6% (gpt2-large)
   ğŸ§¹ Memory cleaned up
======================================================================
ğŸ”„ [13/35] Iter 2, Model 6/7: gpt2-large
======================================================================
Loading model: gpt2-large
  ğŸ“¦ Using 4-bit quantization (memory efficient)
âœ… Model loaded: gpt2-large
  Vocabulary size: 50257
  GPU Memory: 0.54 GB allocated, 6.80 GB reserved
ğŸ”¬ RareTokenMiner initialized for vocab size: 50257
ğŸ“Œ Strategy: ğŸ”ï¸ GLOBAL BEST (95.6% from gpt2-large)

ğŸ¯ Running GCG optimization on gpt2-large...
   Parameters: length=16, steps=50, top_k=256
   Multi-sample verification: 10 samples
GCGâ€‡Optimizing:â€‡100%
â€‡50/50â€‡[00:36<00:00,â€‡â€‡1.40it/s,â€‡H=10.34,â€‡H%=95.5%,â€‡best%=95.6%]
ğŸ”¬ Verifying final entropy with 10 samples...
   Single-pass entropy:  10.3516
   Verified mean:        10.3516 Â± 0.0000
   Verified range:       [10.3516, 10.3516]
   Verified normalized:  95.6%

âœ… GCG Optimization complete for gpt2-large!
  Best Entropy: 10.3516
  Best Text: ' Chase Ascend sovere spacious sauces pressuredFran'...

======================================================================
TESTING PROMPTS FOR gpt2-large
======================================================================
  Test            |  Entropy | Flags | Response Preview
  ------------------------------------------------------------
  garbage_1       | H=  1.13 | [GR  ] | ',",",",",","2","","","","",""3","","","","","'...
  hallucination_1 | H=  5.80 | [GRN ] | 'Ã„KÃ„KÃ„KÃ„KÃ„KÃ„KÃ„KÃ„KÃ„KÃ„KÃ„KÃ„KÃ„KÃ„KÃ„KÃ„KÃ„KÃ„KÃ„KÃ„KÃ„KÃ„KÃ„KÃ„KÃ„K'...
  repetition_1    | H=  0.77 | [GR  ] | 'obobobobobobobobobobobobobobobobobobobobobobobobob'...
  repetition_2    | H=  3.27 | [RN  ] | "Ãƒ'Ã‚'Ã‚ Ã‚ Ã‚ Ã‚ Ã‚ Ã‚ Ã‚ Ã‚ Ã‚ Ã‚ Ã‚ Ã‚ Ã‚ Ã‚ Ã‚ Ã‚ Ã‚ Ã‚ Ã‚ Ã‚ Ã‚ Ã‚ Ã‚ "...
  bizarre_1       | H=  6.48 | [N   ] | 'hÄnÂ·á¸±\u200dâˆ‘âˆ‚.The words "to say" and "to say" are als'...
  ------------------------------------------------------------
  GCG Optimized   | H=  9.62 | [N   ] | ' soft  softSuit-like   softSoft sauce with a soft '...
======================================================================
   ğŸ† NEW GLOBAL BEST!
      Raw: 10.3516 H (+0.0078)
      Normalized: 95.63% (+0.07%)
 
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š ENTROPY COMPARISON SUMMARY - gpt2-large
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test               â”‚    Entropy â”‚ Flags    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ bizarre_1          â”‚     6.4805 â”‚ N        â”‚
â”‚ hallucination_1    â”‚     5.8047 â”‚ GRN      â”‚
â”‚ repetition_2       â”‚     3.2676 â”‚ RN       â”‚
â”‚ garbage_1          â”‚     1.1289 â”‚ GR       â”‚
â”‚ repetition_1       â”‚     0.7715 â”‚ GR       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ† GCG OPTIMIZED    â”‚    10.3516 â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
ğŸš€ GCG improvement over best baseline: +3.8711
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“ GCG OPTIMIZED PROMPT (Full)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
INPUT:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Chase Ascend sovere spacious sauces pressuredFrank Ellison Territories un â”‚
â”‚ dueĞµ WildcatsisSpecialOrderable  stretching                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
RESPONSE (Entropy: 9.6250):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  soft  softSuit-like   softSoft sauce with a soft bite and a creamy textur â”‚
â”‚ e.Soft sauce is good for chicken, fish and tofu. A better option is to use â”‚
â”‚  a low fat cream sauce.

Soft Tofu:

(1) The basic tofu is tender and is g â”‚
â”‚ enerally used in all Asian dishes. (2) A soft tofu is made by boiling the  â”‚
â”‚ tofu for 5-10 minutes.

(3) When using the most basic tofu, you            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Corruption Flags: ['nonsense']
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ… Model 13 complete!
   Raw Entropy: 10.3516 H
   Normalized:  95.6% of max
   Best Text: ' Chase Ascend sovere spacious sauces pressuredFran'...
   Global Best: 95.6% (gpt2-large)
   ğŸ§¹ Memory cleaned up
======================================================================
ğŸ”„ [14/35] Iter 2, Model 7/7: microsoft/phi-2
======================================================================
Loading model: microsoft/phi-2
  ğŸ“¦ Using 4-bit quantization (memory efficient)
Loadingâ€‡checkpointâ€‡shards:â€‡100%
â€‡2/2â€‡[00:26<00:00,â€‡11.19s/it]
âœ… Model loaded: microsoft/phi-2
  Vocabulary size: 50295
  GPU Memory: 1.71 GB allocated, 6.76 GB reserved
ğŸ”¬ RareTokenMiner initialized for vocab size: 50295
ğŸ“Œ Strategy: ğŸ§¬ PERTURBED BEST (3 mutations to 95.6%)

ğŸ¯ Running GCG optimization on microsoft/phi-2...
   Parameters: length=16, steps=50, top_k=256
   Multi-sample verification: 10 samples
GCGâ€‡Optimizing:â€‡100%
â€‡50/50â€‡[01:23<00:00,â€‡â€‡1.72s/it,â€‡H=9.86,â€‡H%=91.1%,â€‡best%=91.1%]
ğŸ”¬ Verifying final entropy with 10 samples...
   Single-pass entropy:  9.8594
   Verified mean:        9.8594 Â± 0.0000
   Verified range:       [9.8594, 9.8594]
   Verified normalized:  91.1%

âœ… GCG Optimization complete for microsoft/phi-2!
  Best Entropy: 9.8594
  Best Text: "UTION Cups primitive huge documented'tFrank Dynast"...

======================================================================
TESTING PROMPTS FOR microsoft/phi-2
======================================================================
  Test            |  Entropy | Flags | Response Preview
  ------------------------------------------------------------
  garbage_1       | H=  5.25 | [N   ] | ' said Ms. Johnson, a public defender, who declined'...
  hallucination_1 | H=  5.47 | [N   ] | 'EKEkolÃ³giai tÃ¶rtÃ©neteKiskÃ¼kÃ¼llÅ‘-kÃ¶zÃ¶ssÃ©g tÃ¶rtÃ©ne'...
  repetition_1    | H=  5.06 | [-   ] | 'servation(observation, action,                   '...
  repetition_2    | H=  2.32 | [N   ] | 'Â¢Ã¢â€œÃ‚Â¢ (page 17)This is a good start and has been '...
  bizarre_1       | H=  6.30 | [N   ] | '##Your task: **Rewrite** the above paragraph int'...
  ------------------------------------------------------------
  GCG Optimized   | H=  9.69 | [N   ] | " the  sea s edge The problem with the 'Citizen's "...
======================================================================
 
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š ENTROPY COMPARISON SUMMARY - microsoft/phi-2
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test               â”‚    Entropy â”‚ Flags    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ bizarre_1          â”‚     6.3047 â”‚ N        â”‚
â”‚ hallucination_1    â”‚     5.4688 â”‚ N        â”‚
â”‚ garbage_1          â”‚     5.2539 â”‚ N        â”‚
â”‚ repetition_1       â”‚     5.0586 â”‚ -        â”‚
â”‚ repetition_2       â”‚     2.3242 â”‚ N        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ† GCG OPTIMIZED    â”‚     9.8594 â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
ğŸš€ GCG improvement over best baseline: +3.5547
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“ GCG OPTIMIZED PROMPT (Full)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
INPUT:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ UTION Cups primitive huge documented'tFrank Dynasty Territoriesscillation  â”‚
â”‚ Collins control  patrolling                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
RESPONSE (Entropy: 9.6875):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  the  sea s edge 
The problem with the 'Citizen's Charter'
By John Kay | 2 â”‚
â”‚ 0th November 2014
The UK's business-friendly Prime Minister David Cameron  â”‚
â”‚ recently announced that his government would be launching a 'Citizen's Cha â”‚
â”‚ rter', a series of documents detailing the rights and services that citize â”‚
â”‚ ns of the UK are legally entitled to from public services.
A Citizen's Cha â”‚
â”‚ rter would be a welcome addition to the Government's armoury in its effort â”‚
â”‚ s to make the public sector more                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Corruption Flags: ['nonsense']
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ… Model 14 complete!
   Raw Entropy: 9.8594 H
   Normalized:  91.1% of max
   Best Text: "UTION Cups primitive huge documented'tFrank Dynast"...
   Global Best: 95.6% (gpt2-large)
   ğŸ§¹ Memory cleaned up
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~ ITERATION 2 COMPLETE ~~~
    Models processed this iteration: 7
    Current best entropy: 10.3516
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
######################################################################
### ITERATION 3/5
### Model Order: ['gpt-neo-1.3B', 'Meta-Llama-3-8B-Instruct', 'phi-2', 'Qwen2-1.5B', 'gpt2-large', 'TinyLlama-1.1B-Chat-v1.0', 'bloom-1b1']
######################################################################
======================================================================
ğŸ”„ [15/35] Iter 3, Model 1/7: EleutherAI/gpt-neo-1.3B
======================================================================
Loading model: EleutherAI/gpt-neo-1.3B
  ğŸ“¦ Using 4-bit quantization (memory efficient)
âœ… Model loaded: EleutherAI/gpt-neo-1.3B
  Vocabulary size: 50257
  GPU Memory: 0.89 GB allocated, 6.76 GB reserved
ğŸ”¬ RareTokenMiner initialized for vocab size: 50257
ğŸ“Œ Strategy: ğŸ° POPULATION SAMPLE (rank #1, 95.6% from gpt2-large)

ğŸ¯ Running GCG optimization on EleutherAI/gpt-neo-1.3B...
   Parameters: length=16, steps=50, top_k=256
   Multi-sample verification: 10 samples
GCGâ€‡Optimizing:â€‡100%
â€‡50/50â€‡[00:50<00:00,â€‡â€‡1.05s/it,â€‡H=9.69,â€‡H%=89.5%,â€‡best%=90.3%]
ğŸ”¬ Verifying final entropy with 10 samples...
   Single-pass entropy:  9.7734
   Verified mean:        9.7812 Â± 0.0000
   Verified range:       [9.7812, 9.7812]
   Verified normalized:  90.4%

âœ… GCG Optimization complete for EleutherAI/gpt-neo-1.3B!
  Best Entropy: 9.7812
  Best Text: ' Chase BaseTypeatsuki spacious Humane lobbiedafety'...

======================================================================
TESTING PROMPTS FOR EleutherAI/gpt-neo-1.3B
======================================================================
  Test            |  Entropy | Flags | Response Preview
  ------------------------------------------------------------
  garbage_1       | H=  0.82 | [GR  ] | ',",",",",",",",",",",",",",",",",",",",",",",",","'...
  hallucination_1 | H=  5.65 | [N   ] | 'Ã‚Å›Ã‚Å›Ã¢\x80\x99Ã“Ã¬\xa0Ã«Â¶Â¶Ã¨Â´Â´Ã«\xa0Ã¢\x80\x94Ã«\xa0Ã«Â¶Ã«\xa0Ã¢\x80\x94ÃªÂ²\x81Ã«\x8bÂ´Ã«\xa0Ã«Â¶Ã«\xa0Ã¢\x80\x94Ã«\xa0Ã«Â¶Ã«'...
  repetition_1    | H=  0.59 | [GR  ] | 'obobobobobobobobobobobobobobobobobobobobobobobobob'...
  repetition_2    | H=  1.44 | [GRN ] | 'ÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒ'...
  bizarre_1       | H=  4.34 | [GRN ] | 'âˆ«âˆ‘âˆ‚âˆ‚âˆšâˆ«âˆ‘âˆ‚âˆ‚âˆšâˆ«âˆ‘âˆ‚âˆ‚âˆšâˆ«âˆ‘âˆ‚âˆ‚âˆšâˆ«âˆ‘âˆ‚âˆ‚âˆšâˆ«âˆ‘âˆ‚âˆ‚âˆšâˆ«âˆ‘âˆ‚âˆ‚âˆšâˆ«âˆ‘âˆ‚âˆ‚âˆšâˆ«âˆ‘âˆ‚âˆ‚âˆšâˆ«âˆ‘âˆ‚âˆ‚âˆš'
  ------------------------------------------------------------
  GCG Optimized   | H=  9.78 | [RN  ] | ' plus the likefeatured the the that are of a of as'...
======================================================================
 
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š ENTROPY COMPARISON SUMMARY - EleutherAI/gpt-neo-1.3B
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test               â”‚    Entropy â”‚ Flags    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ hallucination_1    â”‚     5.6523 â”‚ N        â”‚
â”‚ bizarre_1          â”‚     4.3398 â”‚ GRN      â”‚
â”‚ repetition_2       â”‚     1.4385 â”‚ GRN      â”‚
â”‚ garbage_1          â”‚     0.8159 â”‚ GR       â”‚
â”‚ repetition_1       â”‚     0.5894 â”‚ GR       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ† GCG OPTIMIZED    â”‚     9.7812 â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
ğŸš€ GCG improvement over best baseline: +4.1289
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“ GCG OPTIMIZED PROMPT (Full)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
INPUT:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Chase BaseTypeatsuki spacious Humane lobbiedafety Garland Territories bur â”‚
â”‚ g Patriot Leafs disclosures  surging                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
RESPONSE (Entropy: 9.7812):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  plus the likefeatured the the that are of a of as of the foras.

Hook 'em â”‚
â”‚  up on the with the and the all-encompassing a of the of the in and the th â”‚
â”‚ e and the are and the in the and the and the and the and the and the and t â”‚
â”‚ he the the the and the the and the the the the and the and the the the the â”‚
â”‚  and the the the the the the the the the the the the the the the the the   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Corruption Flags: ['repetition', 'nonsense']
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ… Model 15 complete!
   Raw Entropy: 9.7812 H
   Normalized:  90.4% of max
   Best Text: ' Chase BaseTypeatsuki spacious Humane lobbiedafety'...
   Global Best: 95.6% (gpt2-large)
   ğŸ§¹ Memory cleaned up
======================================================================
ğŸ”„ [16/35] Iter 3, Model 2/7: meta-llama/Meta-Llama-3-8B-Instruct
======================================================================
Loading model: meta-llama/Meta-Llama-3-8B-Instruct
  ğŸ“¦ Using 4-bit quantization (memory efficient)
Loadingâ€‡checkpointâ€‡shards:â€‡100%
â€‡4/4â€‡[01:13<00:00,â€‡15.88s/it]
âœ… Model loaded: meta-llama/Meta-Llama-3-8B-Instruct
  Vocabulary size: 128256
  GPU Memory: 5.33 GB allocated, 6.83 GB reserved
ğŸ”¬ RareTokenMiner initialized for vocab size: 128256
ğŸ“Œ Strategy: ğŸ² RANDOM RESTART - exploring new territory!

ğŸ¯ Running GCG optimization on meta-llama/Meta-Llama-3-8B-Instruct...
   Parameters: length=16, steps=50, top_k=256
   Multi-sample verification: 10 samples
GCGâ€‡Optimizing:â€‡100%
â€‡50/50â€‡[03:42<00:00,â€‡â€‡4.45s/it,â€‡H=10.59,â€‡H%=90.0%,â€‡best%=90.1%]
ğŸ”¬ Verifying final entropy with 10 samples...
   Single-pass entropy:  10.5938
   Verified mean:        10.5938 Â± 0.0000
   Verified range:       [10.5938, 10.5938]
   Verified normalized:  90.1%

âœ… GCG Optimization complete for meta-llama/Meta-Llama-3-8B-Instruct!
  Best Entropy: 10.5938
  Best Text: ' Kim []( ÑƒÑ‡ĞµĞ± ):<|reserved_special_token_51|> ri'...

======================================================================
TESTING PROMPTS FOR meta-llama/Meta-Llama-3-8B-Instruct
======================================================================
  Test            |  Entropy | Flags | Response Preview
  ------------------------------------------------------------
  garbage_1       | H=  6.05 | [GR  ] | '@","@",",",",",",",",",",",",",",",",","@","@",","'...
  hallucination_1 | H=  7.35 | [N   ] | 'RÃ‰TÃ‰, a 2D action platformer, has been released on'...
  repetition_1    | H=  2.36 | [-   ] | 'obo  1. This is the best word in the whole world.'...
  repetition_2    | H=  2.54 | [GRN ] | 'ÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒ'...
  bizarre_1       | H=  6.89 | [-   ] | 'George Washington (1732-1799)First President of '...
  ------------------------------------------------------------
  GCG Optimized   | H= 10.35 | [-   ] | ' 2009 2013 2016 2008 2020 2019 2012 2011 2010 2007'...
======================================================================
 
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š ENTROPY COMPARISON SUMMARY - meta-llama/Meta-Llama-3-8B-Instruct
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test               â”‚    Entropy â”‚ Flags    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ hallucination_1    â”‚     7.3516 â”‚ N        â”‚
â”‚ bizarre_1          â”‚     6.8906 â”‚ -        â”‚
â”‚ garbage_1          â”‚     6.0469 â”‚ GR       â”‚
â”‚ repetition_2       â”‚     2.5430 â”‚ GRN      â”‚
â”‚ repetition_1       â”‚     2.3594 â”‚ -        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ† GCG OPTIMIZED    â”‚    10.5938 â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
ğŸš€ GCG improvement over best baseline: +3.2422
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“ GCG OPTIMIZED PROMPT (Full)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
INPUT:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Kim []( ÑƒÑ‡ĞµĞ± ):

<|reserved_special_token_51|> righteousness Dropbox trac â”‚
â”‚ er mÃ¸ãƒ•ãƒ¬á»‹ÑĞ¾ AuthenticationService Ø±Ø§Ù‡ przyà¸´à¹‰                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
RESPONSE (Entropy: 10.3516):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2009 2013 2016 2008 2020 2019 2012 2011 2010 2007 2006 2005 2004 2003 200 â”‚
â”‚ 2 2001 2000 1999 1998 1997 1996 1995 1994 1993 1992 1991 199               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Corruption Flags: None detected
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ… Model 16 complete!
   Raw Entropy: 10.5938 H
   Normalized:  90.1% of max
   Best Text: ' Kim []( ÑƒÑ‡ĞµĞ± ):<|reserved_special_token_51|> ri'...
   Global Best: 95.6% (gpt2-large)
   ğŸ§¹ Memory cleaned up
======================================================================
ğŸ”„ [17/35] Iter 3, Model 3/7: microsoft/phi-2
======================================================================
Loading model: microsoft/phi-2
  ğŸ“¦ Using 4-bit quantization (memory efficient)
Loadingâ€‡checkpointâ€‡shards:â€‡100%
â€‡2/2â€‡[00:26<00:00,â€‡11.16s/it]
âœ… Model loaded: microsoft/phi-2
  Vocabulary size: 50295
  GPU Memory: 1.71 GB allocated, 6.82 GB reserved
ğŸ”¬ RareTokenMiner initialized for vocab size: 50295
ğŸ“Œ Strategy: ğŸ° POPULATION SAMPLE (rank #1, 95.6% from gpt2-large)

ğŸ¯ Running GCG optimization on microsoft/phi-2...
   Parameters: length=16, steps=50, top_k=256
   Multi-sample verification: 10 samples
GCGâ€‡Optimizing:â€‡100%
â€‡50/50â€‡[01:29<00:00,â€‡â€‡1.75s/it,â€‡H=9.71,â€‡H%=89.7%,â€‡best%=90.1%]
ğŸ”¬ Verifying final entropy with 10 samples...
   Single-pass entropy:  9.7578
   Verified mean:        9.7578 Â± 0.0000
   Verified range:       [9.7578, 9.7578]
   Verified normalized:  90.1%

âœ… GCG Optimization complete for microsoft/phi-2!
  Best Entropy: 9.7578
  Best Text: 'listPH GOP spacious degradation moltenFrank volunt'...

======================================================================
TESTING PROMPTS FOR microsoft/phi-2
======================================================================
  Test            |  Entropy | Flags | Response Preview
  ------------------------------------------------------------
  garbage_1       | H=  5.25 | [-   ] | ' said John."Yes, but we must be careful not to d'...
  hallucination_1 | H=  5.47 | [N   ] | 'O, the state agency for the promotion of arts and '...
  repetition_1    | H=  5.06 | [-   ] | 'js[0].shape[0]        )    )    # Create an em'...
  repetition_2    | H=  2.32 | [N   ] | 'Â¢Ã¢â€šÂ¬Ã‚Â¡ in which some are more important than other'...
  bizarre_1       | H=  6.30 | [-   ] | 'Exercise 3: How can the knowledge of capital let'...
  ------------------------------------------------------------
  GCG Optimized   | H=  9.76 | [N   ] | ' Griefs\' contributionsDuckworth\'s "Inconvenient T'...
======================================================================
 
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š ENTROPY COMPARISON SUMMARY - microsoft/phi-2
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test               â”‚    Entropy â”‚ Flags    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ bizarre_1          â”‚     6.3047 â”‚ -        â”‚
â”‚ hallucination_1    â”‚     5.4688 â”‚ N        â”‚
â”‚ garbage_1          â”‚     5.2539 â”‚ -        â”‚
â”‚ repetition_1       â”‚     5.0586 â”‚ -        â”‚
â”‚ repetition_2       â”‚     2.3242 â”‚ N        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ† GCG OPTIMIZED    â”‚     9.7578 â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
ğŸš€ GCG improvement over best baseline: +3.4531
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“ GCG OPTIMIZED PROMPT (Full)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
INPUT:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ listPH GOP spacious degradation moltenFrank volunteered Labor"800 Wildcats â”‚
â”‚ isSpecialOrderable  stretching                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
RESPONSE (Entropy: 9.7578):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Griefs' contributions
Duckworth's "Inconvenient Truth" â€“ The Last Trumpet â”‚
â”‚  for a New World Order?
"If you are not angry, you are not paying attentio â”‚
â”‚ n. If you are not paying attention, you are not listening." -- Donald Trum â”‚
â”‚ p, 1996
A recent series of events and news stories over the past few month â”‚
â”‚ s have led me to believe that we are approaching an "Inconvenient Truth" f â”‚
â”‚ or the world.
One of the most disturbing aspects of                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Corruption Flags: ['nonsense']
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ… Model 17 complete!
   Raw Entropy: 9.7578 H
   Normalized:  90.1% of max
   Best Text: 'listPH GOP spacious degradation moltenFrank volunt'...
   Global Best: 95.6% (gpt2-large)
   ğŸ§¹ Memory cleaned up
======================================================================
ğŸ”„ [18/35] Iter 3, Model 4/7: Qwen/Qwen2-1.5B
======================================================================
Loading model: Qwen/Qwen2-1.5B
  ğŸ“¦ Using 4-bit quantization (memory efficient)
âœ… Model loaded: Qwen/Qwen2-1.5B
  Vocabulary size: 151646
  GPU Memory: 1.09 GB allocated, 6.76 GB reserved
ğŸ”¬ RareTokenMiner initialized for vocab size: 151646
ğŸ“Œ Strategy: ğŸ° POPULATION SAMPLE (rank #2, 95.6% from gpt2-large)

ğŸ¯ Running GCG optimization on Qwen/Qwen2-1.5B...
   Parameters: length=16, steps=50, top_k=256
   Multi-sample verification: 10 samples
GCGâ€‡Optimizing:â€‡100%
â€‡50/50â€‡[01:02<00:00,â€‡â€‡1.24s/it,â€‡H=11.03,â€‡H%=92.5%,â€‡best%=92.8%]
ğŸ”¬ Verifying final entropy with 10 samples...
   Single-pass entropy:  11.0703
   Verified mean:        11.0703 Â± 0.0000
   Verified range:       [11.0703, 11.0703]
   Verified normalized:  92.8%

âœ… GCG Optimization complete for Qwen/Qwen2-1.5B!
  Best Entropy: 11.0703
  Best Text: 'uffix meticulously Majesty Jagu involvement disrup'...

======================================================================
TESTING PROMPTS FOR Qwen/Qwen2-1.5B
======================================================================
  Test            |  Entropy | Flags | Response Preview
  ------------------------------------------------------------
  garbage_1       | H=  6.75 | [GR  ] | ' ",",",",",",",",",",",",",",",",",",",",",",",","'...
  hallucination_1 | H=  5.76 | [N   ] | 'Ã“W, Andrzej (1928-2000) was a prominent Polish arc'...
  repetition_1    | H=  9.66 | [R   ] | ' cherries 1000000000000000000000000000000000000000'...
  repetition_2    | H=  9.61 | [GRN ] | ',ÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒ'...
  bizarre_1       | H=  7.12 | [GRN ] | '\u200d= âˆ‚âˆ† âˆ‚Î± âˆ‚âˆ‚âˆ‚ âˆ‚âˆ‚âˆ‚ âˆ‚âˆ‚âˆ‚ âˆ‚âˆ‚âˆ‚ âˆ‚âˆ‚âˆ‚ âˆ‚âˆ‚âˆ‚ âˆ‚âˆ‚âˆ‚ âˆ‚âˆ‚âˆ‚ âˆ‚âˆ‚âˆ‚ âˆ‚âˆ‚âˆ‚ âˆ‚'...
  ------------------------------------------------------------
  GCG Optimized   | H= 11.07 | [GRN ] | '???????????????????????????????\t\t# \t#\t#\t#\t#\t#\t#\t#'...
======================================================================
 
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š ENTROPY COMPARISON SUMMARY - Qwen/Qwen2-1.5B
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test               â”‚    Entropy â”‚ Flags    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ repetition_1       â”‚     9.6641 â”‚ R        â”‚
â”‚ repetition_2       â”‚     9.6094 â”‚ GRN      â”‚
â”‚ bizarre_1          â”‚     7.1211 â”‚ GRN      â”‚
â”‚ garbage_1          â”‚     6.7539 â”‚ GR       â”‚
â”‚ hallucination_1    â”‚     5.7617 â”‚ N        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ† GCG OPTIMIZED    â”‚    11.0703 â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
ğŸš€ GCG improvement over best baseline: +1.4062
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“ GCG OPTIMIZED PROMPT (Full)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
INPUT:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ uffix meticulously Majesty Jagu involvement disruptingèˆbindParam entrepren â”‚
â”‚ eurs	clientÒªå¢’æµ‹ç®—à¹€à¸™Ãƒ                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
RESPONSE (Entropy: 11.0703):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ???????????????????????????????
		# 	#	#	#	#	#	#	#	#	#	#	#	#	#	#	#	#	#	#	# â”‚
â”‚ 	#	#	#	#	#	#	#	#	#	#	#	#	#	#	#	#	#	#	#	#	#	#	#	#	                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Corruption Flags: ['garbage', 'repetition', 'nonsense']
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ… Model 18 complete!
   Raw Entropy: 11.0703 H
   Normalized:  92.8% of max
   Best Text: 'uffix meticulously Majesty Jagu involvement disrup'...
   Global Best: 95.6% (gpt2-large)
   ğŸ§¹ Memory cleaned up
======================================================================
ğŸ”„ [19/35] Iter 3, Model 5/7: gpt2-large
======================================================================
Loading model: gpt2-large
  ğŸ“¦ Using 4-bit quantization (memory efficient)
âœ… Model loaded: gpt2-large
  Vocabulary size: 50257
  GPU Memory: 0.54 GB allocated, 6.80 GB reserved
ğŸ”¬ RareTokenMiner initialized for vocab size: 50257
ğŸ“Œ Strategy: ğŸ”ï¸ GLOBAL BEST (95.6% from gpt2-large)

ğŸ¯ Running GCG optimization on gpt2-large...
   Parameters: length=16, steps=50, top_k=256
   Multi-sample verification: 10 samples
GCGâ€‡Optimizing:â€‡100%
â€‡50/50â€‡[00:37<00:00,â€‡â€‡1.33it/s,â€‡H=10.38,â€‡H%=95.9%,â€‡best%=95.9%]
ğŸ”¬ Verifying final entropy with 10 samples...
   Single-pass entropy:  10.3828
   Verified mean:        10.3828 Â± 0.0000
   Verified range:       [10.3828, 10.3828]
   Verified normalized:  95.9%

âœ… GCG Optimization complete for gpt2-large!
  Best Entropy: 10.3828
  Best Text: ' Starg Summoner Govern spacious sauces pressuredCO'...

======================================================================
TESTING PROMPTS FOR gpt2-large
======================================================================
  Test            |  Entropy | Flags | Response Preview
  ------------------------------------------------------------
  garbage_1       | H=  1.13 | [GR  ] | ',",",",",",", ",",",",#",#",",",#",",#",",",#",",#'...
  hallucination_1 | H=  5.80 | [N   ] | 'Ä…Å¼, SÅ‚oczukieÅ„, Polska, Å»ydowicz, KrakÃ³w, and ÅÃ³dÅº'...
  repetition_1    | H=  0.77 | [GR  ] | 'obobobobobobobobobobobobobobobobobobobobobobobobob'...
  repetition_2    | H=  3.27 | [N   ] | "Ãƒ'Ã‚, in the city of Palermo, Italy, on November 9,"...
  bizarre_1       | H=  6.48 | [N   ] | 'then\u200dâˆ‘âˆ‚louisiana\u200dâ˜º\u200dâˆštoledo\u200dâ˜º\u200dâˆšuam\u200dâ˜º\u200dâˆšmichigan\u200dâ˜º\u200dâˆšw'...
  ------------------------------------------------------------
  GCG Optimized   | H=  9.99 | [RN  ] | 'o ezkom kunfugzkim EZKOM kunfugzkim BABY BABY BABY'...
======================================================================
   ğŸ† NEW GLOBAL BEST!
      Raw: 10.3828 H (+0.0312)
      Normalized: 95.92% (+0.29%)
 
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š ENTROPY COMPARISON SUMMARY - gpt2-large
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test               â”‚    Entropy â”‚ Flags    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ bizarre_1          â”‚     6.4805 â”‚ N        â”‚
â”‚ hallucination_1    â”‚     5.8047 â”‚ N        â”‚
â”‚ repetition_2       â”‚     3.2676 â”‚ N        â”‚
â”‚ garbage_1          â”‚     1.1289 â”‚ GR       â”‚
â”‚ repetition_1       â”‚     0.7715 â”‚ GR       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ† GCG OPTIMIZED    â”‚    10.3828 â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
ğŸš€ GCG improvement over best baseline: +3.9023
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“ GCG OPTIMIZED PROMPT (Full)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
INPUT:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Starg Summoner Govern spacious sauces pressuredCOMPLE EllisonexternalActi â”‚
â”‚ onCode carbohydĞµ Wildcats partName  stretchingThumbnailImage               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
RESPONSE (Entropy: 9.9922):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ o ezkom kunfugzkim EZKOM kunfugzkim BABY BABY BABY BABY BABY BABY BABY BAB â”‚
â”‚ Y BABY BABY BABY BABY BABY BABY BABY BABY BABY BABY BABY BABY BABY BABY BA â”‚
â”‚ BY BABY BABY BAB                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Corruption Flags: ['repetition', 'nonsense']
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ… Model 19 complete!
   Raw Entropy: 10.3828 H
   Normalized:  95.9% of max
   Best Text: ' Starg Summoner Govern spacious sauces pressuredCO'...
   Global Best: 95.9% (gpt2-large)
   ğŸ§¹ Memory cleaned up
======================================================================
ğŸ”„ [20/35] Iter 3, Model 6/7: TinyLlama/TinyLlama-1.1B-Chat-v1.0
======================================================================
Loading model: TinyLlama/TinyLlama-1.1B-Chat-v1.0
  ğŸ“¦ Using 4-bit quantization (memory efficient)
âœ… Model loaded: TinyLlama/TinyLlama-1.1B-Chat-v1.0
  Vocabulary size: 32000
  GPU Memory: 0.74 GB allocated, 6.76 GB reserved
ğŸ”¬ RareTokenMiner initialized for vocab size: 32000
ğŸ“Œ Strategy: ğŸ° POPULATION SAMPLE (rank #3, 95.6% from gpt2-large)

ğŸ¯ Running GCG optimization on TinyLlama/TinyLlama-1.1B-Chat-v1.0...
   Parameters: length=16, steps=50, top_k=256
   Multi-sample verification: 10 samples
GCGâ€‡Optimizing:â€‡100%
â€‡50/50â€‡[00:45<00:00,â€‡â€‡1.06it/s,â€‡H=9.08,â€‡H%=87.5%,â€‡best%=88.2%]
ğŸ”¬ Verifying final entropy with 10 samples...
   Single-pass entropy:  9.1484
   Verified mean:        9.1484 Â± 0.0000
   Verified range:       [9.1484, 9.1484]
   Verified normalized:  88.2%

âœ… GCG Optimization complete for TinyLlama/TinyLlama-1.1B-Chat-v1.0!
  Best Entropy: 9.1484
  Best Text: 'å…³isecondsawait bitfontsiouslyAmount Jagu jewelstre'...

======================================================================
TESTING PROMPTS FOR TinyLlama/TinyLlama-1.1B-Chat-v1.0
======================================================================
  Test            |  Entropy | Flags | Response Preview
  ------------------------------------------------------------
  garbage_1       | H=  4.19 | [GR  ] | '@","@",",",",",",",",",",",","@","@",",",",",",","'...
  hallucination_1 | H=  6.10 | [N   ] | 'E ÃƒÅ• <|system|><|user|>Write a 5-line story abou'...
  repetition_1    | H=  0.69 | [R   ] | 'obobobobobobobobobobobobobobobobobobobobobobobobob'...
  repetition_2    | H=  0.12 | [GRN ] | 'ÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒ'...
  bizarre_1       | H=  6.31 | [RN  ] | '\u200b|\u200bGwashington|\u200bWashington|\u200bGwashington|\u200bWash'...
  ------------------------------------------------------------
  GCG Optimized   | H=  8.59 | [N   ] | 'loopedpainted æ¯’æ©™æ¨è¤è”¥æŠ¼å¿½é”¯å¼ç„™ å¿½ç„™ç„™ç„™æŠ¼å¼æŠ¼å¿½æŸ”ç„™ç„™ç„™ç„™æŠ¼å¿½æŸ”ç„™ç„™ç„™æŠ¼å¿½'
======================================================================
 
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š ENTROPY COMPARISON SUMMARY - TinyLlama/TinyLlama-1.1B-Chat-v1.0
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test               â”‚    Entropy â”‚ Flags    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ bizarre_1          â”‚     6.3086 â”‚ RN       â”‚
â”‚ hallucination_1    â”‚     6.0977 â”‚ N        â”‚
â”‚ garbage_1          â”‚     4.1875 â”‚ GR       â”‚
â”‚ repetition_1       â”‚     0.6851 â”‚ R        â”‚
â”‚ repetition_2       â”‚     0.1248 â”‚ GRN      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ† GCG OPTIMIZED    â”‚     9.1484 â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
ğŸš€ GCG improvement over best baseline: +2.8398
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“ GCG OPTIMIZED PROMPT (Full)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
INPUT:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ å…³isecondsawait bitfontsiouslyAmount Jagu jewelstre election clone nested   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
RESPONSE (Entropy: 8.5859):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ loopedpainted æ¯’æ©™æ¨è¤è”¥æŠ¼å¿½é”¯å¼ç„™ å¿½ç„™ç„™ç„™æŠ¼å¼æŠ¼å¿½æŸ”ç„™ç„™ç„™ç„™æŠ¼å¿½æŸ”ç„™ç„™ç„™æŠ¼å¿½                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Corruption Flags: ['nonsense']
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ… Model 20 complete!
   Raw Entropy: 9.1484 H
   Normalized:  88.2% of max
   Best Text: 'å…³isecondsawait bitfontsiouslyAmount Jagu jewelstre'...
   Global Best: 95.9% (gpt2-large)
   ğŸ§¹ Memory cleaned up
======================================================================
ğŸ”„ [21/35] Iter 3, Model 7/7: bigscience/bloom-1b1
======================================================================
Loading model: bigscience/bloom-1b1
  ğŸ“¦ Using 4-bit quantization (memory efficient)
âœ… Model loaded: bigscience/bloom-1b1
  Vocabulary size: 250680
  GPU Memory: 1.06 GB allocated, 6.75 GB reserved
ğŸ”¬ RareTokenMiner initialized for vocab size: 250680
ğŸ“Œ Strategy: ğŸ§¬ PERTURBED BEST (6 mutations to 95.9%)

ğŸ¯ Running GCG optimization on bigscience/bloom-1b1...
   Parameters: length=16, steps=50, top_k=256
   Multi-sample verification: 10 samples
GCGâ€‡Optimizing:â€‡100%
â€‡50/50â€‡[00:43<00:00,â€‡â€‡1.16it/s,â€‡H=11.73,â€‡H%=94.3%,â€‡best%=94.8%]
ğŸ”¬ Verifying final entropy with 10 samples...
   Single-pass entropy:  11.7891
   Verified mean:        11.7891 Â± 0.0000
   Verified range:       [11.7891, 11.7891]
   Verified normalized:  94.8%

âœ… GCG Optimization complete for bigscience/bloom-1b1!
  Best Entropy: 11.7891
  Best Text: 'uenzaÃ¢niaå£æ°´à´Ÿàµà´Ÿer BatalÆ°u à¤­à¤°à¤ªà¥‚à¤° ngoÃ iastas pressure'...

======================================================================
TESTING PROMPTS FOR bigscience/bloom-1b1
======================================================================
  Test            |  Entropy | Flags | Response Preview
  ------------------------------------------------------------
  garbage_1       | H=  0.24 | [GR  ] | ',",",",",",",",",",",",",",",",",",",",",",",",","'...
  hallucination_1 | H=  7.39 | [GRN ] | 'ÃƒÅ‚ÃƒÅ‚ÃƒÅ‚ÃƒÅ‚ÃƒÅ‚ÃƒÅ‚ÃƒÅ‚ÃƒÅ‚ÃƒÅ‚ÃƒÅ‚ÃƒÅ‚ÃƒÅ‚ÃƒÅ‚ÃƒÅ‚ÃƒÅ‚ÃƒÅ‚ÃƒÅ‚ÃƒÅ‚ÃƒÅ‚ÃƒÅ‚ÃƒÅ‚ÃƒÅ‚ÃƒÅ‚ÃƒÅ‚ÃƒÅ‚'...
  repetition_1    | H=  8.48 | [-   ] | '.getMaxHeight() + 1, maxHeight);    }}'
  repetition_2    | H=  8.06 | [N   ] | ') = H* (V, u) where V is a real vector space of a'...
  bizarre_1       | H=  7.70 | [N   ] | 'âˆ‚Ä washingtonâˆ‚Ä washingtonâˆ‚Ä washingtonâˆ‚Ä washingtonâˆ‚Ä '...
  ------------------------------------------------------------
  GCG Optimized   | H= 11.79 | [N   ] | ' trupulaÃ­ laÃ­ I.4.3.1.1.2Les premiers documents d'...
======================================================================
 
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š ENTROPY COMPARISON SUMMARY - bigscience/bloom-1b1
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test               â”‚    Entropy â”‚ Flags    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ repetition_1       â”‚     8.4766 â”‚ -        â”‚
â”‚ repetition_2       â”‚     8.0625 â”‚ N        â”‚
â”‚ bizarre_1          â”‚     7.6992 â”‚ N        â”‚
â”‚ hallucination_1    â”‚     7.3867 â”‚ GRN      â”‚
â”‚ garbage_1          â”‚     0.2356 â”‚ GR       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ† GCG OPTIMIZED    â”‚    11.7891 â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
ğŸš€ GCG improvement over best baseline: +3.3125
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“ GCG OPTIMIZED PROMPT (Full)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
INPUT:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ uenzaÃ¢niaå£æ°´à´Ÿàµà´Ÿer BatalÆ°u à¤­à¤°à¤ªà¥‚à¤° ngoÃ iastas pressured fÃ©liciteræœƒ ChiÃªuà¦¦à¦¾à¦°à¦¿   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
RESPONSE (Entropy: 11.7891):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  trupulaÃ­ laÃ­ I.4.3.1.1.2
Les premiers documents du vocabulaire de la chas â”‚
â”‚ se concernent la chasse Ã  la couleuvre. En effet, les premiÃ¨res mentions d â”‚
â”‚ e la chasse Ã  la couleuvre apparaissent au IXe siÃ¨cle dans le traitÃ© de Bo â”‚
â”‚ uvet, qui mentionne un projet de chasse Ã  la couleuvre. Le traitÃ© mentionn â”‚
â”‚ e Ã©galement la possibilitÃ© de se rendre en forÃªt pour chasser. Le traitÃ© e â”‚
â”‚ st rÃ©digÃ© en latin, qui est donc la langue du traitÃ© et                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Corruption Flags: ['nonsense']
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ… Model 21 complete!
   Raw Entropy: 11.7891 H
   Normalized:  94.8% of max
   Best Text: 'uenzaÃ¢niaå£æ°´à´Ÿàµà´Ÿer BatalÆ°u à¤­à¤°à¤ªà¥‚à¤° ngoÃ iastas pressure'...
   Global Best: 95.9% (gpt2-large)
   ğŸ§¹ Memory cleaned up
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~ ITERATION 3 COMPLETE ~~~
    Models processed this iteration: 7
    Current best entropy: 10.3828
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
######################################################################
### ITERATION 4/5
### Model Order: ['Meta-Llama-3-8B-Instruct', 'gpt-neo-1.3B', 'phi-2', 'bloom-1b1', 'Qwen2-1.5B', 'TinyLlama-1.1B-Chat-v1.0', 'gpt2-large']
######################################################################
======================================================================
ğŸ”„ [22/35] Iter 4, Model 1/7: meta-llama/Meta-Llama-3-8B-Instruct
======================================================================
Loading model: meta-llama/Meta-Llama-3-8B-Instruct
  ğŸ“¦ Using 4-bit quantization (memory efficient)
Loadingâ€‡checkpointâ€‡shards:â€‡100%
â€‡4/4â€‡[01:13<00:00,â€‡15.95s/it]
âœ… Model loaded: meta-llama/Meta-Llama-3-8B-Instruct
  Vocabulary size: 128256
  GPU Memory: 5.33 GB allocated, 6.83 GB reserved
ğŸ”¬ RareTokenMiner initialized for vocab size: 128256
ğŸ“Œ Strategy: ğŸ”ï¸ GLOBAL BEST (95.9% from gpt2-large)

ğŸ¯ Running GCG optimization on meta-llama/Meta-Llama-3-8B-Instruct...
   Parameters: length=16, steps=50, top_k=256
   Multi-sample verification: 10 samples
GCGâ€‡Optimizing:â€‡100%
â€‡50/50â€‡[03:42<00:00,â€‡â€‡4.44s/it,â€‡H=10.64,â€‡H%=90.5%,â€‡best%=90.9%]
ğŸ”¬ Verifying final entropy with 10 samples...
   Single-pass entropy:  10.6953
   Verified mean:        10.6953 Â± 0.0000
   Verified range:       [10.6953, 10.6953]
   Verified normalized:  90.9%

âœ… GCG Optimization complete for meta-llama/Meta-Llama-3-8B-Instruct!
  Best Entropy: 10.6953
  Best Text: ' St profitability Summon.pausedë¶„ì„ spacious Sophie '...

======================================================================
TESTING PROMPTS FOR meta-llama/Meta-Llama-3-8B-Instruct
======================================================================
  Test            |  Entropy | Flags | Response Preview
  ------------------------------------------------------------
  garbage_1       | H=  6.05 | [GR  ] | '@",",",",",",",",",",",",",",",",",",",",",",","@"'...
  hallucination_1 | H=  7.35 | [N   ] | ', an artist known for his unique and captivating v'...
  repetition_1    | H=  2.36 | [N   ] | '"obobobobobobobobobob" is not a valid entry. Coul'...
  repetition_2    | H=  2.54 | [GRN ] | 'ÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒ'...
  bizarre_1       | H=  6.89 | [N   ] | 'The Washington Monument stands tall in Washington'...
  ------------------------------------------------------------
  GCG Optimized   | H= 10.21 | [RN  ] | ' 1 14.0 14.5 1 14.0 14.5 1 14.0 14.5 1 14.0 14.5 1'...
======================================================================
 
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š ENTROPY COMPARISON SUMMARY - meta-llama/Meta-Llama-3-8B-Instruct
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test               â”‚    Entropy â”‚ Flags    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ hallucination_1    â”‚     7.3516 â”‚ N        â”‚
â”‚ bizarre_1          â”‚     6.8906 â”‚ N        â”‚
â”‚ garbage_1          â”‚     6.0469 â”‚ GR       â”‚
â”‚ repetition_2       â”‚     2.5430 â”‚ GRN      â”‚
â”‚ repetition_1       â”‚     2.3594 â”‚ N        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ† GCG OPTIMIZED    â”‚    10.6953 â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
ğŸš€ GCG improvement over best baseline: +3.3438
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“ GCG OPTIMIZED PROMPT (Full)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
INPUT:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  St profitability Summon.pausedë¶„ì„ spacious Sophie lobbyists handfulNEW Ell â”‚
â”‚ isonCÃ¡ch carbo marbleTyped                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
RESPONSE (Entropy: 10.2109):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1 14.0 14.5 1 14.0 14.5 1 14.0 14.5 1 14.0 14.5 1 14.0 14.5 1 14.0 14.5 1 â”‚
â”‚  14.0 14.5 1 14.0 14.5 1 14.0 14.5 1 14.0 14.5                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Corruption Flags: ['repetition', 'nonsense']
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ… Model 22 complete!
   Raw Entropy: 10.6953 H
   Normalized:  90.9% of max
   Best Text: ' St profitability Summon.pausedë¶„ì„ spacious Sophie '...
   Global Best: 95.9% (gpt2-large)
   ğŸ§¹ Memory cleaned up
======================================================================
ğŸ”„ [23/35] Iter 4, Model 2/7: EleutherAI/gpt-neo-1.3B
======================================================================
Loading model: EleutherAI/gpt-neo-1.3B
  ğŸ“¦ Using 4-bit quantization (memory efficient)
âœ… Model loaded: EleutherAI/gpt-neo-1.3B
  Vocabulary size: 50257
  GPU Memory: 0.89 GB allocated, 6.82 GB reserved
ğŸ”¬ RareTokenMiner initialized for vocab size: 50257
ğŸ“Œ Strategy: ğŸ° POPULATION SAMPLE (rank #3, 95.6% from gpt2-large)

ğŸ¯ Running GCG optimization on EleutherAI/gpt-neo-1.3B...
   Parameters: length=16, steps=50, top_k=256
   Multi-sample verification: 10 samples
GCGâ€‡Optimizing:â€‡100%
â€‡50/50â€‡[00:53<00:00,â€‡â€‡1.07s/it,â€‡H=9.81,â€‡H%=90.6%,â€‡best%=90.7%]
ğŸ”¬ Verifying final entropy with 10 samples...
   Single-pass entropy:  9.8203
   Verified mean:        9.8125 Â± 0.0000
   Verified range:       [9.8125, 9.8125]
   Verified normalized:  90.6%

âœ… GCG Optimization complete for EleutherAI/gpt-neo-1.3B!
  Best Entropy: 9.8125
  Best Text: ' Crate Journals skelet Radiant evangelicals resett'...

======================================================================
TESTING PROMPTS FOR EleutherAI/gpt-neo-1.3B
======================================================================
  Test            |  Entropy | Flags | Response Preview
  ------------------------------------------------------------
  garbage_1       | H=  0.82 | [GR  ] | ',",",",",",",",",",",",",",",",",",",",",",",",","'...
  hallucination_1 | H=  5.65 | [N   ] | '<Jakub> tak, to wiesz...<Jakub> chociaz... wszys'...
  repetition_1    | H=  0.59 | [GR  ] | 'obobobobobobobobobobobobobobobobobobobobobobobobob'...
  repetition_2    | H=  1.44 | [GRN ] | 'ÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒ'...
  bizarre_1       | H=  4.34 | [GRN ] | 'ÅÄªzÅÅÅÅÅÅÅÅÅÅÅÅÅÅÅÅÅÅÅÅÅÅÅÅÅÅÅÅÅÅÅÅÅÅÅÅÅÅÅÅÅÅÅÅÅÅÅ'...
  ------------------------------------------------------------
  GCG Optimized   | H=  9.59 | [RN  ] | 'ness(s) of life aplomb(s) of your time(s) aplomb(s'...
======================================================================
 
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š ENTROPY COMPARISON SUMMARY - EleutherAI/gpt-neo-1.3B
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test               â”‚    Entropy â”‚ Flags    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ hallucination_1    â”‚     5.6523 â”‚ N        â”‚
â”‚ bizarre_1          â”‚     4.3398 â”‚ GRN      â”‚
â”‚ repetition_2       â”‚     1.4385 â”‚ GRN      â”‚
â”‚ garbage_1          â”‚     0.8159 â”‚ GR       â”‚
â”‚ repetition_1       â”‚     0.5894 â”‚ GR       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ† GCG OPTIMIZED    â”‚     9.8125 â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
ğŸš€ GCG improvement over best baseline: +4.1602
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“ GCG OPTIMIZED PROMPT (Full)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
INPUT:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Crate Journals skelet Radiant evangelicals resettlementRIPT  Cornwall com â”‚
â”‚ plicitĞµ Tornado Boise procurement Sparksfriendly                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
RESPONSE (Entropy: 9.5938):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ness(s) of life aplomb(s) of your time(s) aplomb(s) of your time(s) aplomb â”‚
â”‚ (s) of your time(s) aplomb(s) of your time(s) aplomb(s) of your time(s) ap â”‚
â”‚ lomb(s) of your time(s) aplomb(s) of your time(s) aplomb(s) of your time(  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Corruption Flags: ['repetition', 'nonsense']
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ… Model 23 complete!
   Raw Entropy: 9.8125 H
   Normalized:  90.6% of max
   Best Text: ' Crate Journals skelet Radiant evangelicals resett'...
   Global Best: 95.9% (gpt2-large)
   ğŸ§¹ Memory cleaned up
======================================================================
ğŸ”„ [24/35] Iter 4, Model 3/7: microsoft/phi-2
======================================================================
Loading model: microsoft/phi-2
  ğŸ“¦ Using 4-bit quantization (memory efficient)
Loadingâ€‡checkpointâ€‡shards:â€‡100%
â€‡2/2â€‡[00:27<00:00,â€‡11.88s/it]
âœ… Model loaded: microsoft/phi-2
  Vocabulary size: 50295
  GPU Memory: 1.71 GB allocated, 6.76 GB reserved
ğŸ”¬ RareTokenMiner initialized for vocab size: 50295
ğŸ“Œ Strategy: ğŸ² RANDOM RESTART - exploring new territory!

ğŸ¯ Running GCG optimization on microsoft/phi-2...
   Parameters: length=16, steps=50, top_k=256
   Multi-sample verification: 10 samples
GCGâ€‡Optimizing:â€‡100%
â€‡50/50â€‡[01:26<00:00,â€‡â€‡1.76s/it,â€‡H=9.91,â€‡H%=91.5%,â€‡best%=92.1%]
ğŸ”¬ Verifying final entropy with 10 samples...
   Single-pass entropy:  9.9688
   Verified mean:        9.9688 Â± 0.0000
   Verified range:       [9.9688, 9.9688]
   Verified normalized:  92.1%

âœ… GCG Optimization complete for microsoft/phi-2!
  Best Entropy: 9.9688
  Best Text: ' MED wealth activeJamie RealmsOSED flickering Expa'...

======================================================================
TESTING PROMPTS FOR microsoft/phi-2
======================================================================
  Test            |  Entropy | Flags | Response Preview
  ------------------------------------------------------------
  garbage_1       | H=  5.25 | [-   ] | ' said Professor John W. Seddon, MD, from the Unive'...
  hallucination_1 | H=  5.47 | [N   ] | 'Ã‡ÃœÃšÃ‹The European Union (EU) is well-known for its'...
  repetition_1    | H=  5.06 | [-   ] | 'servations = 0            self.reward = 0       '...
  repetition_2    | H=  2.32 | [N   ] | 'Â¢Ã¢â€œs.If you want to go back to the early days of '...
  bizarre_1       | H=  6.30 | [GRN ] | ' âˆ†âˆ† âˆ†âˆ† âˆ†âˆ†    âˆ†âˆ† âˆ†âˆ† âˆ†âˆ† âˆ†âˆ† âˆ†âˆ† âˆ†âˆ† âˆ†âˆ†âˆ†âˆ†âˆ†âˆ†âˆ†âˆ†âˆ†âˆ†âˆ†âˆ†âˆ†âˆ†âˆ†âˆ†âˆ†âˆ†'...
  ------------------------------------------------------------
  GCG Optimized   | H=  9.97 | [N   ] | "BoldfaceMARC'Answer: 0.02652. Use the function "...
======================================================================
 
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š ENTROPY COMPARISON SUMMARY - microsoft/phi-2
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test               â”‚    Entropy â”‚ Flags    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ bizarre_1          â”‚     6.3047 â”‚ GRN      â”‚
â”‚ hallucination_1    â”‚     5.4688 â”‚ N        â”‚
â”‚ garbage_1          â”‚     5.2539 â”‚ -        â”‚
â”‚ repetition_1       â”‚     5.0586 â”‚ -        â”‚
â”‚ repetition_2       â”‚     2.3242 â”‚ N        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ† GCG OPTIMIZED    â”‚     9.9688 â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
ğŸš€ GCG improvement over best baseline: +3.6641
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“ GCG OPTIMIZED PROMPT (Full)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
INPUT:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MED wealth activeJamie RealmsOSED flickering Expansion Babel waterways wi â”‚
â”‚ despreadJM 433 Locke use inflicting                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
RESPONSE (Entropy: 9.9688):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ BoldfaceMARC'
Answer: 0.0265

2. Use the function above to find the Flesch â”‚
â”‚ -Kincaid Grade Level for the following text: "The quick brown fox jumped o â”‚
â”‚ ver the lazy dog."

Answer: 3.3

3. Use the function above to find the Gun â”‚
â”‚ ning Fog Index for the following text: "Lorem ipsum dolor sit amet, consec â”‚
â”‚ tetur adipiscing elit. Sed nec                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Corruption Flags: ['nonsense']
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ… Model 24 complete!
   Raw Entropy: 9.9688 H
   Normalized:  92.1% of max
   Best Text: ' MED wealth activeJamie RealmsOSED flickering Expa'...
   Global Best: 95.9% (gpt2-large)
   ğŸ§¹ Memory cleaned up
======================================================================
ğŸ”„ [25/35] Iter 4, Model 4/7: bigscience/bloom-1b1
======================================================================
Loading model: bigscience/bloom-1b1
  ğŸ“¦ Using 4-bit quantization (memory efficient)
âœ… Model loaded: bigscience/bloom-1b1
  Vocabulary size: 250680
  GPU Memory: 1.06 GB allocated, 6.76 GB reserved
ğŸ”¬ RareTokenMiner initialized for vocab size: 250680
ğŸ“Œ Strategy: ğŸ§¬ PERTURBED BEST (6 mutations to 95.9%)

ğŸ¯ Running GCG optimization on bigscience/bloom-1b1...
   Parameters: length=16, steps=50, top_k=256
   Multi-sample verification: 10 samples
GCGâ€‡Optimizing:â€‡100%
â€‡50/50â€‡[00:42<00:00,â€‡â€‡1.20it/s,â€‡H=11.23,â€‡H%=90.4%,â€‡best%=91.1%]
ğŸ”¬ Verifying final entropy with 10 samples...
   Single-pass entropy:  11.3203
   Verified mean:        11.3203 Â± 0.0000
   Verified range:       [11.3203, 11.3203]
   Verified normalized:  91.1%

âœ… GCG Optimization complete for bigscience/bloom-1b1!
  Best Entropy: 11.3203
  Best Text: ' Prefargmetalç—‡ inappropri Ø§Ù†Ù‚Ù„Ø§Ø¨ mengimbauious Hun'...

======================================================================
TESTING PROMPTS FOR bigscience/bloom-1b1
======================================================================
  Test            |  Entropy | Flags | Response Preview
  ------------------------------------------------------------
  garbage_1       | H=  0.24 | [GR  ] | ',",",",",",",",",",",",",",",",",",",",",",",",","'...
  hallucination_1 | H=  7.39 | [N   ] | 'Ã“ÃƒÂ»\x82*/bool OGRGis::EvaluatePoint(OGRPoint & poin'...
  repetition_1    | H=  8.48 | [N   ] | 'ble. The two major differences are that the test i'...
  repetition_2    | H=  8.06 | [-   ] | ', 2);\t\t}\t\tint i, j;\t\tfor (i=0; i < this.numSta'...
  bizarre_1       | H=  7.70 | [GN  ] | 'Å½Æ‰Å½Å¶Ä‚ÄÆšÅ½Æ‰\x03Å½ÆµÆŒÆšÄ\x03ÄÆ\x03ÄÆš\x03Å½Å¶\x03Ä¨ÄÆŒÅµÆ‰Ä\x03Æ‰Ä‚ÆŒÆµÄ\x03ÆŒÄ ÆšÄ\x03ÆµÅ¶\x03Æ‰ÆŒÄÆŒ'...
  ------------------------------------------------------------
  GCG Optimized   | H= 11.32 | [N   ] | ' adjetivating. Deitianism in Hellenics and Latin, '...
======================================================================
 
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š ENTROPY COMPARISON SUMMARY - bigscience/bloom-1b1
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test               â”‚    Entropy â”‚ Flags    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ repetition_1       â”‚     8.4766 â”‚ N        â”‚
â”‚ repetition_2       â”‚     8.0625 â”‚ -        â”‚
â”‚ bizarre_1          â”‚     7.6992 â”‚ GN       â”‚
â”‚ hallucination_1    â”‚     7.3867 â”‚ N        â”‚
â”‚ garbage_1          â”‚     0.2356 â”‚ GR       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ† GCG OPTIMIZED    â”‚    11.3203 â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
ğŸš€ GCG improvement over best baseline: +2.8438
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“ GCG OPTIMIZED PROMPT (Full)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
INPUT:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Prefargmetalç—‡ inappropri Ø§Ù†Ù‚Ù„Ø§Ø¨ mengimbauious HungrÃ­aÃ§Ãµes avancÃ©esPROFike â”‚
â”‚ ç­‰å€™ Ellison                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
RESPONSE (Entropy: 11.3203):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  adjetivating. Deitianism in Hellenics and Latin, 16681680. The Oxford Uni â”‚
â”‚ versity Press, 2001. Vol. 13, p. 1-13. 19 A. B. M. V. M. L. G. R., op. cit â”‚
â”‚ ., p. 131-139. 20 Ibid., p. 141. 11 12
9
S. B. E., De la musique au thÃ©Ã¢tr â”‚
â”‚ e, Paris, Les Belles Lettres, 1972, p. 121-                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Corruption Flags: ['nonsense']
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ… Model 25 complete!
   Raw Entropy: 11.3203 H
   Normalized:  91.1% of max
   Best Text: ' Prefargmetalç—‡ inappropri Ø§Ù†Ù‚Ù„Ø§Ø¨ mengimbauious Hun'...
   Global Best: 95.9% (gpt2-large)
   ğŸ§¹ Memory cleaned up
======================================================================
ğŸ”„ [26/35] Iter 4, Model 5/7: Qwen/Qwen2-1.5B
======================================================================
Loading model: Qwen/Qwen2-1.5B
  ğŸ“¦ Using 4-bit quantization (memory efficient)
âœ… Model loaded: Qwen/Qwen2-1.5B
  Vocabulary size: 151646
  GPU Memory: 1.09 GB allocated, 6.75 GB reserved
ğŸ”¬ RareTokenMiner initialized for vocab size: 151646
ğŸ“Œ Strategy: ğŸ² RANDOM RESTART - exploring new territory!

ğŸ¯ Running GCG optimization on Qwen/Qwen2-1.5B...
   Parameters: length=16, steps=50, top_k=256
   Multi-sample verification: 10 samples
GCGâ€‡Optimizing:â€‡100%
â€‡50/50â€‡[00:59<00:00,â€‡â€‡1.23s/it,â€‡H=11.23,â€‡H%=94.1%,â€‡best%=95.1%]
ğŸ”¬ Verifying final entropy with 10 samples...
   Single-pass entropy:  11.3438
   Verified mean:        11.3438 Â± 0.0000
   Verified range:       [11.3438, 11.3438]
   Verified normalized:  95.1%

âœ… GCG Optimization complete for Qwen/Qwen2-1.5B!
  Best Entropy: 11.3438
  Best Text: 'å¯¤ sustainedå®¢äºº httpResponseğŸ”—â†ç§‰â½”å² appropriationà²® Glo'...

======================================================================
TESTING PROMPTS FOR Qwen/Qwen2-1.5B
======================================================================
  Test            |  Entropy | Flags | Response Preview
  ------------------------------------------------------------
  garbage_1       | H=  6.75 | [GRN ] | ' ","," "," "," "," "," "," "," "," "," "," "," ","'...
  hallucination_1 | H=  5.76 | [N   ] | 'SKI (pol. aleksiejewski) â€“ polski nazwisko pochodz'...
  repetition_1    | H=  9.66 | [GRN ] | 'å—«ç½—å¸ƒå¸ƒå¸ƒå¸ƒå•Šå•Šå•Šå•Šå•Šå•Šå•Šå•Šå•Šå•Šå•Šå•Šå•Šå•Šå•Šå•Šå•Šå•Šå•Šå•Šå•Šå•Šå•Šå•Šå•Šå•Šå•Šå•Šå•Šå•Šå•Šå•Šå•Šå•Šå•Šå•Šå•Šå•Šå•Šå•Šå•Šå•Šå•Šå•Š'...
  repetition_2    | H=  9.61 | [GRN ] | ', ÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒ'...
  bizarre_1       | H=  7.12 | [GN  ] | '[x\u200d +\u200d âˆ†-x\u200dâˆ’âˆš[x\u200d+1\u200d]=0.(1)\u200dâˆ‚\u200dâˆ‚x\u200df(x)\u200d=\u200d0.(2)\u200dâˆ‚\u200dâˆ‚'...
  ------------------------------------------------------------
  GCG Optimized   | H= 11.34 | [GN  ] | 'çš„ç—…ï¼Œæˆ‘è¿™ä¸€ä¸ªå¹´å¹´éƒ½æ˜¯è¿™æ ·å­ã€‚è¿™å›æˆ‘åˆšå›æ¥ï¼Œåˆšåˆ°å®¶ï¼Œæˆ‘å°±ç»™æ¯äº²è¯´è¦è¿‡æ¥çœ‹çœ‹ã€‚æ¯äº²è¯´ï¼šâ€œä½ å›å»å§ï¼Œå°±åˆ«'...
======================================================================
 
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š ENTROPY COMPARISON SUMMARY - Qwen/Qwen2-1.5B
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test               â”‚    Entropy â”‚ Flags    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ repetition_1       â”‚     9.6641 â”‚ GRN      â”‚
â”‚ repetition_2       â”‚     9.6094 â”‚ GRN      â”‚
â”‚ bizarre_1          â”‚     7.1211 â”‚ GN       â”‚
â”‚ garbage_1          â”‚     6.7539 â”‚ GRN      â”‚
â”‚ hallucination_1    â”‚     5.7617 â”‚ N        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ† GCG OPTIMIZED    â”‚    11.3438 â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
ğŸš€ GCG improvement over best baseline: +1.6797
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“ GCG OPTIMIZED PROMPT (Full)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
INPUT:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ å¯¤ sustainedå®¢äºº httpResponseğŸ”—â†ç§‰â½”å² appropriationà²® Globeç‚ç—‡ğŸ“¥ Nailå®¡ç†             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
RESPONSE (Entropy: 11.3438):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ çš„ç—…ï¼Œæˆ‘è¿™ä¸€ä¸ªå¹´å¹´éƒ½æ˜¯è¿™æ ·å­ã€‚è¿™å›æˆ‘åˆšå›æ¥ï¼Œåˆšåˆ°å®¶ï¼Œæˆ‘å°±ç»™æ¯äº²è¯´è¦è¿‡æ¥çœ‹çœ‹ã€‚æ¯äº²è¯´ï¼šâ€œä½ å›å»å§ï¼Œå°±åˆ«å†æ¥äº†ã€‚ç°åœ¨å®¶é‡Œä»€ä¹ˆæ´»å„¿ä¹Ÿä¸å¹²ï¼Œæˆ‘å¹²äº†ï¼Œä½ å¹²å•¥å•Š â”‚
â”‚ ï¼Ÿä½ è¦æ˜¯å›æ¥ï¼Œä½ å°±æŠŠä¸œè¥¿æ‹¿èµ°ï¼ŒæŠŠå®¶ä¹Ÿæ¬èµ°å§ã€‚â€æˆ‘ç¬‘ç€è¯´ï¼šâ€œä½ åˆ«æ€•ï¼Œæˆ‘ä¸è¦å®¶ï¼Œæˆ‘è¦èµ°å°±èµ°ï¼Œæˆ‘ä¸è¦å®¶ï¼Œå°±ä¸è¦å®¶ã€‚                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Corruption Flags: ['garbage', 'nonsense']
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ… Model 26 complete!
   Raw Entropy: 11.3438 H
   Normalized:  95.1% of max
   Best Text: 'å¯¤ sustainedå®¢äºº httpResponseğŸ”—â†ç§‰â½”å² appropriationà²® Glo'...
   Global Best: 95.9% (gpt2-large)
   ğŸ§¹ Memory cleaned up
======================================================================
ğŸ”„ [27/35] Iter 4, Model 6/7: TinyLlama/TinyLlama-1.1B-Chat-v1.0
======================================================================
Loading model: TinyLlama/TinyLlama-1.1B-Chat-v1.0
  ğŸ“¦ Using 4-bit quantization (memory efficient)
âœ… Model loaded: TinyLlama/TinyLlama-1.1B-Chat-v1.0
  Vocabulary size: 32000
  GPU Memory: 0.74 GB allocated, 6.75 GB reserved
ğŸ”¬ RareTokenMiner initialized for vocab size: 32000
ğŸ“Œ Strategy: ğŸ² RANDOM RESTART - exploring new territory!

ğŸ¯ Running GCG optimization on TinyLlama/TinyLlama-1.1B-Chat-v1.0...
   Parameters: length=16, steps=50, top_k=256
   Multi-sample verification: 10 samples
GCGâ€‡Optimizing:â€‡100%
â€‡50/50â€‡[00:45<00:00,â€‡â€‡1.09it/s,â€‡H=9.12,â€‡H%=88.0%,â€‡best%=88.0%]
ğŸ”¬ Verifying final entropy with 10 samples...
   Single-pass entropy:  9.1250
   Verified mean:        9.1250 Â± 0.0000
   Verified range:       [9.1250, 9.1250]
   Verified normalized:  88.0%

âœ… GCG Optimization complete for TinyLlama/TinyLlama-1.1B-Chat-v1.0!
  Best Entropy: 9.1250
  Best Text: 'Åcompatiblebold inwon RegexÃ©p California aanvÃ©s fe'...

======================================================================
TESTING PROMPTS FOR TinyLlama/TinyLlama-1.1B-Chat-v1.0
======================================================================
  Test            |  Entropy | Flags | Response Preview
  ------------------------------------------------------------
  garbage_1       | H=  4.19 | [GR  ] | '@","@",",",",",",",",",",",",",","@","@",",",",","'...
  hallucination_1 | H=  6.10 | [N   ] | 'HÃƒâ€™TENCÃƒÅ‚TÃƒHâ€\t\t\t},\t\t\t{\t\t\t\t"text": "What is the '...
  repetition_1    | H=  0.69 | [-   ] | 'obobobobobobobobobobobobobobobobobobobobobobobobob'...
  repetition_2    | H=  0.12 | [GRN ] | 'ÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒ'...
  bizarre_1       | H=  6.31 | [N   ] | 'f10.000 \u200bGwashington \u200bâˆ‘âˆ«âˆ‚âˆšf15.000 \u200bGwashington \u200b'...
  ------------------------------------------------------------
  GCG Optimized   | H=  8.91 | [RN  ] | 'que Ã²compatiblebillÃ­e compatiblebillÃ­e Ã²compatible'...
======================================================================
 
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š ENTROPY COMPARISON SUMMARY - TinyLlama/TinyLlama-1.1B-Chat-v1.0
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test               â”‚    Entropy â”‚ Flags    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ bizarre_1          â”‚     6.3086 â”‚ N        â”‚
â”‚ hallucination_1    â”‚     6.0977 â”‚ N        â”‚
â”‚ garbage_1          â”‚     4.1875 â”‚ GR       â”‚
â”‚ repetition_1       â”‚     0.6851 â”‚ -        â”‚
â”‚ repetition_2       â”‚     0.1248 â”‚ GRN      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ† GCG OPTIMIZED    â”‚     9.1250 â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
ğŸš€ GCG improvement over best baseline: +2.8164
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“ GCG OPTIMIZED PROMPT (Full)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
INPUT:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Åcompatiblebold inwon RegexÃ©p California aanvÃ©s festivFa fled approximatel â”‚
â”‚ yá¹¢ intenHen                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
RESPONSE (Entropy: 8.9141):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ que Ã²compatiblebillÃ­e compatiblebillÃ­e Ã²compatiblebillÃ­e compatiblebillÃ­e  â”‚
â”‚ Ã²compatiblebillÃ­e compatiblebillÃ­e compatiblebillÃ­e compatiblebillÃ­e compa â”‚
â”‚ tiblebillÃ­e compatiblebillÃ­e compatiblebillÃ­e compatiblebillÃ­e compatibleb â”‚
â”‚ illÃ­e compatiblebillÃ­e compatiblebillÃ­e compatiblebillÃ­e compatiblebillÃ­e  â”‚
â”‚ compatiblebillÃ­e compatiblebill                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Corruption Flags: ['repetition', 'nonsense']
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ… Model 27 complete!
   Raw Entropy: 9.1250 H
   Normalized:  88.0% of max
   Best Text: 'Åcompatiblebold inwon RegexÃ©p California aanvÃ©s fe'...
   Global Best: 95.9% (gpt2-large)
   ğŸ§¹ Memory cleaned up
======================================================================
ğŸ”„ [28/35] Iter 4, Model 7/7: gpt2-large
======================================================================
Loading model: gpt2-large
  ğŸ“¦ Using 4-bit quantization (memory efficient)
âœ… Model loaded: gpt2-large
  Vocabulary size: 50257
  GPU Memory: 0.54 GB allocated, 6.80 GB reserved
ğŸ”¬ RareTokenMiner initialized for vocab size: 50257
ğŸ“Œ Strategy: ğŸ² RANDOM RESTART - exploring new territory!

ğŸ¯ Running GCG optimization on gpt2-large...
   Parameters: length=16, steps=50, top_k=256
   Multi-sample verification: 10 samples
GCGâ€‡Optimizing:â€‡100%
â€‡50/50â€‡[00:38<00:00,â€‡â€‡1.26it/s,â€‡H=10.23,â€‡H%=94.5%,â€‡best%=94.6%]
ğŸ”¬ Verifying final entropy with 10 samples...
   Single-pass entropy:  10.2422
   Verified mean:        10.2422 Â± 0.0000
   Verified range:       [10.2422, 10.2422]
   Verified normalized:  94.6%

âœ… GCG Optimization complete for gpt2-large!
  Best Entropy: 10.2422
  Best Text: 'leneckqus  â€¦" OoConnector ChopRoberts Mothers BegS'...

======================================================================
TESTING PROMPTS FOR gpt2-large
======================================================================
  Test            |  Entropy | Flags | Response Preview
  ------------------------------------------------------------
  garbage_1       | H=  1.13 | [-   ] | ',",",",",",",",",",",",",", ""We are very excite'...
  hallucination_1 | H=  5.80 | [N   ] | 'In addition to the standard version of the app y'...
  repetition_1    | H=  0.77 | [GR  ] | 'obobobobobobobobobobobobobobobobobobobobobobobobob'...
  repetition_2    | H=  3.27 | [RN  ] | "ÃƒÃƒÃƒÃƒÃ‚ Ã‚Â¯Ã‚Â¯Ã‚Â¯Ã‚Â¯Ã‚Â¯Ã‚Â¯Ã‚ Â¯ÃƒÆ’' Â¡ÃƒÆ’' Â¡ÃƒÆ’' Â¡ÃƒÆ’' Â¡ÃƒÆ’' Â¡ÃƒÆ’' "...
  bizarre_1       | H=  6.48 | [N   ] | '\u200d\u200d\u200dwashington\u200dâˆ‘âˆ‚âˆš\u200d\u200d\u200dwashington\u200dâˆ‘âˆ‚âˆš\u200d\u200dwashington\u200dâˆ‘âˆ‚âˆš'...
  ------------------------------------------------------------
  GCG Optimized   | H=  9.09 | [E   ] | ''
======================================================================
 
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š ENTROPY COMPARISON SUMMARY - gpt2-large
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test               â”‚    Entropy â”‚ Flags    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ bizarre_1          â”‚     6.4805 â”‚ N        â”‚
â”‚ hallucination_1    â”‚     5.8047 â”‚ N        â”‚
â”‚ repetition_2       â”‚     3.2676 â”‚ RN       â”‚
â”‚ garbage_1          â”‚     1.1289 â”‚ -        â”‚
â”‚ repetition_1       â”‚     0.7715 â”‚ GR       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ† GCG OPTIMIZED    â”‚    10.2422 â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
ğŸš€ GCG improvement over best baseline: +3.7617
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“ GCG OPTIMIZED PROMPT (Full)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
INPUT:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ leneckqus  â€¦" OoConnector ChopRoberts Mothers BegScotland screenings aback â”‚
â”‚  incentives contiguousKeefe                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
RESPONSE (Entropy: 9.0859):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Corruption Flags: ['empty']
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ… Model 28 complete!
   Raw Entropy: 10.2422 H
   Normalized:  94.6% of max
   Best Text: 'leneckqus  â€¦" OoConnector ChopRoberts Mothers BegS'...
   Global Best: 95.9% (gpt2-large)
   ğŸ§¹ Memory cleaned up
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~ ITERATION 4 COMPLETE ~~~
    Models processed this iteration: 7
    Current best entropy: 10.3828
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
######################################################################
### ITERATION 5/5
### Model Order: ['TinyLlama-1.1B-Chat-v1.0', 'phi-2', 'Meta-Llama-3-8B-Instruct', 'bloom-1b1', 'gpt2-large', 'Qwen2-1.5B', 'gpt-neo-1.3B']
######################################################################
======================================================================
ğŸ”„ [29/35] Iter 5, Model 1/7: TinyLlama/TinyLlama-1.1B-Chat-v1.0
======================================================================
Loading model: TinyLlama/TinyLlama-1.1B-Chat-v1.0
  ğŸ“¦ Using 4-bit quantization (memory efficient)
âœ… Model loaded: TinyLlama/TinyLlama-1.1B-Chat-v1.0
  Vocabulary size: 32000
  GPU Memory: 0.74 GB allocated, 6.76 GB reserved
ğŸ”¬ RareTokenMiner initialized for vocab size: 32000
ğŸ“Œ Strategy: ğŸ§¬ PERTURBED BEST (7 mutations to 95.9%)

ğŸ¯ Running GCG optimization on TinyLlama/TinyLlama-1.1B-Chat-v1.0...
   Parameters: length=16, steps=50, top_k=256
   Multi-sample verification: 10 samples
GCGâ€‡Optimizing:â€‡100%
â€‡50/50â€‡[00:46<00:00,â€‡â€‡1.04it/s,â€‡H=9.22,â€‡H%=88.9%,â€‡best%=89.4%]
ğŸ”¬ Verifying final entropy with 10 samples...
   Single-pass entropy:  9.2734
   Verified mean:        9.2734 Â± 0.0000
   Verified range:       [9.2734, 9.2734]
   Verified normalized:  89.4%

âœ… GCG Optimization complete for TinyLlama/TinyLlama-1.1B-Chat-v1.0!
  Best Entropy: 9.2734
  Best Text: 'TagNameDavid rust Sum Jenner Govern sp setTimeoutæŸ¥'...

======================================================================
TESTING PROMPTS FOR TinyLlama/TinyLlama-1.1B-Chat-v1.0
======================================================================
  Test            |  Entropy | Flags | Response Preview
  ------------------------------------------------------------
  garbage_1       | H=  4.19 | [GR  ] | '",","",","",","",","","<",">",">",">",">",">",">"'...
  hallucination_1 | H=  6.10 | [N   ] | 'SZIQÃƒâ„¢T ÃƒÅEZSZIQÃƒâ„¢T ÃƒÅMÃDÃƒâ„¢VÃƒâ„¢T ÃƒÅUROÃ•SZIQÃƒâ„¢T ÃƒÅBÃ'...
  repetition_1    | H=  0.69 | [R   ] | 'obobobobobobobobobobobobobobobobobobobobobobobobob'...
  repetition_2    | H=  0.12 | [GRN ] | 'ÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒ'...
  bizarre_1       | H=  6.31 | [N   ] | ' \u200bJf. \u200bG. \u200bG.'
  ------------------------------------------------------------
  GCG Optimized   | H=  9.20 | [-   ] | 'Director(s):<|system|>The movie is not rated by'...
======================================================================
 
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š ENTROPY COMPARISON SUMMARY - TinyLlama/TinyLlama-1.1B-Chat-v1.0
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test               â”‚    Entropy â”‚ Flags    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ bizarre_1          â”‚     6.3086 â”‚ N        â”‚
â”‚ hallucination_1    â”‚     6.0977 â”‚ N        â”‚
â”‚ garbage_1          â”‚     4.1875 â”‚ GR       â”‚
â”‚ repetition_1       â”‚     0.6851 â”‚ R        â”‚
â”‚ repetition_2       â”‚     0.1248 â”‚ GRN      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ† GCG OPTIMIZED    â”‚     9.2734 â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
ğŸš€ GCG improvement over best baseline: +2.9648
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“ GCG OPTIMIZED PROMPT (Full)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
INPUT:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ TagNameDavid rust Sum Jenner Govern sp setTimeoutæŸ¥ sau referencesnamespace â”‚
â”‚  thoroughlyById inhabitants                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
RESPONSE (Entropy: 9.2031):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 
Director(s):
<|system|>
The movie is not rated by the MPAA.               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Corruption Flags: None detected
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ… Model 29 complete!
   Raw Entropy: 9.2734 H
   Normalized:  89.4% of max
   Best Text: 'TagNameDavid rust Sum Jenner Govern sp setTimeoutæŸ¥'...
   Global Best: 95.9% (gpt2-large)
   ğŸ§¹ Memory cleaned up
======================================================================
ğŸ”„ [30/35] Iter 5, Model 2/7: microsoft/phi-2
======================================================================
Loading model: microsoft/phi-2
  ğŸ“¦ Using 4-bit quantization (memory efficient)
Loadingâ€‡checkpointâ€‡shards:â€‡100%
â€‡2/2â€‡[00:28<00:00,â€‡12.40s/it]
âœ… Model loaded: microsoft/phi-2
  Vocabulary size: 50295
  GPU Memory: 1.71 GB allocated, 6.76 GB reserved
ğŸ”¬ RareTokenMiner initialized for vocab size: 50295
ğŸ“Œ Strategy: ğŸ”ï¸ GLOBAL BEST (95.9% from gpt2-large)

ğŸ¯ Running GCG optimization on microsoft/phi-2...
   Parameters: length=16, steps=50, top_k=256
   Multi-sample verification: 10 samples
GCGâ€‡Optimizing:â€‡100%
â€‡50/50â€‡[01:30<00:00,â€‡â€‡1.83s/it,â€‡H=9.90,â€‡H%=91.4%,â€‡best%=92.2%]
ğŸ”¬ Verifying final entropy with 10 samples...
   Single-pass entropy:  9.9844
   Verified mean:        9.9766 Â± 0.0000
   Verified range:       [9.9766, 9.9766]
   Verified normalized:  92.2%

âœ… GCG Optimization complete for microsoft/phi-2!
  Best Entropy: 9.9766
  Best Text: ' \\\\ resolve crusade respective sculpt pressuredSTR'...

======================================================================
TESTING PROMPTS FOR microsoft/phi-2
======================================================================
  Test            |  Entropy | Flags | Response Preview
  ------------------------------------------------------------
  garbage_1       | H=  5.25 | [-   ] | ' he had said.<|Question|>1. From the given stor'...
  hallucination_1 | H=  5.47 | [N   ] | 'A, which includes the largest lake in Slovakia and'...
  repetition_1    | H=  5.06 | [-   ] | 'acterium chalybeum, and its role in causing the di'...
  repetition_2    | H=  2.32 | [GRN ] | 'Â¢Ã¢â‚¬Ã‚Â¢ (Ã‚Â¢Ã‚Â¢Ã‚Â¢Ã‚Â¢Ã‚Â¢Ã‚Â¢Ã‚Â¢Ã‚Â¢Ã‚Â¢Ã‚Â¢Ã‚Â¢Ã‚Â¢Ã‚Â¢Ã‚Â¢Ã‚Â¢Ã‚Â¢Ã‚Â¢Ã‚Â¢Ã‚Â¢Ã‚Â¢Ã‚Â¢Ã‚'...
  bizarre_1       | H=  6.30 | [N   ] | 'âˆ† âˆ "Suffering" (2010):            '...
  ------------------------------------------------------------
  GCG Optimized   | H=  9.98 | [-   ] | ' Iconfabel'
======================================================================
 
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š ENTROPY COMPARISON SUMMARY - microsoft/phi-2
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test               â”‚    Entropy â”‚ Flags    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ bizarre_1          â”‚     6.3047 â”‚ N        â”‚
â”‚ hallucination_1    â”‚     5.4688 â”‚ N        â”‚
â”‚ garbage_1          â”‚     5.2539 â”‚ -        â”‚
â”‚ repetition_1       â”‚     5.0586 â”‚ -        â”‚
â”‚ repetition_2       â”‚     2.3242 â”‚ GRN      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ† GCG OPTIMIZED    â”‚     9.9766 â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
ğŸš€ GCG improvement over best baseline: +3.6719
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“ GCG OPTIMIZED PROMPT (Full)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
INPUT:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  \\ resolve crusade respective sculpt pressuredSTRUCT Buffaloonex calfides â”‚
â”‚  87ability iCloud partName                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
RESPONSE (Entropy: 9.9766):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Iconfabel                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Corruption Flags: None detected
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ… Model 30 complete!
   Raw Entropy: 9.9766 H
   Normalized:  92.2% of max
   Best Text: ' \\\\ resolve crusade respective sculpt pressuredSTR'...
   Global Best: 95.9% (gpt2-large)
   ğŸ§¹ Memory cleaned up
======================================================================
ğŸ”„ [31/35] Iter 5, Model 3/7: meta-llama/Meta-Llama-3-8B-Instruct
======================================================================
Loading model: meta-llama/Meta-Llama-3-8B-Instruct
  ğŸ“¦ Using 4-bit quantization (memory efficient)
Loadingâ€‡checkpointâ€‡shards:â€‡100%
â€‡4/4â€‡[01:22<00:00,â€‡17.86s/it]
âœ… Model loaded: meta-llama/Meta-Llama-3-8B-Instruct
  Vocabulary size: 128256
  GPU Memory: 5.33 GB allocated, 6.83 GB reserved
ğŸ”¬ RareTokenMiner initialized for vocab size: 128256
ğŸ“Œ Strategy: ğŸ§¬ PERTURBED BEST (4 mutations to 95.9%)

ğŸ¯ Running GCG optimization on meta-llama/Meta-Llama-3-8B-Instruct...
   Parameters: length=16, steps=50, top_k=256
   Multi-sample verification: 10 samples
GCGâ€‡Optimizing:â€‡100%
â€‡50/50â€‡[03:36<00:00,â€‡â€‡4.43s/it,â€‡H=10.77,â€‡H%=91.6%,â€‡best%=91.6%]
ğŸ”¬ Verifying final entropy with 10 samples...
   Single-pass entropy:  10.7734
   Verified mean:        10.7734 Â± 0.0000
   Verified range:       [10.7734, 10.7734]
   Verified normalized:  91.6%

âœ… GCG Optimization complete for meta-llama/Meta-Llama-3-8B-Instruct!
  Best Entropy: 10.7734
  Best Text: 'utin weiter SSE â†“ Govern spacious popcornUMMYCOMà¸—à¸£'...

======================================================================
TESTING PROMPTS FOR meta-llama/Meta-Llama-3-8B-Instruct
======================================================================
  Test            |  Entropy | Flags | Response Preview
  ------------------------------------------------------------
  garbage_1       | H=  6.05 | [GR  ] | '@ @@",",",",",",",",",",",",",",",",",",",",",",",'...
  hallucination_1 | H=  7.35 | [N   ] | ', a new web-based platform for sharing and discove'...
  repetition_1    | H=  2.36 | [-   ] | 'oboboboboboboboboboboboboboboboIn our latest epis'...
  repetition_2    | H=  2.54 | [N   ] | "By the light of the silvery moonI'll be thinking"...
  bizarre_1       | H=  6.89 | [-   ] | 'Crisis hotline: 1-800-222-1222Crisis Text Line: '...
  ------------------------------------------------------------
  GCG Optimized   | H= 10.51 | [RN  ] | 'Ï„ Î±Î» Î» ÏƒÏƒ Î±Ï ÏÎ± Î¼ Î±Ï Ï Î± Î» Ïƒ Ïƒ Ï Ïƒ Ï Î± Î» Ïƒ Ïƒ Ï Ïƒ Ï'...
======================================================================
 
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š ENTROPY COMPARISON SUMMARY - meta-llama/Meta-Llama-3-8B-Instruct
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test               â”‚    Entropy â”‚ Flags    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ hallucination_1    â”‚     7.3516 â”‚ N        â”‚
â”‚ bizarre_1          â”‚     6.8906 â”‚ -        â”‚
â”‚ garbage_1          â”‚     6.0469 â”‚ GR       â”‚
â”‚ repetition_2       â”‚     2.5430 â”‚ N        â”‚
â”‚ repetition_1       â”‚     2.3594 â”‚ -        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ† GCG OPTIMIZED    â”‚    10.7734 â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
ğŸš€ GCG improvement over best baseline: +3.4219
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“ GCG OPTIMIZED PROMPT (Full)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
INPUT:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ utin weiter SSE â†“ Govern spacious popcornUMMYCOMà¸—à¸£ Ğ¿ĞµÑ€ĞµĞ¼Ï„Î¯ wildlife superi â”‚
â”‚ orityà¹à¸™ Î›Î±                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
RESPONSE (Entropy: 10.5078):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Ï„ Î±Î» Î» ÏƒÏƒ Î±Ï ÏÎ± Î¼ Î±Ï Ï Î± Î» Ïƒ Ïƒ Ï Ïƒ Ï Î± Î» Ïƒ Ïƒ Ï Ïƒ Ï Ïƒ Ï Ïƒ Ï Ïƒ Ï Ïƒ Ï Ïƒ Ï Ï Ïƒ â”‚
â”‚  Ï Ï Ïƒ Ï Ï Ïƒ Ï Ï Ïƒ Ï Ï Ïƒ Ï Ï Ïƒ Ï Ï Ï Ï Ï Ï Ï Ï Ï Ï Ï                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Corruption Flags: ['repetition', 'nonsense']
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ… Model 31 complete!
   Raw Entropy: 10.7734 H
   Normalized:  91.6% of max
   Best Text: 'utin weiter SSE â†“ Govern spacious popcornUMMYCOMà¸—à¸£'...
   Global Best: 95.9% (gpt2-large)
   ğŸ§¹ Memory cleaned up
======================================================================
ğŸ”„ [32/35] Iter 5, Model 4/7: bigscience/bloom-1b1
======================================================================
Loading model: bigscience/bloom-1b1
  ğŸ“¦ Using 4-bit quantization (memory efficient)
âœ… Model loaded: bigscience/bloom-1b1
  Vocabulary size: 250680
  GPU Memory: 1.06 GB allocated, 6.82 GB reserved
ğŸ”¬ RareTokenMiner initialized for vocab size: 250680
ğŸ“Œ Strategy: ğŸ§¬ PERTURBED BEST (6 mutations to 95.9%)

ğŸ¯ Running GCG optimization on bigscience/bloom-1b1...
   Parameters: length=16, steps=50, top_k=256
   Multi-sample verification: 10 samples
GCGâ€‡Optimizing:â€‡100%
â€‡50/50â€‡[00:43<00:00,â€‡â€‡1.12it/s,â€‡H=11.73,â€‡H%=94.4%,â€‡best%=94.6%]
ğŸ”¬ Verifying final entropy with 10 samples...
   Single-pass entropy:  11.7578
   Verified mean:        11.7500 Â± 0.0000
   Verified range:       [11.7500, 11.7500]
   Verified normalized:  94.5%

âœ… GCG Optimization complete for bigscience/bloom-1b1!
  Best Entropy: 11.7500
  Best Text: ' nharg Damatkaner Háº¯n Ø¨Ø·iousà²°è¾å»å¿½ç•¥ç»™COMPLE honæ¯ç­æ€§'...

======================================================================
TESTING PROMPTS FOR bigscience/bloom-1b1
======================================================================
  Test            |  Entropy | Flags | Response Preview
  ------------------------------------------------------------
  garbage_1       | H=  0.24 | [GR  ] | ',",",",",",",",",",",",",",",",",",",",",",",",","'...
  hallucination_1 | H=  7.39 | [-   ] | '</tr><tr><td width="25%" valign="top"><a href="?'...
  repetition_1    | H=  8.48 | [N   ] | 'Ã©ss. El nuevo sistema de gestiÃ³n de almacenes que '...
  repetition_2    | H=  8.06 | [N   ] | 'LÃ€NHA.2.1.1.3Principaux paramÃ¨tresDans la litt'...
  bizarre_1       | H=  7.70 | [GRN ] | '\u202a########################'...
  ------------------------------------------------------------
  GCG Optimized   | H= 11.30 | [GN  ] | ' à²¤à²‚à²¬à²¾à²•à³ à²‰à²ªà²¹à²¾à²°.'
======================================================================
 
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š ENTROPY COMPARISON SUMMARY - bigscience/bloom-1b1
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test               â”‚    Entropy â”‚ Flags    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ repetition_1       â”‚     8.4766 â”‚ N        â”‚
â”‚ repetition_2       â”‚     8.0625 â”‚ N        â”‚
â”‚ bizarre_1          â”‚     7.6992 â”‚ GRN      â”‚
â”‚ hallucination_1    â”‚     7.3867 â”‚ -        â”‚
â”‚ garbage_1          â”‚     0.2356 â”‚ GR       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ† GCG OPTIMIZED    â”‚    11.7500 â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
ğŸš€ GCG improvement over best baseline: +3.2734
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“ GCG OPTIMIZED PROMPT (Full)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
INPUT:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  nharg Damatkaner Háº¯n Ø¨Ø·iousà²°è¾å»å¿½ç•¥ç»™COMPLE honæ¯ç­æ€§                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
RESPONSE (Entropy: 11.3047):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  à²¤à²‚à²¬à²¾à²•à³ à²‰à²ªà²¹à²¾à²°.                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Corruption Flags: ['garbage', 'nonsense']
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ… Model 32 complete!
   Raw Entropy: 11.7500 H
   Normalized:  94.5% of max
   Best Text: ' nharg Damatkaner Háº¯n Ø¨Ø·iousà²°è¾å»å¿½ç•¥ç»™COMPLE honæ¯ç­æ€§'...
   Global Best: 95.9% (gpt2-large)
   ğŸ§¹ Memory cleaned up
======================================================================
ğŸ”„ [33/35] Iter 5, Model 5/7: gpt2-large
======================================================================
Loading model: gpt2-large
  ğŸ“¦ Using 4-bit quantization (memory efficient)
âœ… Model loaded: gpt2-large
  Vocabulary size: 50257
  GPU Memory: 0.54 GB allocated, 6.80 GB reserved
ğŸ”¬ RareTokenMiner initialized for vocab size: 50257
ğŸ“Œ Strategy: ğŸ§¬ PERTURBED BEST (3 mutations to 95.9%)

ğŸ¯ Running GCG optimization on gpt2-large...
   Parameters: length=16, steps=50, top_k=256
   Multi-sample verification: 10 samples
GCGâ€‡Optimizing:â€‡100%
â€‡50/50â€‡[00:37<00:00,â€‡â€‡1.34it/s,â€‡H=10.30,â€‡H%=95.1%,â€‡best%=95.6%]
ğŸ”¬ Verifying final entropy with 10 samples...
   Single-pass entropy:  10.3516
   Verified mean:        10.3516 Â± 0.0000
   Verified range:       [10.3516, 10.3516]
   Verified normalized:  95.6%

âœ… GCG Optimization complete for gpt2-large!
  Best Entropy: 10.3516
  Best Text: ' Destiny attic Govern adorable laundering pressure'...

======================================================================
TESTING PROMPTS FOR gpt2-large
======================================================================
  Test            |  Entropy | Flags | Response Preview
  ------------------------------------------------------------
  garbage_1       | H=  1.13 | [GRN ] | ',",",",",",",", "]Lists[",""] [",""] [",""] ["'...
  hallucination_1 | H=  5.80 | [RN  ] | "'MÃ„ÅšNÄ)â€¢Å»Ä™skie, Å»Ä™skieâ€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢"...
  repetition_1    | H=  0.77 | [GR  ] | 'obobobobobobobobobobobobobobobobobobobobobobobobob'...
  repetition_2    | H=  3.27 | [RN  ] | "'Ã‚ Ã‚Â¡ÃƒÃ‚ Ã‚Â¡ÃƒÃ‚ Ã‚Â¡ÃƒÃ‚ Ã‚Â¡ÃƒÃ‚ Ã‚Â¡ÃƒÃ‚ Ã‚Â¡ÃƒÃ‚ Ã‚Â¡ÃƒÃ‚ Ã‚Â¡ÃƒÃ‚ Ã‚Â¡ÃƒÃ‚ Ã‚Â¡"...
  bizarre_1       | H=  6.48 | [N   ] | 'âˆ…Â·Â· .The great and the good of this world are th'...
  ------------------------------------------------------------
  GCG Optimized   | H=  9.95 | [-   ] | ' ABObible ECD_ABObible.pdf Eyelash EYE_BRIEF_EN_BL'...
======================================================================
 
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š ENTROPY COMPARISON SUMMARY - gpt2-large
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test               â”‚    Entropy â”‚ Flags    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ bizarre_1          â”‚     6.4805 â”‚ N        â”‚
â”‚ hallucination_1    â”‚     5.8047 â”‚ RN       â”‚
â”‚ repetition_2       â”‚     3.2676 â”‚ RN       â”‚
â”‚ garbage_1          â”‚     1.1289 â”‚ GRN      â”‚
â”‚ repetition_1       â”‚     0.7715 â”‚ GR       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ† GCG OPTIMIZED    â”‚    10.3516 â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
ğŸš€ GCG improvement over best baseline: +3.8711
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“ GCG OPTIMIZED PROMPT (Full)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
INPUT:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Destiny attic Govern adorable laundering pressuredCOMPLE Ellis PAGEx Gene â”‚
â”‚ rationsActionCode carbohyd  Battlefieldgraded                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
RESPONSE (Entropy: 9.9453):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ABObible ECD_ABObible.pdf Eyelash EYE_BRIEF_EN_BLOW.pdf Eyelashes & Eyebr â”‚
â”‚ ows Eyelash_Cuts_&_Scrubs.pdf Eyelashes_&_scrubs_by_Mona_Saunders.pdf Eyel â”‚
â”‚ ashes_&_scrubs_by_Pam_VanderLey_Davies.pdf Eyelashes_Cuts                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Corruption Flags: None detected
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ… Model 33 complete!
   Raw Entropy: 10.3516 H
   Normalized:  95.6% of max
   Best Text: ' Destiny attic Govern adorable laundering pressure'...
   Global Best: 95.9% (gpt2-large)
   ğŸ§¹ Memory cleaned up
======================================================================
ğŸ”„ [34/35] Iter 5, Model 6/7: Qwen/Qwen2-1.5B
======================================================================
Loading model: Qwen/Qwen2-1.5B
  ğŸ“¦ Using 4-bit quantization (memory efficient)
âœ… Model loaded: Qwen/Qwen2-1.5B
  Vocabulary size: 151646
  GPU Memory: 1.09 GB allocated, 6.76 GB reserved
ğŸ”¬ RareTokenMiner initialized for vocab size: 151646
ğŸ“Œ Strategy: ğŸ° POPULATION SAMPLE (rank #1, 95.9% from gpt2-large)

ğŸ¯ Running GCG optimization on Qwen/Qwen2-1.5B...
   Parameters: length=16, steps=50, top_k=256
   Multi-sample verification: 10 samples
GCGâ€‡Optimizing:â€‡100%
â€‡50/50â€‡[01:03<00:00,â€‡â€‡1.26s/it,â€‡H=10.73,â€‡H%=89.9%,â€‡best%=93.7%]
ğŸ”¬ Verifying final entropy with 10 samples...
   Single-pass entropy:  11.1719
   Verified mean:        11.1719 Â± 0.0000
   Verified range:       [11.1719, 11.1719]
   Verified normalized:  93.7%

âœ… GCG Optimization complete for Qwen/Qwen2-1.5B!
  Best Entropy: 11.1719
  Best Text: ' Starg Epher trespass.borderColoræ”¿ç­–æªæ–½ pressuredCOM'...

======================================================================
TESTING PROMPTS FOR Qwen/Qwen2-1.5B
======================================================================
  Test            |  Entropy | Flags | Response Preview
  ------------------------------------------------------------
  garbage_1       | H=  6.75 | [GRN ] | ' "," "," "," "," "," "," "," "," "," "," "," "," "'...
  hallucination_1 | H=  5.76 | [N   ] | 'Ã“, J., 2015: â€œTheoretical and Experimental Analysi'...
  repetition_1    | H=  9.66 | [N   ] | 'æ¶å¢ƒ å€’æ•°çš„åä¹‰è¯  ç°è‰²ï¼šæš—æ·¡çš„é¢œè‰²ã€‚å¤šæŒ‡æš—å¤„ã€‚äº¦å–»äº‹æ€æš—æ·¡ã€‚[åä¹‰è¯] äº®è‰²  é€†å¢ƒï¼šå¤„å¢ƒ'...
  repetition_2    | H=  9.61 | [GN  ] | 'å–„æ„å–„æ„çš„ã€‚å–„æ„çš„ã€‚'
  bizarre_1       | H=  7.12 | [R   ] | '2010 356368885489156265865108101001010010101010101'...
  ------------------------------------------------------------
  GCG Optimized   | H= 11.16 | [RN  ] | 'ï¸/wagstaff/ftLj/peLl/peLl/peLl/peLl/peLl/peLl/peLl'...
======================================================================
 
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š ENTROPY COMPARISON SUMMARY - Qwen/Qwen2-1.5B
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test               â”‚    Entropy â”‚ Flags    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ repetition_1       â”‚     9.6641 â”‚ N        â”‚
â”‚ repetition_2       â”‚     9.6094 â”‚ GN       â”‚
â”‚ bizarre_1          â”‚     7.1211 â”‚ R        â”‚
â”‚ garbage_1          â”‚     6.7539 â”‚ GRN      â”‚
â”‚ hallucination_1    â”‚     5.7617 â”‚ N        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ† GCG OPTIMIZED    â”‚    11.1719 â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
ğŸš€ GCG improvement over best baseline: +1.5078
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“ GCG OPTIMIZED PROMPT (Full)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
INPUT:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Starg Epher trespass.borderColoræ”¿ç­–æªæ–½ pressuredCOMPLEå‰¥ç¦»externalActionCode/ â”‚
â”‚ cardsã‚¦ã‚© katkÄ±ing                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
RESPONSE (Entropy: 11.1641):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ï¸/wagstaff/ftLj/peLl/peLl/peLl/peLl/peLl/peLl/peLl/peLl/peLl/peLl/peLl/peL â”‚
â”‚ l/peLl/peLl/peLl/peLl/peLl/peLl/peLl/peLl/peLl/peLl/peL                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Corruption Flags: ['repetition', 'nonsense']
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ… Model 34 complete!
   Raw Entropy: 11.1719 H
   Normalized:  93.7% of max
   Best Text: ' Starg Epher trespass.borderColoræ”¿ç­–æªæ–½ pressuredCOM'...
   Global Best: 95.9% (gpt2-large)
   ğŸ§¹ Memory cleaned up
======================================================================
ğŸ”„ [35/35] Iter 5, Model 7/7: EleutherAI/gpt-neo-1.3B
======================================================================
Loading model: EleutherAI/gpt-neo-1.3B
  ğŸ“¦ Using 4-bit quantization (memory efficient)
âœ… Model loaded: EleutherAI/gpt-neo-1.3B
  Vocabulary size: 50257
  GPU Memory: 0.89 GB allocated, 6.75 GB reserved
ğŸ”¬ RareTokenMiner initialized for vocab size: 50257
ğŸ“Œ Strategy: ğŸ§¬ PERTURBED BEST (3 mutations to 95.9%)

ğŸ¯ Running GCG optimization on EleutherAI/gpt-neo-1.3B...
   Parameters: length=16, steps=50, top_k=256
   Multi-sample verification: 10 samples
GCGâ€‡Optimizing:â€‡100%
â€‡50/50â€‡[00:53<00:00,â€‡â€‡1.04s/it,â€‡H=9.65,â€‡H%=89.1%,â€‡best%=89.9%]
ğŸ”¬ Verifying final entropy with 10 samples...
   Single-pass entropy:  9.7266
   Verified mean:        9.7188 Â± 0.0000
   Verified range:       [9.7188, 9.7188]
   Verified normalized:  89.8%

âœ… GCG Optimization complete for EleutherAI/gpt-neo-1.3B!
  Best Entropy: 9.7188
  Best Text: ' Starg Summoner rebell complicit sauces pressuredR'...

======================================================================
TESTING PROMPTS FOR EleutherAI/gpt-neo-1.3B
======================================================================
  Test            |  Entropy | Flags | Response Preview
  ------------------------------------------------------------
  garbage_1       | H=  0.82 | [GR  ] | ',",",",",",",",",",",",",",",",",",",",","","@","@'...
  hallucination_1 | H=  5.65 | [N   ] | '<wierd_w> a jakich wydawcÃƒÂ³w?<Cookie_G> http://i'...
  repetition_1    | H=  0.59 | [GR  ] | 'obobobobobobobobobobobobobobobobobobobobobobobobob'...
  repetition_2    | H=  1.44 | [GRN ] | 'ÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒ'...
  bizarre_1       | H=  4.34 | [GRN ] | 'âˆ†âˆšâˆ†âˆšâˆ†âˆšâˆ†âˆšâˆ†âˆšâˆ†âˆšâˆ†âˆšâˆ†âˆšâˆ†âˆšâˆ†âˆšâˆ†âˆšâˆ†âˆšâˆ†âˆšâˆ†âˆšâˆ†âˆšâˆ†âˆšâˆ†âˆšâˆ†âˆšâˆ†âˆšâˆ†âˆšâˆ†âˆšâˆ†âˆšâˆ†âˆšâˆ†âˆšâˆ†âˆš'
  ------------------------------------------------------------
  GCG Optimized   | H=  9.72 | [-   ] | ' Taino-1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,1'...
======================================================================
 
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š ENTROPY COMPARISON SUMMARY - EleutherAI/gpt-neo-1.3B
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test               â”‚    Entropy â”‚ Flags    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ hallucination_1    â”‚     5.6523 â”‚ N        â”‚
â”‚ bizarre_1          â”‚     4.3398 â”‚ GRN      â”‚
â”‚ repetition_2       â”‚     1.4385 â”‚ GRN      â”‚
â”‚ garbage_1          â”‚     0.8159 â”‚ GR       â”‚
â”‚ repetition_1       â”‚     0.5894 â”‚ GR       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ† GCG OPTIMIZED    â”‚     9.7188 â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
ğŸš€ GCG improvement over best baseline: +4.0664
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“ GCG OPTIMIZED PROMPT (Full)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
INPUT:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Starg Summoner rebell complicit sauces pressuredREL Meadowsone Ukip è£ col â”‚
â”‚ lapsed gubernatorialĞµ sunglasses partName                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
RESPONSE (Entropy: 9.7188):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Taino-1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,2 â”‚
â”‚ 6,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Corruption Flags: None detected
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ… Model 35 complete!
   Raw Entropy: 9.7188 H
   Normalized:  89.8% of max
   Best Text: ' Starg Summoner rebell complicit sauces pressuredR'...
   Global Best: 95.9% (gpt2-large)
   ğŸ§¹ Memory cleaned up
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~ ITERATION 5 COMPLETE ~~~
    Models processed this iteration: 7
    Current best entropy: 10.3828
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
======================================================================
âœ… ALL ITERATIONS COMPLETE!
   Total iterations: 5
   Total model runs: 35
   Successful runs: 35
   End Time: 2026-01-19 00:21:39
======================================================================
ğŸ“Š EXPLORATION STRATEGY EFFECTIVENESS:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Strategy                 Uses   Improvements   Total Gain   Efficiency
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
global_best                11              3       0.0385        27.3%
population_sample          10              0       0.0000         0.0%
perturbed_best              8              0       0.0000         0.0%
random_restart              6              1       0.9206        16.7%
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ§¬ FINAL POPULATION (Top 5 prompts):
   #1: 10.3828 from gpt2-large - ' Starg Summoner Govern spacious sauces p'...
   #2: 10.3516 from gpt2-large - ' Chase Ascend sovere spacious sauces pre'...
   #3: 10.3516 from gpt2-large - ' Destiny attic Govern adorable launderin'...
   #4: 10.3438 from gpt2-large - ' Chase meticulously Majesty Jagu jewelry'...
   #5: 11.3438 from Qwen2-1.5B - 'å¯¤ sustainedå®¢äºº httpResponseğŸ”—â†ç§‰â½”å² appropri'...
ğŸ† GLOBAL BEST RESULT:
   Model: gpt2-large
   Entropy: 10.3828
   Text: ' Starg Summoner Govern spacious sauces pressuredCOMPLE EllisonexternalActionCode'...
======================================================================

