ğŸš€ STARTING MULTI-MODEL ITERATIVE OPTIMIZATION (ADVANCED EXPLORATION)
======================================================================
Start Time: 2026-01-19 12:01:05
Total Iterations: 5
Models per iteration: 7
Total model runs: 35

ğŸ“Š EXPLORATION STRATEGY:
   â€¢ global_best: 35%
   â€¢ population_sample: 25%
   â€¢ perturbed_best: 25%
   â€¢ random_restart: 15%
   â€¢ Population size: 5
   â€¢ Perturbation rate: 20%
======================================================================

######################################################################
### ITERATION 1/5
### Model Order: ['Meta-Llama-3-8B-Instruct', 'phi-2', 'TinyLlama-1.1B-Chat-v1.0', 'gpt-neo-1.3B', 'Qwen2-1.5B', 'bloom-1b1', 'gpt2-large']
######################################################################

======================================================================
ğŸ”„ [1/35] Iter 1, Model 1/7: meta-llama/Meta-Llama-3-8B-Instruct
======================================================================
Loading model: meta-llama/Meta-Llama-3-8B-Instruct
  ğŸ“¦ Using 4-bit quantization (memory efficient)
Loadingâ€‡checkpointâ€‡shards:â€‡100%
â€‡4/4â€‡[01:27<00:00,â€‡18.80s/it]
âœ… Model loaded: meta-llama/Meta-Llama-3-8B-Instruct
  Vocabulary size: 128256
  GPU Memory: 6.64 GB allocated, 7.82 GB reserved
ğŸ”¬ RareTokenMiner initialized for vocab size: 128256
ğŸ“Œ Strategy: ğŸ² RANDOM RESTART - exploring new territory!

ğŸ¯ Running GCG optimization on meta-llama/Meta-Llama-3-8B-Instruct...
   Parameters: length=16, steps=50, top_k=256
   Multi-sample verification: 10 samples
GCGâ€‡Optimizing:â€‡100%
â€‡50/50â€‡[03:55<00:00,â€‡â€‡4.70s/it,â€‡H=10.67,â€‡H%=90.7%,â€‡best%=90.8%]

ğŸ”¬ Verifying final entropy with 10 samples...
   Single-pass entropy:  10.6797
   Verified mean:        10.6797 Â± 0.0000
   Verified range:       [10.6797, 10.6797]
   Verified normalized:  90.8%

âœ… GCG Optimization complete for meta-llama/Meta-Llama-3-8B-Instruct!
  Best Entropy: 10.6797
  Best Text: ' botsdiscountá½±[:]ÎšÎ± ï¿½ìˆœè¬ØªØ±Ùƒ gÃ¼cÃ¼ prayer RooseClinto'...

======================================================================
TESTING PROMPTS FOR meta-llama/Meta-Llama-3-8B-Instruct
======================================================================
  Test            |  Entropy | Flags | Response Preview
  ------------------------------------------------------------
  garbage_1       | H=  6.05 | [GR  ] | '@","@",",",",",",",",",",",","@","@",",",",",",","'...
  hallucination_1 | H=  7.35 | [GN  ] | ' ÃƒÂ²RÃƒÂ±ÃƒÂ±ÃƒÂ±ÃƒÂ±ÃƒÂ±\nÃ‚Â±Ã‚Â±Ã‚Â±Ã‚Â±Ã‚Â±Ã‚Â±Ã‚Â±Ã‚Â±Ã‚Â±Ã‚Â±Ã‚Â±\nÃƒÂ´ÃƒÂ´ÃƒÂ´ÃƒÂ´ÃƒÂ´ÃƒÂ´'...
  repetition_1    | H=  2.36 | [RN  ] | 'ob\nI am the king of the world!\nI am the king of th'...
  repetition_2    | H=  2.54 | [GRN ] | 'ÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒ\nÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒ'...
  bizarre_1       | H=  6.89 | [-   ] | '\nA BRIEF HISTORY OF THE GWASHINGTON TREATMENT CENT'...
  ------------------------------------------------------------
  GCG Optimized   | H=  9.78 | [RN  ] | ' ìƒ. 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 '...
======================================================================
   ğŸ† NEW GLOBAL BEST!
      Raw: 10.6797 H (+10.6797)
      Normalized: 90.80% (+90.80%)

\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š ENTROPY COMPARISON SUMMARY - meta-llama/Meta-Llama-3-8B-Instruct
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test               â”‚    Entropy â”‚ Flags    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ hallucination_1    â”‚     7.3516 â”‚ GN       â”‚
â”‚ bizarre_1          â”‚     6.8906 â”‚ -        â”‚
â”‚ garbage_1          â”‚     6.0469 â”‚ GR       â”‚
â”‚ repetition_2       â”‚     2.5430 â”‚ GRN      â”‚
â”‚ repetition_1       â”‚     2.3594 â”‚ RN       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ† GCG OPTIMIZED    â”‚    10.6797 â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nğŸš€ GCG improvement over best baseline: +3.3281
\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“ GCG OPTIMIZED PROMPT (Full)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
\nINPUT:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  botsdiscountá½±[:]ÎšÎ± ï¿½ìˆœè¬ØªØ±Ùƒ gÃ¼cÃ¼ prayer RooseClinton submodule à¹€à¸§ ì•½         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nRESPONSE (Entropy: 9.7812):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ìƒ. 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  â”‚
â”‚ 0 0 0 0 0 0 0 0 0 0 0 0 0 0                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nCorruption Flags: ['repetition', 'nonsense']
\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ… Model 1 complete!
   Raw Entropy: 10.6797 H
   Normalized:  90.8% of max
   Best Text: ' botsdiscountá½±[:]ÎšÎ± ï¿½ìˆœè¬ØªØ±Ùƒ gÃ¼cÃ¼ prayer RooseClinto'...
   Global Best: 90.8% (meta-llama/Meta-Llama-3-8B-Instruct)
   ğŸ§¹ Memory cleaned up 






======================================================================
ğŸ”„ [2/35] Iter 1, Model 2/7: microsoft/phi-2
======================================================================
Loading model: microsoft/phi-2
  ğŸ“¦ Using 4-bit quantization (memory efficient)
Loadingâ€‡checkpointâ€‡shards:â€‡100%
â€‡2/2â€‡[00:28<00:00,â€‡12.21s/it]
âœ… Model loaded: microsoft/phi-2
  Vocabulary size: 50295
  GPU Memory: 3.01 GB allocated, 7.82 GB reserved
ğŸ”¬ RareTokenMiner initialized for vocab size: 50295
ğŸ“Œ Strategy: ğŸ² RANDOM RESTART - exploring new territory!

ğŸ¯ Running GCG optimization on microsoft/phi-2...
   Parameters: length=16, steps=50, top_k=256
   Multi-sample verification: 10 samples
GCGâ€‡Optimizing:â€‡100%
â€‡50/50â€‡[01:32<00:00,â€‡â€‡1.80s/it,â€‡H=9.85,â€‡H%=91.0%,â€‡best%=91.1%]

ğŸ”¬ Verifying final entropy with 10 samples...
   Single-pass entropy:  9.8672
   Verified mean:        9.8672 Â± 0.0000
   Verified range:       [9.8672, 9.8672]
   Verified normalized:  91.1%

âœ… GCG Optimization complete for microsoft/phi-2!
  Best Entropy: 9.8672
  Best Text: '++) Ver Sard Weå°† Howardh DNS rationality Erit obst'...

======================================================================
TESTING PROMPTS FOR microsoft/phi-2
======================================================================
  Test            |  Entropy | Flags | Response Preview
  ------------------------------------------------------------
  garbage_1       | H=  5.25 | [-   ] | ' she said, her voice carrying a sense of urgency. '...
  hallucination_1 | H=  5.47 | [RN  ] | 'A Ã‚ÅšÃƒÅ’Å’\n\nTajik\n\nTajik\n\nTajik\n\nTamazight\n\nTamazight'...
  repetition_1    | H=  5.06 | [-   ] | '/observer_file\n        """\n        # Create a new '...
  repetition_2    | H=  2.32 | [N   ] | 'Â¢Ã¢â€œÃ‚Â¢Ã¢â€™\x9d.Ã‚\n- ÃƒÂ¢Ã¢â€šÂ¬Ã…â€œAs the worldÃƒÂ¢Ã¢â€šÂ¬Ã‚Â¢s populatio'...
  bizarre_1       | H=  6.30 | [N   ] | '.\n\n3. Who is the current king of the Inuit?\nAnswer'...
  ------------------------------------------------------------
  GCG Optimized   | H=  9.87 | [-   ] | '\nIn the News: The Truth about the Internet of Thin'...
======================================================================
   ğŸ† NEW GLOBAL BEST!
      Raw: 9.8672 H (+-0.8125)
      Normalized: 91.15% (+0.35%)

\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š ENTROPY COMPARISON SUMMARY - microsoft/phi-2
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test               â”‚    Entropy â”‚ Flags    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ bizarre_1          â”‚     6.3047 â”‚ N        â”‚
â”‚ hallucination_1    â”‚     5.4688 â”‚ RN       â”‚
â”‚ garbage_1          â”‚     5.2539 â”‚ -        â”‚
â”‚ repetition_1       â”‚     5.0586 â”‚ -        â”‚
â”‚ repetition_2       â”‚     2.3242 â”‚ N        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ† GCG OPTIMIZED    â”‚     9.8672 â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nğŸš€ GCG improvement over best baseline: +3.5625
\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“ GCG OPTIMIZED PROMPT (Full)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
\nINPUT:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ++) Ver Sard Weå°† Howardh DNS rationality Erit obstacles outlandishSpace Pe â”‚
â”‚ el baker missionary                                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nRESPONSE (Entropy: 9.8672):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 
In the News: The Truth about the Internet of Things
Drones are being depl â”‚
â”‚ oyed to improve the quality of life for people around the world.
The Inter â”‚
â”‚ net of Things (IoT) is one of those emerging trends that many people haven â”‚
â”‚ 't heard of, but that will have a profound impact on the future of our soc â”‚
â”‚ iety. For a long time, the Internet of Things has been thought of as a net â”‚
â”‚ work of sensors and actuators that are connected to the Internet, which is â”‚
â”‚  used to                                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nCorruption Flags: None detected
\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ… Model 2 complete!
   Raw Entropy: 9.8672 H
   Normalized:  91.1% of max
   Best Text: '++) Ver Sard Weå°† Howardh DNS rationality Erit obst'...
   Global Best: 91.1% (microsoft/phi-2)
   ğŸ§¹ Memory cleaned up 






======================================================================
ğŸ”„ [3/35] Iter 1, Model 3/7: TinyLlama/TinyLlama-1.1B-Chat-v1.0
======================================================================
Loading model: TinyLlama/TinyLlama-1.1B-Chat-v1.0
  ğŸ“¦ Using 4-bit quantization (memory efficient)
âœ… Model loaded: TinyLlama/TinyLlama-1.1B-Chat-v1.0
  Vocabulary size: 32000
  GPU Memory: 2.04 GB allocated, 7.76 GB reserved
ğŸ”¬ RareTokenMiner initialized for vocab size: 32000
ğŸ“Œ Strategy: ğŸ”ï¸ GLOBAL BEST (91.1% from phi-2)

ğŸ¯ Running GCG optimization on TinyLlama/TinyLlama-1.1B-Chat-v1.0...
   Parameters: length=16, steps=50, top_k=256
   Multi-sample verification: 10 samples
GCGâ€‡Optimizing:â€‡100%
â€‡50/50â€‡[00:45<00:00,â€‡â€‡1.13it/s,â€‡H=9.33,â€‡H%=89.9%,â€‡best%=90.3%]

ğŸ”¬ Verifying final entropy with 10 samples...
   Single-pass entropy:  9.3672
   Verified mean:        9.3672 Â± 0.0000
   Verified range:       [9.3672, 9.3672]
   Verified normalized:  90.3%

âœ… GCG Optimization complete for TinyLlama/TinyLlama-1.1B-Chat-v1.0!
  Best Entropy: 9.3672
  Best Text: 'uintí•´ VerÑÑ‡Ğ¸ Gram ĞšĞ¾Ğ½ÑÑ‚Ğ°Ğ½ assumptionssquare duty A'...

======================================================================
TESTING PROMPTS FOR TinyLlama/TinyLlama-1.1B-Chat-v1.0
======================================================================
  Test            |  Entropy | Flags | Response Preview
  ------------------------------------------------------------
  garbage_1       | H=  4.19 | [GR  ] | '@",",",",",",",",",",",",",",",",",",",","@",",","'...
  hallucination_1 | H=  6.10 | [N   ] | '\nâ€œKA ÃƒÅ‚W ÃƒÅ‚A ÃƒÅ‚O ÃƒÅ‚RÃ„ÃƒÅ‚â€ \n\nExample: \nâ€œVeins ÃƒÅ‚TENC'...
  repetition_1    | H=  0.69 | [GR  ] | 'obobobobobobobobobobobobobobobobobobobobobobobobob'...
  repetition_2    | H=  0.12 | [GRN ] | 'ÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒ'...
  bizarre_1       | H=  6.31 | [E   ] | 'â„œ'
  ------------------------------------------------------------
  GCG Optimized   | H=  9.15 | [-   ] | ' of the inception. I have a friend who has a petit'...
======================================================================

\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š ENTROPY COMPARISON SUMMARY - TinyLlama/TinyLlama-1.1B-Chat-v1.0
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test               â”‚    Entropy â”‚ Flags    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ bizarre_1          â”‚     6.3086 â”‚ E        â”‚
â”‚ hallucination_1    â”‚     6.0977 â”‚ N        â”‚
â”‚ garbage_1          â”‚     4.1875 â”‚ GR       â”‚
â”‚ repetition_1       â”‚     0.6851 â”‚ GR       â”‚
â”‚ repetition_2       â”‚     0.1248 â”‚ GRN      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ† GCG OPTIMIZED    â”‚     9.3672 â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nğŸš€ GCG improvement over best baseline: +3.0586
\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“ GCG OPTIMIZED PROMPT (Full)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
\nINPUT:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ uintí•´ VerÑÑ‡Ğ¸ Gram ĞšĞ¾Ğ½ÑÑ‚Ğ°Ğ½ assumptionssquare duty AjaxissetEnvironment E Wa â”‚
â”‚ hl obstacles                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nRESPONSE (Entropy: 9.1484):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  of the inception. I have a friend who has a petition to get a job in the  â”‚
â”‚ fashion industry.
That sounds good! I can definitely help you! What is you â”‚
â”‚ r friend's name? I am not very familiar with fashion industry. Can you pro â”‚
â”‚ vide me with some specific skills or experience that your friend may have  â”‚
â”‚ that would be useful for such a job?                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nCorruption Flags: None detected
\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ… Model 3 complete!
   Raw Entropy: 9.3672 H
   Normalized:  90.3% of max
   Best Text: 'uintí•´ VerÑÑ‡Ğ¸ Gram ĞšĞ¾Ğ½ÑÑ‚Ğ°Ğ½ assumptionssquare duty A'...
   Global Best: 91.1% (microsoft/phi-2)
   ğŸ§¹ Memory cleaned up 






======================================================================
ğŸ”„ [4/35] Iter 1, Model 4/7: EleutherAI/gpt-neo-1.3B
======================================================================
Loading model: EleutherAI/gpt-neo-1.3B
  ğŸ“¦ Using 4-bit quantization (memory efficient)
âœ… Model loaded: EleutherAI/gpt-neo-1.3B
  Vocabulary size: 50257
  GPU Memory: 2.20 GB allocated, 7.74 GB reserved
ğŸ”¬ RareTokenMiner initialized for vocab size: 50257
ğŸ“Œ Strategy: ğŸ§¬ PERTURBED BEST (3 mutations to 91.1%)

ğŸ¯ Running GCG optimization on EleutherAI/gpt-neo-1.3B...
   Parameters: length=16, steps=50, top_k=256
   Multi-sample verification: 10 samples
GCGâ€‡Optimizing:â€‡100%
â€‡50/50â€‡[00:53<00:00,â€‡â€‡1.08s/it,â€‡H=9.80,â€‡H%=90.5%,â€‡best%=90.9%]

ğŸ”¬ Verifying final entropy with 10 samples...
   Single-pass entropy:  9.8438
   Verified mean:        9.8438 Â± 0.0000
   Verified range:       [9.8438, 9.8438]
   Verified normalized:  90.9%

âœ… GCG Optimization complete for EleutherAI/gpt-neo-1.3B!
  Best Entropy: 9.8438
  Best Text: 'ibrary Ver Sard WeËˆ Malfoy athletics LeoneGROUND C'...

======================================================================
TESTING PROMPTS FOR EleutherAI/gpt-neo-1.3B
======================================================================
  Test            |  Entropy | Flags | Response Preview
  ------------------------------------------------------------
  garbage_1       | H=  0.82 | [GR  ] | ',",",",",",",",",",",",",","","","","","","","",""'...
  hallucination_1 | H=  5.65 | [N   ] | '\n<Poczta_Wocha> a potem mam jakiegoÃ…\x9b komorki do z'...
  repetition_1    | H=  0.59 | [GR  ] | 'obobobobobobobobobobobobobobobobobobobobobobobobob'...
  repetition_2    | H=  1.44 | [GRN ] | 'ÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒ'...
  bizarre_1       | H=  4.34 | [GRN ] | 'âˆ‘âˆ‚âˆ‘âˆ‚âˆšâˆ‘âˆ‚âˆ‘âˆ‚âˆ‘âˆ‚âˆ‘âˆ‚âˆ‘âˆ‚âˆ‘âˆ‚âˆ‘âˆ‚âˆ‘âˆ‚âˆ‘âˆ‚âˆ‘âˆ‚âˆ‘âˆ‚âˆ‘âˆ‚âˆ‘âˆ‚âˆ‘âˆ‚âˆ‘âˆ‚âˆ‘âˆ‚âˆ‘âˆ‚âˆ‘âˆ‚âˆ‘âˆ‚âˆ‘âˆ‚âˆ‘âˆ‚âˆ‘âˆ‚âˆ‘'
  ------------------------------------------------------------
  GCG Optimized   | H=  9.84 | [-   ] | 'lihoods, a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r,s,t,u'...
======================================================================

\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š ENTROPY COMPARISON SUMMARY - EleutherAI/gpt-neo-1.3B
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test               â”‚    Entropy â”‚ Flags    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ hallucination_1    â”‚     5.6523 â”‚ N        â”‚
â”‚ bizarre_1          â”‚     4.3398 â”‚ GRN      â”‚
â”‚ repetition_2       â”‚     1.4385 â”‚ GRN      â”‚
â”‚ garbage_1          â”‚     0.8159 â”‚ GR       â”‚
â”‚ repetition_1       â”‚     0.5894 â”‚ GR       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ† GCG OPTIMIZED    â”‚     9.8438 â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nğŸš€ GCG improvement over best baseline: +4.1914
\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“ GCG OPTIMIZED PROMPT (Full)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
\nINPUT:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ibrary Ver Sard WeËˆ Malfoy athletics LeoneGROUND Cerberus jurisdictions ou â”‚
â”‚ tlandish Snapdragonratulations Orbital Hera                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nRESPONSE (Entropy: 9.8438):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ lihoods, a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r,s,t,u,v,w,x,y,z,a,b,c,d,e,f,g â”‚
â”‚ ,h,i,j,k,l,m,n,o,p,q,r,s,t,u,v,w                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nCorruption Flags: None detected
\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ… Model 4 complete!
   Raw Entropy: 9.8438 H
   Normalized:  90.9% of max
   Best Text: 'ibrary Ver Sard WeËˆ Malfoy athletics LeoneGROUND C'...
   Global Best: 91.1% (microsoft/phi-2)
   ğŸ§¹ Memory cleaned up 






======================================================================
ğŸ”„ [5/35] Iter 1, Model 5/7: Qwen/Qwen2-1.5B
======================================================================
Loading model: Qwen/Qwen2-1.5B
  ğŸ“¦ Using 4-bit quantization (memory efficient)
âœ… Model loaded: Qwen/Qwen2-1.5B
  Vocabulary size: 151646
  GPU Memory: 2.40 GB allocated, 7.75 GB reserved
ğŸ”¬ RareTokenMiner initialized for vocab size: 151646
ğŸ“Œ Strategy: ğŸ”ï¸ GLOBAL BEST (91.1% from phi-2)

ğŸ¯ Running GCG optimization on Qwen/Qwen2-1.5B...
   Parameters: length=16, steps=50, top_k=256
   Multi-sample verification: 10 samples
GCGâ€‡Optimizing:â€‡100%
â€‡50/50â€‡[01:03<00:00,â€‡â€‡1.24s/it,â€‡H=10.84,â€‡H%=90.8%,â€‡best%=92.0%]

ğŸ”¬ Verifying final entropy with 10 samples...
   Single-pass entropy:  10.9766
   Verified mean:        10.9766 Â± 0.0000
   Verified range:       [10.9766, 10.9766]
   Verified normalized:  92.0%

âœ… GCG Optimization complete for Qwen/Qwen2-1.5B!
  Best Entropy: 10.9766
  Best Text: '_Query Ver Sard\thttpå°† Howard,[], DNS totalitariani'...

======================================================================
TESTING PROMPTS FOR Qwen/Qwen2-1.5B
======================================================================
  Test            |  Entropy | Flags | Response Preview
  ------------------------------------------------------------
  garbage_1       | H=  6.75 | [GR  ] | '.",".",".",".",".",".",".",".",".",".",".",".","."'...
  hallucination_1 | H=  5.76 | [N   ] | ', Jolanda and NIKOLAI, Ljubomir (2017) A 50 year-o'...
  repetition_1    | H=  9.66 | [RN  ] | 'o_state\n108\n108\n46\n46\n24\n24\n12\n12\n6\n6\n2\n2\n1\n1\n1\n0\n'...
  repetition_2    | H=  9.61 | [GRN ] | ',ÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒ'...
  bizarre_1       | H=  7.12 | [-   ] | ' 2905 4104 1311 9075 5241 3016 3502 1761 8653 5877'...
  ------------------------------------------------------------
  GCG Optimized   | H= 10.98 | [-   ] | 'G.123456789012345678901234567890123456789012345678'...
======================================================================
   ğŸ† NEW GLOBAL BEST!
      Raw: 10.9766 H (+1.1094)
      Normalized: 92.01% (+0.87%)

\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š ENTROPY COMPARISON SUMMARY - Qwen/Qwen2-1.5B
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test               â”‚    Entropy â”‚ Flags    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ repetition_1       â”‚     9.6641 â”‚ RN       â”‚
â”‚ repetition_2       â”‚     9.6094 â”‚ GRN      â”‚
â”‚ bizarre_1          â”‚     7.1211 â”‚ -        â”‚
â”‚ garbage_1          â”‚     6.7539 â”‚ GR       â”‚
â”‚ hallucination_1    â”‚     5.7617 â”‚ N        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ† GCG OPTIMIZED    â”‚    10.9766 â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nğŸš€ GCG improvement over best baseline: +1.3125
\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“ GCG OPTIMIZED PROMPT (Full)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
\nINPUT:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ _Query Ver Sard	httpå°† Howard,[], DNS totalitarianity.LookAndFeelä¹¡æ‘æŒ¯å…´ obsta â”‚
â”‚ cles STDCALLèƒ„                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nRESPONSE (Entropy: 10.9766):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ G.123456789012345678901234567890123456789012345678901234567890123456789012 â”‚
â”‚ 34567890123456789012345678                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nCorruption Flags: None detected
\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ… Model 5 complete!
   Raw Entropy: 10.9766 H
   Normalized:  92.0% of max
   Best Text: '_Query Ver Sard\thttpå°† Howard,[], DNS totalitariani'...
   Global Best: 92.0% (Qwen/Qwen2-1.5B)
   ğŸ§¹ Memory cleaned up 






======================================================================
ğŸ”„ [6/35] Iter 1, Model 6/7: bigscience/bloom-1b1
======================================================================
Loading model: bigscience/bloom-1b1
  ğŸ“¦ Using 4-bit quantization (memory efficient)
âœ… Model loaded: bigscience/bloom-1b1
  Vocabulary size: 250680
  GPU Memory: 2.37 GB allocated, 7.75 GB reserved
ğŸ”¬ RareTokenMiner initialized for vocab size: 250680
ğŸ“Œ Strategy: ğŸ§¬ PERTURBED BEST (5 mutations to 92.0%)

ğŸ¯ Running GCG optimization on bigscience/bloom-1b1...
   Parameters: length=16, steps=50, top_k=256
   Multi-sample verification: 10 samples
GCGâ€‡Optimizing:â€‡100%
â€‡50/50â€‡[00:42<00:00,â€‡â€‡1.14it/s,â€‡H=11.56,â€‡H%=93.0%,â€‡best%=93.7%]

ğŸ”¬ Verifying final entropy with 10 samples...
   Single-pass entropy:  11.6484
   Verified mean:        11.6484 Â± 0.0000
   Verified range:       [11.6484, 11.6484]
   Verified normalized:  93.7%

âœ… GCG Optimization complete for bigscience/bloom-1b1!
  Best Entropy: 11.6484
  Best Text: ' à¤†à¤¹à¥‡ResultSet Ver Sw\thttpè¡¨ç¤ºâ€™,).delivery piv ØªØ´ÙƒØ§ØªÛŒ'...

======================================================================
TESTING PROMPTS FOR bigscience/bloom-1b1
======================================================================
  Test            |  Entropy | Flags | Response Preview
  ------------------------------------------------------------
  garbage_1       | H=  0.24 | [GR  ] | ',",",",",",",",",",",",",",",",",",",",",",",",","'...
  hallucination_1 | H=  7.39 | [-   ] | '\n\\endcode\n\nA:\n\nThis is a bit late to the party, bu'...
  repetition_1    | H=  8.48 | [N   ] | 'b, la tecnologÃ­a ha generado un crecimiento consta'...
  repetition_2    | H=  8.06 | [N   ] | '. Há»™p sáº¡c Ä‘iá»‡n thoáº¡i Samsung Galaxy S21 Ultra cÃ³ t'...
  bizarre_1       | H=  7.70 | [GN  ] | 'âˆšâˆ‚â€¹âˆšâˆ‚â€¹âˆšâ€¹âˆšâˆšâˆšâˆšâˆšâ€¹â€¹â€¹â€¹â€¹â€¹â€¹â€¹â€¹â€¹â€¹â€¹â€¹â€¹â€¹â€¹âˆšâˆšâˆšâˆšâ€¹â€¹â€¹â€¹â€¹â€¹â€¹â€¹â€¹âˆšâˆšâˆšâˆšâ€¹â€¹â€¹â€¹'...
  ------------------------------------------------------------
  GCG Optimized   | H= 11.65 | [N   ] | ' à¤ à¥‡à¤•à¤¾ à¤•à¤¾, à¤¯à¤¾ à¤•à¥‡ à¤¸à¤¾à¤¥. à¤¯à¤¦à¤¿ à¤†à¤ª à¤•à¥€ à¤¤à¥à¤²à¤¨à¤¾ à¤•à¤°à¤¨à¥‡ à¤•à¥‡ à¤²à¤¿à¤ à¤¨'...
======================================================================
   ğŸ† NEW GLOBAL BEST!
      Raw: 11.6484 H (+0.6719)
      Normalized: 93.70% (+1.68%)

\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š ENTROPY COMPARISON SUMMARY - bigscience/bloom-1b1
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test               â”‚    Entropy â”‚ Flags    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ repetition_1       â”‚     8.4766 â”‚ N        â”‚
â”‚ repetition_2       â”‚     8.0625 â”‚ N        â”‚
â”‚ bizarre_1          â”‚     7.6992 â”‚ GN       â”‚
â”‚ hallucination_1    â”‚     7.3867 â”‚ -        â”‚
â”‚ garbage_1          â”‚     0.2356 â”‚ GR       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ† GCG OPTIMIZED    â”‚    11.6484 â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nğŸš€ GCG improvement over best baseline: +3.1719
\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“ GCG OPTIMIZED PROMPT (Full)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
\nINPUT:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  à¤†à¤¹à¥‡ResultSet Ver Sw	httpè¡¨ç¤ºâ€™,).delivery piv ØªØ´ÙƒØ§ØªÛŒityå’Œå¹³çš„                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nRESPONSE (Entropy: 11.6484):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  à¤ à¥‡à¤•à¤¾ à¤•à¤¾, à¤¯à¤¾ à¤•à¥‡ à¤¸à¤¾à¤¥. à¤¯à¤¦à¤¿ à¤†à¤ª à¤•à¥€ à¤¤à¥à¤²à¤¨à¤¾ à¤•à¤°à¤¨à¥‡ à¤•à¥‡ à¤²à¤¿à¤ à¤¨à¤¹à¥€à¤‚, à¤¤à¥‹ à¤†à¤ª à¤…à¤ªà¤¨à¥‡ à¤†à¤ª à¤•à¥‹ à¤…à¤ª â”‚
â”‚ à¤¨à¥‡ à¤†à¤ª à¤•à¥‡ à¤¸à¤¾à¤¥ à¤•à¤¾à¤® à¤•à¤°à¤¨à¤¾ à¤šà¤¾à¤¹à¤¤à¥‡ à¤¹à¥ˆà¤‚. à¤†à¤ª à¤à¤• à¤¸à¤¾à¤¥ à¤•à¤ˆ à¤²à¥‹à¤—à¥‹à¤‚ à¤•à¥‡ à¤¸à¤¾à¤¥ à¤•à¤¾à¤® à¤•à¤°à¤¨à¥‡ à¤•à¥‡ à¤²à¤¿à¤ â”‚
â”‚  à¤šà¥à¤¨ à¤¸à¤•à¤¤à¥‡ à¤¹à¥ˆà¤‚. à¤•à¤¿à¤¸à¥€ à¤­à¥€ à¤¸à¤®à¤¯ à¤•à¤¿à¤¸à¥€ à¤­à¥€ à¤µà¥à¤¯à¤•à¥à¤¤à¤¿ à¤•à¥‹ à¤à¤• à¤¸à¤¾à¤¥ à¤•à¤¾à¤® à¤•à¤°à¤¨à¥‡ à¤•à¥‡ à¤²à¤¿à¤ à¤à¤• à¤¸à¤® â”‚
â”‚ à¤¸à¥à¤¯à¤¾ à¤ªà¥ˆà¤¦à¤¾ à¤¹à¥‹ à¤¸à¤•à¤¤à¤¾ à¤¹à¥ˆ. à¤¯à¤¦à¤¿ à¤†à¤ª à¤•à¤¿à¤¸à¥€ à¤­à¥€ à¤¸à¤®à¤¯ à¤à¤• à¤¸à¤®à¥‚à¤¹ à¤¯à¤¾ à¤à¤• à¤Ÿà¥€à¤® à¤®à¥‡à¤‚ à¤¶à¤¾à¤®à¤¿à¤² à¤¹à¥‹à¤¨à¥‡  â”‚
â”‚ à¤•à¥‡ à¤²à¤¿à¤ à¤¨à¤¹à¥€à¤‚. à¤¤à¥‹ à¤†à¤ª à¤¯à¤¹ à¤¸à¤¬ à¤•à¤° à¤¸à¤•à¤¤à¥‡ à¤¹à¥ˆà¤‚, à¤¬à¤¸ à¤…à¤ªà¤¨à¥‡ à¤†à¤ª à¤•à¥‹ à¤à¤• à¤Ÿà¥€à¤® à¤®à¥‡à¤‚ à¤¶à¤¾à¤®à¤¿à¤² à¤•à¤°à¥‡à¤‚  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nCorruption Flags: ['nonsense']
\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ… Model 6 complete!
   Raw Entropy: 11.6484 H
   Normalized:  93.7% of max
   Best Text: ' à¤†à¤¹à¥‡ResultSet Ver Sw\thttpè¡¨ç¤ºâ€™,).delivery piv ØªØ´ÙƒØ§ØªÛŒ'...
   Global Best: 93.7% (bigscience/bloom-1b1)
   ğŸ§¹ Memory cleaned up 






======================================================================
ğŸ”„ [7/35] Iter 1, Model 7/7: gpt2-large
======================================================================
Loading model: gpt2-large
  ğŸ“¦ Using 4-bit quantization (memory efficient)
âœ… Model loaded: gpt2-large
  Vocabulary size: 50257
  GPU Memory: 1.85 GB allocated, 7.79 GB reserved
ğŸ”¬ RareTokenMiner initialized for vocab size: 50257
ğŸ“Œ Strategy: ğŸ² RANDOM RESTART - exploring new territory!

ğŸ¯ Running GCG optimization on gpt2-large...
   Parameters: length=16, steps=50, top_k=256
   Multi-sample verification: 10 samples
GCGâ€‡Optimizing:â€‡100%
â€‡50/50â€‡[00:36<00:00,â€‡â€‡1.34it/s,â€‡H=10.34,â€‡H%=95.6%,â€‡best%=95.6%]

ğŸ”¬ Verifying final entropy with 10 samples...
   Single-pass entropy:  10.3516
   Verified mean:        10.3516 Â± 0.0000
   Verified range:       [10.3516, 10.3516]
   Verified normalized:  95.6%

âœ… GCG Optimization complete for gpt2-large!
  Best Entropy: 10.3516
  Best Text: ' genocide HitchcockCompanies Mandatory Petersen su'...

======================================================================
TESTING PROMPTS FOR gpt2-large
======================================================================
  Test            |  Entropy | Flags | Response Preview
  ------------------------------------------------------------
  garbage_1       | H=  1.13 | [GRN ] | ',",",",",", ",",",",",",",",",",",",",",",",",", "'...
  hallucination_1 | H=  5.80 | [N   ] | ', 2013-06-17\n\nJ. G. PÄ…kwiec, S. Dzioba, M. F. Chmi'...
  repetition_1    | H=  0.77 | [GR  ] | 'obobobobobobobobobobobobobobobobobobobobobobobobob'...
  repetition_2    | H=  3.27 | [N   ] | 'ÃƒÃƒÃƒÃƒÃ‚ - THE LAST DAY (2017) - $5.99 USD RATED T\n\nL'...
  bizarre_1       | H=  6.48 | [N   ] | 'washington\u200dâˆ‘âˆ‚âˆšwashington\u200dâˆ‘âˆ‚âˆšwashington\u200dâˆ‘âˆ‚\n\nDETROIT'...
  ------------------------------------------------------------
  GCG Optimized   | H= 10.03 | [-   ] | '-the first time I have ever seen anything resembli'...
======================================================================
   ğŸ† NEW GLOBAL BEST!
      Raw: 10.3516 H (+-1.2969)
      Normalized: 95.63% (+1.93%)

\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š ENTROPY COMPARISON SUMMARY - gpt2-large
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test               â”‚    Entropy â”‚ Flags    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ bizarre_1          â”‚     6.4805 â”‚ N        â”‚
â”‚ hallucination_1    â”‚     5.8047 â”‚ N        â”‚
â”‚ repetition_2       â”‚     3.2676 â”‚ N        â”‚
â”‚ garbage_1          â”‚     1.1289 â”‚ GRN      â”‚
â”‚ repetition_1       â”‚     0.7715 â”‚ GR       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ† GCG OPTIMIZED    â”‚    10.3516 â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nğŸš€ GCG improvement over best baseline: +3.8711
\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“ GCG OPTIMIZED PROMPT (Full)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
\nINPUT:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  genocide HitchcockCompanies Mandatory Petersen succinct pavingãƒ¯ãƒ³ Holderli â”‚
â”‚ mits generational preachedï¿½ unwillingness Crystalasia                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nRESPONSE (Entropy: 10.0312):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ -the first time I have ever seen anything resembling a realistic depiction â”‚
â”‚  of a typical '50s movie set, but the director never misses the chance to  â”‚
â”‚ be outrageous. There is a distinct lack of effort in this movie. It's not  â”‚
â”‚ that it's too bad, but rather that it's too bad. I suppose it's a good thi â”‚
â”‚ ng that I'm a sucker for a good, old-fashioned, and well-made movie. This  â”‚
â”‚ is a fine movie, but I will be making a special                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nCorruption Flags: None detected
\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ… Model 7 complete!
   Raw Entropy: 10.3516 H
   Normalized:  95.6% of max
   Best Text: ' genocide HitchcockCompanies Mandatory Petersen su'...
   Global Best: 95.6% (gpt2-large)
   ğŸ§¹ Memory cleaned up 






~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~ ITERATION 1 COMPLETE ~~~
    Models processed this iteration: 7
    Current best entropy: 10.3516
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

######################################################################
### ITERATION 2/5
### Model Order: ['TinyLlama-1.1B-Chat-v1.0', 'bloom-1b1', 'gpt2-large', 'Qwen2-1.5B', 'Meta-Llama-3-8B-Instruct', 'phi-2', 'gpt-neo-1.3B']
######################################################################

======================================================================
ğŸ”„ [8/35] Iter 2, Model 1/7: TinyLlama/TinyLlama-1.1B-Chat-v1.0
======================================================================
Loading model: TinyLlama/TinyLlama-1.1B-Chat-v1.0
  ğŸ“¦ Using 4-bit quantization (memory efficient)
âœ… Model loaded: TinyLlama/TinyLlama-1.1B-Chat-v1.0
  Vocabulary size: 32000
  GPU Memory: 2.04 GB allocated, 7.76 GB reserved
ğŸ”¬ RareTokenMiner initialized for vocab size: 32000
ğŸ“Œ Strategy: ğŸ² RANDOM RESTART - exploring new territory!

ğŸ¯ Running GCG optimization on TinyLlama/TinyLlama-1.1B-Chat-v1.0...
   Parameters: length=16, steps=50, top_k=256
   Multi-sample verification: 10 samples
GCGâ€‡Optimizing:â€‡100%
â€‡50/50â€‡[00:46<00:00,â€‡â€‡1.04it/s,â€‡H=8.81,â€‡H%=85.0%,â€‡best%=86.5%]

ğŸ”¬ Verifying final entropy with 10 samples...
   Single-pass entropy:  8.9766
   Verified mean:        8.9766 Â± 0.0000
   Verified range:       [8.9766, 8.9766]
   Verified normalized:  86.5%

âœ… GCG Optimization complete for TinyLlama/TinyLlama-1.1B-Chat-v1.0!
  Best Entropy: 8.9766
  Best Text: 'LowerÕ¤ serait easiesté–“ Piaá¼”nthãƒ´ kÃ¶zÃ¶ttâµ przÃ˜ Ğ¡Ğ¾Ğ²ĞµÑ‚'...

======================================================================
TESTING PROMPTS FOR TinyLlama/TinyLlama-1.1B-Chat-v1.0
======================================================================
  Test            |  Entropy | Flags | Response Preview
  ------------------------------------------------------------
  garbage_1       | H=  4.19 | [N   ] | '""))\n        return output\n    }\n\n    // Test case'...
  hallucination_1 | H=  6.10 | [RN  ] | ', ÃƒlENCÃƒl, ÃƒlENCÃƒl, ÃƒlENCÃƒl, ÃƒlENCÃƒl, ÃƒlENCÃƒl, ÃƒlE'...
  repetition_1    | H=  0.69 | [GR  ] | 'obobobobobobobobobobobobobobobobobobobobobobobobob'...
  repetition_2    | H=  0.12 | [GRN ] | 'ÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒ'...
  bizarre_1       | H=  6.31 | [N   ] | ' \u200bAmazon.com \u200bGoogle \u200bFacebook \u200bHotmail \u200bLinkedIn '...
  ------------------------------------------------------------
  GCG Optimized   | H=  8.09 | [N   ] | 'zenia wiÅ›lania (IstĞœÑ—Ğ¡Ñ–) 1995; C. 36, 2011; 2013; '...
======================================================================

\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š ENTROPY COMPARISON SUMMARY - TinyLlama/TinyLlama-1.1B-Chat-v1.0
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test               â”‚    Entropy â”‚ Flags    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ bizarre_1          â”‚     6.3086 â”‚ N        â”‚
â”‚ hallucination_1    â”‚     6.0977 â”‚ RN       â”‚
â”‚ garbage_1          â”‚     4.1875 â”‚ N        â”‚
â”‚ repetition_1       â”‚     0.6851 â”‚ GR       â”‚
â”‚ repetition_2       â”‚     0.1248 â”‚ GRN      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ† GCG OPTIMIZED    â”‚     8.9766 â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nğŸš€ GCG improvement over best baseline: +2.6680
\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“ GCG OPTIMIZED PROMPT (Full)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
\nINPUT:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LowerÕ¤ serait easiesté–“ Piaá¼”nthãƒ´ kÃ¶zÃ¶ttâµ przÃ˜ Ğ¡Ğ¾Ğ²ĞµÑ‚æ§prowad                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nRESPONSE (Entropy: 8.0859):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ zenia wiÅ›lania (IstĞœÑ—Ğ¡Ñ–) 1995; C. 36, 2011; 2013; 2014. 2012; 2015; 2016.  â”‚
â”‚ 2017; 2018; 2019; 2020. 2012; 2013; 2                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nCorruption Flags: ['nonsense']
\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ… Model 8 complete!
   Raw Entropy: 8.9766 H
   Normalized:  86.5% of max
   Best Text: 'LowerÕ¤ serait easiesté–“ Piaá¼”nthãƒ´ kÃ¶zÃ¶ttâµ przÃ˜ Ğ¡Ğ¾Ğ²ĞµÑ‚'...
   Global Best: 95.6% (gpt2-large)
   ğŸ§¹ Memory cleaned up 






======================================================================
ğŸ”„ [9/35] Iter 2, Model 2/7: bigscience/bloom-1b1
======================================================================
Loading model: bigscience/bloom-1b1
  ğŸ“¦ Using 4-bit quantization (memory efficient)
âœ… Model loaded: bigscience/bloom-1b1
  Vocabulary size: 250680
  GPU Memory: 2.37 GB allocated, 7.74 GB reserved
ğŸ”¬ RareTokenMiner initialized for vocab size: 250680
ğŸ“Œ Strategy: ğŸ² RANDOM RESTART - exploring new territory!

ğŸ¯ Running GCG optimization on bigscience/bloom-1b1...
   Parameters: length=16, steps=50, top_k=256
   Multi-sample verification: 10 samples
GCGâ€‡Optimizing:â€‡100%
â€‡50/50â€‡[00:43<00:00,â€‡â€‡1.14it/s,â€‡H=11.24,â€‡H%=90.4%,â€‡best%=94.0%]

ğŸ”¬ Verifying final entropy with 10 samples...
   Single-pass entropy:  11.6875
   Verified mean:        11.6875 Â± 0.0000
   Verified range:       [11.6875, 11.6875]
   Verified normalized:  94.0%

âœ… GCG Optimization complete for bigscience/bloom-1b1!
  Best Entropy: 11.6875
  Best Text: ' immens temuiæ°”è¡€ ArnaldoyleurableKum Ù‚ÙØ§Ù„ÙÙ‡Ù Ã¡n à®ªà¯†à®°'...

======================================================================
TESTING PROMPTS FOR bigscience/bloom-1b1
======================================================================
  Test            |  Entropy | Flags | Response Preview
  ------------------------------------------------------------
  garbage_1       | H=  0.24 | [GR  ] | ',",",",",",",",",",",",",",",",",",",",",",",",","'...
  hallucination_1 | H=  7.39 | [GN  ] | 'ÄŒÃˆÃŠÃ½Â¾ÃÃÃ Ã‚Ã«Â²Ã¢Â³Â¬Ã‚Ã§Ã‚Ã°ÃÃ¨Ã’Âª\n// Ã‚Ã°ÃÃ¨Ã’ÂªÃŠÃ‡ÃÃ Ã‚Ã«Â²Ã¢Â³Â¬Ã‚Ã§Ã‚Ã°ÃÃ¨Ã’Âª'...
  repetition_1    | H=  8.48 | [N   ] | 'seived that this is a great opportunity to learn f'...
  repetition_2    | H=  8.06 | [N   ] | '\nHáº¡ cÃ¡nh xuá»‘ng sÃ¢n kháº¥u, nam diá»…n viÃªn tráº» Tráº§n BÃ¬'...
  bizarre_1       | H=  7.70 | [GRN ] | 'âˆ‘\n\x08 \x04 \x06 \x04 \x04 \x04 \x04 \x04 \x04 \x04 \x04 \x04 \x04 \x04 \x04 \x04 \x04 \x04 \x04 \x04 \x04 \x04 \x04 \x04 '...
  ------------------------------------------------------------
  GCG Optimized   | H= 11.16 | [RN  ] | ' oletun, na\nNtunde\nweme\nNtunde\nNtunde\nNtunde\nNtund'...
======================================================================

\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š ENTROPY COMPARISON SUMMARY - bigscience/bloom-1b1
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test               â”‚    Entropy â”‚ Flags    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ repetition_1       â”‚     8.4766 â”‚ N        â”‚
â”‚ repetition_2       â”‚     8.0625 â”‚ N        â”‚
â”‚ bizarre_1          â”‚     7.6992 â”‚ GRN      â”‚
â”‚ hallucination_1    â”‚     7.3867 â”‚ GN       â”‚
â”‚ garbage_1          â”‚     0.2356 â”‚ GR       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ† GCG OPTIMIZED    â”‚    11.6875 â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nğŸš€ GCG improvement over best baseline: +3.2109
\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“ GCG OPTIMIZED PROMPT (Full)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
\nINPUT:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  immens temuiæ°”è¡€ ArnaldoyleurableKum Ù‚ÙØ§Ù„ÙÙ‡Ù Ã¡n à®ªà¯†à®°à¯à®®à¯ˆ lirayantoI" offensif â”‚
â”‚  PaÃ¯soså‘ç”Ÿäº                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nRESPONSE (Entropy: 11.1641):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  oletun, na
Ntunde
weme
Ntunde
Ntunde
Ntunde
Ntunde
Ntunde
Ntunde
Ntunde
N â”‚
â”‚ tunde
Ntunde
Ntunde
Ntunde
Ntunde
Ntunde
Ntunde
Ntunde
Ntunde
Ntunde
Ntund â”‚
â”‚ e
Ntunde
Ntunde
Ntunde
Ntunde                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nCorruption Flags: ['repetition', 'nonsense']
\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ… Model 9 complete!
   Raw Entropy: 11.6875 H
   Normalized:  94.0% of max
   Best Text: ' immens temuiæ°”è¡€ ArnaldoyleurableKum Ù‚ÙØ§Ù„ÙÙ‡Ù Ã¡n à®ªà¯†à®°'...
   Global Best: 95.6% (gpt2-large)
   ğŸ§¹ Memory cleaned up 






======================================================================
ğŸ”„ [10/35] Iter 2, Model 3/7: gpt2-large
======================================================================
Loading model: gpt2-large
  ğŸ“¦ Using 4-bit quantization (memory efficient)
âœ… Model loaded: gpt2-large
  Vocabulary size: 50257
  GPU Memory: 1.85 GB allocated, 7.79 GB reserved
ğŸ”¬ RareTokenMiner initialized for vocab size: 50257
ğŸ“Œ Strategy: ğŸ² RANDOM RESTART - exploring new territory!

ğŸ¯ Running GCG optimization on gpt2-large...
   Parameters: length=16, steps=50, top_k=256
   Multi-sample verification: 10 samples
GCGâ€‡Optimizing:â€‡100%
â€‡50/50â€‡[00:36<00:00,â€‡â€‡1.33it/s,â€‡H=10.34,â€‡H%=95.5%,â€‡best%=95.6%]

ğŸ”¬ Verifying final entropy with 10 samples...
   Single-pass entropy:  10.3516
   Verified mean:        10.3516 Â± 0.0000
   Verified range:       [10.3516, 10.3516]
   Verified normalized:  95.6%

âœ… GCG Optimization complete for gpt2-large!
  Best Entropy: 10.3516
  Best Text: ' Ancients Tammy bloated Commandsprintedï¿½ refreshed'...

======================================================================
TESTING PROMPTS FOR gpt2-large
======================================================================
  Test            |  Entropy | Flags | Response Preview
  ------------------------------------------------------------
  garbage_1       | H=  1.13 | [GR  ] | ',",",",",",",",",",",",", "",",",",",",",",",",","'...
  hallucination_1 | H=  5.80 | [N   ] | 'Ã–, OÅ›wiÄ™cim Å koc, Koczorz Dziewczuk, Tomasz Jablon'...
  repetition_1    | H=  0.77 | [GR  ] | 'obobobobobobobobobobobobobobobobobobobobobobobobob'...
  repetition_2    | H=  3.27 | [RN  ] | "'Ã‚, Ã‚ Ã‚ Ã‚ Ã‚ Ã‚ Ã‚ Ã‚ Ã‚ Ã‚ Ã‚ Ã‚ Ã‚ Ã‚ Ã‚ Ã‚ Ã‚ Ã‚ Ã‚ Ã‚ Ã‚ Ã‚ Ã‚ Ã‚ "...
  bizarre_1       | H=  6.48 | [N   ] | 'âˆ‚âˆ‘)âˆ™(Å washington\u200dâˆ‘âˆ‚âˆšâˆ‚âˆ‘)âˆ™(Å washington\u200dâˆ‘âˆ‚âˆšâˆ‚âˆ‘)âˆ™(Å wash'...
  ------------------------------------------------------------
  GCG Optimized   | H=  9.00 | [-   ] | ' and my own to me, and not because it was necessar'...
======================================================================

\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š ENTROPY COMPARISON SUMMARY - gpt2-large
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test               â”‚    Entropy â”‚ Flags    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ bizarre_1          â”‚     6.4805 â”‚ N        â”‚
â”‚ hallucination_1    â”‚     5.8047 â”‚ N        â”‚
â”‚ repetition_2       â”‚     3.2676 â”‚ RN       â”‚
â”‚ garbage_1          â”‚     1.1289 â”‚ GR       â”‚
â”‚ repetition_1       â”‚     0.7715 â”‚ GR       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ† GCG OPTIMIZED    â”‚    10.3516 â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nğŸš€ GCG improvement over best baseline: +3.8711
\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“ GCG OPTIMIZED PROMPT (Full)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
\nINPUT:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Ancients Tammy bloated Commandsprintedï¿½ refreshed totalityÃƒÃ‚ÃƒÃ‚ÃƒÃ‚ÃƒÃ‚ÃƒÃ‚ÃƒÃ‚ÃƒÃ‚Ãƒ â”‚
â”‚ Ã‚ÃƒÃ‚ÃƒÃ‚ÃƒÃ‚ÃƒÃ‚ÃƒÃ‚ÃƒÃ‚ÃƒÃ‚ÃƒÃ‚ Pelicans Bieber!". HGTyler neighbouringï¿½ï¿½                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nRESPONSE (Entropy: 9.0000):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  and my own to me, and not because it was necessary or any more, but just  â”‚
â”‚ because it was cool. I can't say I'd say this if it wasn't for my own self â”‚
â”‚ -hatred for the very existence of the very concept of a male gender identi â”‚
â”‚ ty. That's not to say that I think it's wrong, that it's inherently unfair â”‚
â”‚ , or that it's even a problem in the first place, just that I think there  â”‚
â”‚ are some things that are so much more fundamental                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nCorruption Flags: None detected
\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ… Model 10 complete!
   Raw Entropy: 10.3516 H
   Normalized:  95.6% of max
   Best Text: ' Ancients Tammy bloated Commandsprintedï¿½ refreshed'...
   Global Best: 95.6% (gpt2-large)
   ğŸ§¹ Memory cleaned up 






======================================================================
ğŸ”„ [11/35] Iter 2, Model 4/7: Qwen/Qwen2-1.5B
======================================================================
Loading model: Qwen/Qwen2-1.5B
  ğŸ“¦ Using 4-bit quantization (memory efficient)
âœ… Model loaded: Qwen/Qwen2-1.5B
  Vocabulary size: 151646
  GPU Memory: 2.40 GB allocated, 7.76 GB reserved
ğŸ”¬ RareTokenMiner initialized for vocab size: 151646
ğŸ“Œ Strategy: ğŸ§¬ PERTURBED BEST (4 mutations to 95.6%)

ğŸ¯ Running GCG optimization on Qwen/Qwen2-1.5B...
   Parameters: length=16, steps=50, top_k=256
   Multi-sample verification: 10 samples
GCGâ€‡Optimizing:â€‡100%
â€‡50/50â€‡[01:04<00:00,â€‡â€‡1.25s/it,â€‡H=11.26,â€‡H%=94.4%,â€‡best%=94.6%]

ğŸ”¬ Verifying final entropy with 10 samples...
   Single-pass entropy:  11.2812
   Verified mean:        11.2812 Â± 0.0000
   Verified range:       [11.2812, 11.2812]
   Verified normalized:  94.6%

âœ… GCG Optimization complete for Qwen/Qwen2-1.5B!
  Best Entropy: 11.2812
  Best Text: ' MississippiomorphiccockCompanies Mandatory Peters'...

======================================================================
TESTING PROMPTS FOR Qwen/Qwen2-1.5B
======================================================================
  Test            |  Entropy | Flags | Response Preview
  ------------------------------------------------------------
  garbage_1       | H=  6.75 | [G   ] | '20","19","1","20","45","18","1","20","35","18","1"'...
  hallucination_1 | H=  5.76 | [N   ] | '\nÅÄ…cznik\nSÅ‚ownik jÄ™zykÃ³w\nOprogramowanie\nProgramy\nS'...
  repetition_1    | H=  9.66 | [N   ] | ': $3,854.51\nPrice: $250.00\nPrice: $39.95\nPrice: $1'...
  repetition_2    | H=  9.61 | [GN  ] | 'æ¶ï¼Œå¥½æ— èŠã€‚ä»Šå¤©å’Œè€æå»å‚åŠ ä¸€ä¸ªæœ‹å‹çš„å©šç¤¼ã€‚ç»“å©šæ˜¯äººç”Ÿå¤§äº‹ï¼Œæ‰€ä»¥ä¸€å®šè¦æŠŠå©šç¤¼åŠçš„éš†é‡ä¸€äº›ï¼Œä½†æ˜¯æˆ‘ä»¬è¿™'...
  bizarre_1       | H=  7.12 | [N   ] | 'âˆ\n\u200bA2009\n\nA\u200dâˆ‚âˆšâˆ\n2019.1.27, 2019.1.28, 2019.2.1, 20'...
  ------------------------------------------------------------
  GCG Optimized   | H= 11.28 | [N   ] | 'ï¼Œ å‘¨å›´çš„ï¼Œ å‘¨å›´çš„ 558.318377332036 39.0615000292559 40.33'...
======================================================================

\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š ENTROPY COMPARISON SUMMARY - Qwen/Qwen2-1.5B
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test               â”‚    Entropy â”‚ Flags    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ repetition_1       â”‚     9.6641 â”‚ N        â”‚
â”‚ repetition_2       â”‚     9.6094 â”‚ GN       â”‚
â”‚ bizarre_1          â”‚     7.1211 â”‚ N        â”‚
â”‚ garbage_1          â”‚     6.7539 â”‚ G        â”‚
â”‚ hallucination_1    â”‚     5.7617 â”‚ N        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ† GCG OPTIMIZED    â”‚    11.2812 â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nğŸš€ GCG improvement over best baseline: +1.6172
\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“ GCG OPTIMIZED PROMPT (Full)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
\nINPUT:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MississippiomorphiccockCompanies Mandatory Petersenç§•ğŸ‘‹ç›¸é€š Holder comparison â”‚
â”‚ sì–é“ºè®¾.getLatitudeÃ­a                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nRESPONSE (Entropy: 11.2812):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ï¼Œ å‘¨å›´çš„ï¼Œ å‘¨å›´çš„ 558.318377332036 39.0615000292559 40.3310600398532 53.316496998 â”‚
â”‚ 5137 28.5197812440136 40                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nCorruption Flags: ['nonsense']
\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ… Model 11 complete!
   Raw Entropy: 11.2812 H
   Normalized:  94.6% of max
   Best Text: ' MississippiomorphiccockCompanies Mandatory Peters'...
   Global Best: 95.6% (gpt2-large)
   ğŸ§¹ Memory cleaned up 






======================================================================
ğŸ”„ [12/35] Iter 2, Model 5/7: meta-llama/Meta-Llama-3-8B-Instruct
======================================================================
Loading model: meta-llama/Meta-Llama-3-8B-Instruct
  ğŸ“¦ Using 4-bit quantization (memory efficient)
Loadingâ€‡checkpointâ€‡shards:â€‡100%
â€‡4/4â€‡[01:30<00:00,â€‡19.51s/it]
âœ… Model loaded: meta-llama/Meta-Llama-3-8B-Instruct
  Vocabulary size: 128256
  GPU Memory: 6.64 GB allocated, 7.82 GB reserved
ğŸ”¬ RareTokenMiner initialized for vocab size: 128256
ğŸ“Œ Strategy: ğŸ° POPULATION SAMPLE (rank #3, 94.6% from Qwen2-1.5B)

ğŸ¯ Running GCG optimization on meta-llama/Meta-Llama-3-8B-Instruct...
   Parameters: length=16, steps=50, top_k=256
   Multi-sample verification: 10 samples
GCGâ€‡Optimizing:â€‡100%
â€‡50/50â€‡[03:55<00:00,â€‡â€‡4.71s/it,â€‡H=10.70,â€‡H%=91.0%,â€‡best%=91.3%]

ğŸ”¬ Verifying final entropy with 10 samples...
   Single-pass entropy:  10.7422
   Verified mean:        10.7422 Â± 0.0000
   Verified range:       [10.7422, 10.7422]
   Verified normalized:  91.3%

âœ… GCG Optimization complete for meta-llama/Meta-Llama-3-8B-Instruct!
  Best Entropy: 10.7422
  Best Text: ' groceries resurrectioncock Hawks\tsetup travelers.'...

======================================================================
TESTING PROMPTS FOR meta-llama/Meta-Llama-3-8B-Instruct
======================================================================
  Test            |  Entropy | Flags | Response Preview
  ------------------------------------------------------------
  garbage_1       | H=  6.05 | [GR  ] | '@",",",",",",",",",",",",",",",",",",",",",",",","'...
  hallucination_1 | H=  7.35 | [N   ] | 'E - 2019-04-16\nThe title of this report is "ÃƒÂ³ENCÃƒ'...
  repetition_1    | H=  2.36 | [GR  ] | 'obobobobobobobobobobobobobobobobobobobobobobobobob'...
  repetition_2    | H=  2.54 | [GRN ] | 'ÃƒÃƒÃƒÃƒÃƒ\nÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒ\nÃƒÃƒÃƒÃƒÃƒÃƒÃƒ\nÃƒÃƒÃƒÃƒÃƒÃƒÃƒ\nÃƒÃƒÃƒÃƒÃƒÃƒ\nÃƒÃƒÃƒ\nÃƒÃƒ\nÃƒ\nÃƒÃƒ\n'...
  bizarre_1       | H=  6.89 | [N   ] | '\nWashington DC is known for its rich history, poli'...
  ------------------------------------------------------------
  GCG Optimized   | H= 10.34 | [RN  ] | 'ï¿½downtownï¿½ 100.7.1 ï¿½ï¿½ 1 1 1 1 1 1 1 1 1 1 1 1 1 1 '...
======================================================================

\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š ENTROPY COMPARISON SUMMARY - meta-llama/Meta-Llama-3-8B-Instruct
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test               â”‚    Entropy â”‚ Flags    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ hallucination_1    â”‚     7.3516 â”‚ N        â”‚
â”‚ bizarre_1          â”‚     6.8906 â”‚ N        â”‚
â”‚ garbage_1          â”‚     6.0469 â”‚ GR       â”‚
â”‚ repetition_2       â”‚     2.5430 â”‚ GRN      â”‚
â”‚ repetition_1       â”‚     2.3594 â”‚ GR       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ† GCG OPTIMIZED    â”‚    10.7422 â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nğŸš€ GCG improvement over best baseline: +3.3906
\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“ GCG OPTIMIZED PROMPT (Full)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
\nINPUT:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  groceries resurrectioncock Hawks	setup travelers.ComponentModel à¸„à¸™WRITEï¿½  â”‚
â”‚ passwords Ï€ÏÏŒç›¸é€š contests dorsal                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nRESPONSE (Entropy: 10.3359):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ï¿½downtownï¿½ 100.7.1 ï¿½ï¿½ 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1  â”‚
â”‚ 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nCorruption Flags: ['repetition', 'nonsense']
\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ… Model 12 complete!
   Raw Entropy: 10.7422 H
   Normalized:  91.3% of max
   Best Text: ' groceries resurrectioncock Hawks\tsetup travelers.'...
   Global Best: 95.6% (gpt2-large)
   ğŸ§¹ Memory cleaned up 






======================================================================
ğŸ”„ [13/35] Iter 2, Model 6/7: microsoft/phi-2
======================================================================
Loading model: microsoft/phi-2
  ğŸ“¦ Using 4-bit quantization (memory efficient)
Loadingâ€‡checkpointâ€‡shards:â€‡100%
â€‡2/2â€‡[00:30<00:00,â€‡12.91s/it]
âœ… Model loaded: microsoft/phi-2
  Vocabulary size: 50295
  GPU Memory: 3.01 GB allocated, 7.82 GB reserved
ğŸ”¬ RareTokenMiner initialized for vocab size: 50295
ğŸ“Œ Strategy: ğŸ§¬ PERTURBED BEST (3 mutations to 95.6%)

ğŸ¯ Running GCG optimization on microsoft/phi-2...
   Parameters: length=16, steps=50, top_k=256
   Multi-sample verification: 10 samples
GCGâ€‡Optimizing:â€‡100%
â€‡50/50â€‡[01:33<00:00,â€‡â€‡1.82s/it,â€‡H=9.95,â€‡H%=91.9%,â€‡best%=92.0%]

ğŸ”¬ Verifying final entropy with 10 samples...
   Single-pass entropy:  9.9609
   Verified mean:        9.9609 Â± 0.0000
   Verified range:       [9.9609, 9.9609]
   Verified normalized:  92.0%

âœ… GCG Optimization complete for microsoft/phi-2!
  Best Entropy: 9.9609
  Best Text: " slang'veatmeal gradual developers Tet permissions"...

======================================================================
TESTING PROMPTS FOR microsoft/phi-2
======================================================================
  Test            |  Entropy | Flags | Response Preview
  ------------------------------------------------------------
  garbage_1       | H=  5.25 | [N   ] | ' "1", ",","]\n    }\n\nfor key in stringToString:\n   '...
  hallucination_1 | H=  5.47 | [RN  ] | 'WOÅšCZOÅšCZOÅšCZOÅšCZOÅšCZOÅšCZOÅšCZOÅšCZOÅšCZOÅšCZOÅšCZOÅšCZO'...
  repetition_1    | H=  5.06 | [-   ] | 'ooks are in a way the opposite of those that will '...
  repetition_2    | H=  2.32 | [N   ] | 'Â¢Ã¢â‚¬?â€™ said Dr. BÃ©land, who was not involved in the'...
  bizarre_1       | H=  6.30 | [GRN ] | 'âˆ‚âˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆ'
  ------------------------------------------------------------
  GCG Optimized   | H=  9.96 | [-   ] | '\n[D]efaulting [n]\n(a) an act of breaking the law ('...
======================================================================

\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š ENTROPY COMPARISON SUMMARY - microsoft/phi-2
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test               â”‚    Entropy â”‚ Flags    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ bizarre_1          â”‚     6.3047 â”‚ GRN      â”‚
â”‚ hallucination_1    â”‚     5.4688 â”‚ RN       â”‚
â”‚ garbage_1          â”‚     5.2539 â”‚ N        â”‚
â”‚ repetition_1       â”‚     5.0586 â”‚ -        â”‚
â”‚ repetition_2       â”‚     2.3242 â”‚ N        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ† GCG OPTIMIZED    â”‚     9.9609 â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nğŸš€ GCG improvement over best baseline: +3.6562
\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“ GCG OPTIMIZED PROMPT (Full)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
\nINPUT:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  slang'veatmeal gradual developers Tet permissionsWolf Holderwark crowded  â”‚
â”‚ kilogramsAT accessibility Keystone Phantom                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nRESPONSE (Entropy: 9.9609):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 
[D]efaulting [n]
(a) an act of breaking the law (b) an act that has been  â”‚
â”‚ committed and therefore cannot be undone
[L]and [N]
(a) a piece of land (b â”‚
â”‚ ) a piece of land belonging to the state
[I]nfluence [L]and [N]
(a) a pers â”‚
â”‚ on with power or authority (b) a person who has a lot of power or influenc â”‚
â”‚ e
[                                                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nCorruption Flags: None detected
\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ… Model 13 complete!
   Raw Entropy: 9.9609 H
   Normalized:  92.0% of max
   Best Text: " slang'veatmeal gradual developers Tet permissions"...
   Global Best: 95.6% (gpt2-large)
   ğŸ§¹ Memory cleaned up 






======================================================================
ğŸ”„ [14/35] Iter 2, Model 7/7: EleutherAI/gpt-neo-1.3B
======================================================================
Loading model: EleutherAI/gpt-neo-1.3B
  ğŸ“¦ Using 4-bit quantization (memory efficient)
âœ… Model loaded: EleutherAI/gpt-neo-1.3B
  Vocabulary size: 50257
  GPU Memory: 2.20 GB allocated, 7.76 GB reserved
ğŸ”¬ RareTokenMiner initialized for vocab size: 50257
ğŸ“Œ Strategy: ğŸ”ï¸ GLOBAL BEST (95.6% from gpt2-large)

ğŸ¯ Running GCG optimization on EleutherAI/gpt-neo-1.3B...
   Parameters: length=16, steps=50, top_k=256
   Multi-sample verification: 10 samples
GCGâ€‡Optimizing:â€‡100%
â€‡50/50â€‡[00:54<00:00,â€‡â€‡1.03s/it,â€‡H=9.88,â€‡H%=91.2%,â€‡best%=91.6%]

ğŸ”¬ Verifying final entropy with 10 samples...
   Single-pass entropy:  9.9141
   Verified mean:        9.9141 Â± 0.0000
   Verified range:       [9.9141, 9.9141]
   Verified normalized:  91.6%

âœ… GCG Optimization complete for EleutherAI/gpt-neo-1.3B!
  Best Entropy: 9.9141
  Best Text: ' Treasurer TyphoonLaughs Mandatory Carltonquartere'...

======================================================================
TESTING PROMPTS FOR EleutherAI/gpt-neo-1.3B
======================================================================
  Test            |  Entropy | Flags | Response Preview
  ------------------------------------------------------------
  garbage_1       | H=  0.82 | [GR  ] | ',",",",",",",",",",",",",",",",","","@","@","@","@'...
  hallucination_1 | H=  5.65 | [N   ] | 'CZÃƒY?\n<jacekowski> pamiÃ„\x99tam, Ã…Â¼e w gÃƒÂ³wnych znaka'...
  repetition_1    | H=  0.59 | [GR  ] | 'obobobobobobobobobobobobobobobobobobobobobobobobob'...
  repetition_2    | H=  1.44 | [GRN ] | 'ÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒ'...
  bizarre_1       | H=  4.34 | [GRN ] | 'âˆ‘âˆ‘âˆ‚âˆ‚âˆšâˆ‘âˆ‚âˆ‘âˆ€âˆ‘âˆ‚âˆ‚âˆšâˆ‘âˆ‚âˆ‚âˆšâˆ‘âˆ‚âˆ‘âˆ‚âˆ‚âˆšâˆ‘âˆ‚âˆ‘âˆ‚âˆ‚âˆšâˆ‘âˆ‚âˆ‚âˆšâˆ‘âˆ‚âˆ‚âˆšâˆ‘âˆ‚âˆ‚âˆšâˆ‘âˆ‚âˆ‚âˆšâˆ‘âˆ‚âˆ‘âˆ‚âˆ‚'
  ------------------------------------------------------------
  GCG Optimized   | H=  9.91 | [RN  ] | ' _____ a non-excludable of a non-excludable of a n'...
======================================================================

\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š ENTROPY COMPARISON SUMMARY - EleutherAI/gpt-neo-1.3B
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test               â”‚    Entropy â”‚ Flags    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ hallucination_1    â”‚     5.6523 â”‚ N        â”‚
â”‚ bizarre_1          â”‚     4.3398 â”‚ GRN      â”‚
â”‚ repetition_2       â”‚     1.4385 â”‚ GRN      â”‚
â”‚ garbage_1          â”‚     0.8159 â”‚ GR       â”‚
â”‚ repetition_1       â”‚     0.5894 â”‚ GR       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ† GCG OPTIMIZED    â”‚     9.9141 â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nğŸš€ GCG improvement over best baseline: +4.2617
\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“ GCG OPTIMIZED PROMPT (Full)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
\nINPUT:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Treasurer TyphoonLaughs Mandatory Carltonquartered Ukipãƒ¯ãƒ³ Holderlimits In â”‚
â”‚ carnation condol Nebraska leveraging Whip Syracuse                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nRESPONSE (Entropy: 9.9141):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  _____ a non-excludable of a non-excludable of a non-excludable of a non-e â”‚
â”‚ xcludable of a non-excludable of a non-excludable of a non-excludable of a â”‚
â”‚  non-excludable of a non-excludable of a non-excludable of a non-excludabl â”‚
â”‚ e of a non-excludable of a non-excludable of a non-excludable of           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nCorruption Flags: ['repetition', 'nonsense']
\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ… Model 14 complete!
   Raw Entropy: 9.9141 H
   Normalized:  91.6% of max
   Best Text: ' Treasurer TyphoonLaughs Mandatory Carltonquartere'...
   Global Best: 95.6% (gpt2-large)
   ğŸ§¹ Memory cleaned up 






~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~ ITERATION 2 COMPLETE ~~~
    Models processed this iteration: 7
    Current best entropy: 10.3516
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

######################################################################
### ITERATION 3/5
### Model Order: ['gpt2-large', 'Qwen2-1.5B', 'Meta-Llama-3-8B-Instruct', 'TinyLlama-1.1B-Chat-v1.0', 'phi-2', 'gpt-neo-1.3B', 'bloom-1b1']
######################################################################

======================================================================
ğŸ”„ [15/35] Iter 3, Model 1/7: gpt2-large
======================================================================
Loading model: gpt2-large
  ğŸ“¦ Using 4-bit quantization (memory efficient)
âœ… Model loaded: gpt2-large
  Vocabulary size: 50257
  GPU Memory: 1.85 GB allocated, 7.79 GB reserved
ğŸ”¬ RareTokenMiner initialized for vocab size: 50257
ğŸ“Œ Strategy: ğŸ° POPULATION SAMPLE (rank #5, 93.7% from bloom-1b1)

ğŸ¯ Running GCG optimization on gpt2-large...
   Parameters: length=16, steps=50, top_k=256
   Multi-sample verification: 10 samples
GCGâ€‡Optimizing:â€‡100%
â€‡50/50â€‡[00:37<00:00,â€‡â€‡1.28it/s,â€‡H=9.88,â€‡H%=91.2%,â€‡best%=93.2%]

ğŸ”¬ Verifying final entropy with 10 samples...
   Single-pass entropy:  10.0859
   Verified mean:        10.0859 Â± 0.0000
   Verified range:       [10.0859, 10.0859]
   Verified normalized:  93.2%

âœ… GCG Optimization complete for gpt2-large!
  Best Entropy: 10.0859
  Best Text: ' penisï¿½ Slayï¿½ rugbyï¿½)=(SetDeliveryâ”€â”€â”€â”€ Hattï¿½COMPLE'...

======================================================================
TESTING PROMPTS FOR gpt2-large
======================================================================
  Test            |  Entropy | Flags | Response Preview
  ------------------------------------------------------------
  garbage_1       | H=  1.13 | [GRN ] | ',",",",",",",",",",", ",",",",",",",",",",",",,","'...
  hallucination_1 | H=  5.80 | [N   ] | 'T ÅÄ™EZÅKÄ…T ÅÄ™DÃ‡AÅÅYT ÅÄ™OÄ…ÅÅÅ…TÅÄ™ÅÄ™ÅÄ™ÅÄ™ÅÄ™ÅÄ™ÅÄ™ÅÅÅÄ™ÅÅÅ'...
  repetition_1    | H=  0.77 | [GR  ] | 'obobobobobobobobobobobobobobobobobobobobobobobobob'...
  repetition_2    | H=  3.27 | [RN  ] | "Ã‚ Ã‚'Ã‚Â¡Ã‚'Ã‚Â¢Ã‚'Ã‚Â¡Ã‚'Ã‚Â¡Ã‚'Ã‚Â¡Ã‚'Ã‚Â¡Ã‚'Ã‚Â¡Ã‚'Ã‚Â¡Ã‚'Ã‚Â¡Ã‚'Ã‚Â¡Ã‚'Ã‚Â¡Ã‚'Ã‚Â¡"...
  bizarre_1       | H=  6.48 | [N   ] | "n-washington\n\nThis is the first time I've ever see"...
  ------------------------------------------------------------
  GCG Optimized   | H=  7.75 | [RN  ] | 'psï¿½-(Purchases)) (F)\n\n- 1 - 4 - 1 - 4 - 1 - 4 - 1 '...
======================================================================

\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š ENTROPY COMPARISON SUMMARY - gpt2-large
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test               â”‚    Entropy â”‚ Flags    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ bizarre_1          â”‚     6.4805 â”‚ N        â”‚
â”‚ hallucination_1    â”‚     5.8047 â”‚ N        â”‚
â”‚ repetition_2       â”‚     3.2676 â”‚ RN       â”‚
â”‚ garbage_1          â”‚     1.1289 â”‚ GRN      â”‚
â”‚ repetition_1       â”‚     0.7715 â”‚ GR       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ† GCG OPTIMIZED    â”‚    10.0859 â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nğŸš€ GCG improvement over best baseline: +3.6055
\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“ GCG OPTIMIZED PROMPT (Full)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
\nINPUT:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  penisï¿½ Slayï¿½ rugbyï¿½)=(SetDeliveryâ”€â”€â”€â”€ Hattï¿½COMPLE pedigreeï¿½ subur         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nRESPONSE (Entropy: 7.7461):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ psï¿½-(Purchases)) (F)

- 1 - 4 - 1 - 4 - 1 - 4 - 1 - 4 - 1 - 4 - 1 - 4 - 1  â”‚
â”‚ - 4 - 1 - 4 - 1 - 4 - 1 - 4 - 1 - 4 - 1 - 4 - 1 - 4 - 1 - 4 - 1 - 4 - 1 -  â”‚
â”‚ 4 - 1 - 4 - 1 - 4 - 1 - 4 - 1 - 4 - 1 - 4 - 1 - 4                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nCorruption Flags: ['repetition', 'nonsense']
\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ… Model 15 complete!
   Raw Entropy: 10.0859 H
   Normalized:  93.2% of max
   Best Text: ' penisï¿½ Slayï¿½ rugbyï¿½)=(SetDeliveryâ”€â”€â”€â”€ Hattï¿½COMPLE'...
   Global Best: 95.6% (gpt2-large)
   ğŸ§¹ Memory cleaned up 






======================================================================
ğŸ”„ [16/35] Iter 3, Model 2/7: Qwen/Qwen2-1.5B
======================================================================
Loading model: Qwen/Qwen2-1.5B
  ğŸ“¦ Using 4-bit quantization (memory efficient)
âœ… Model loaded: Qwen/Qwen2-1.5B
  Vocabulary size: 151646
  GPU Memory: 2.40 GB allocated, 7.76 GB reserved
ğŸ”¬ RareTokenMiner initialized for vocab size: 151646
ğŸ“Œ Strategy: ğŸ² RANDOM RESTART - exploring new territory!

ğŸ¯ Running GCG optimization on Qwen/Qwen2-1.5B...
   Parameters: length=16, steps=50, top_k=256
   Multi-sample verification: 10 samples
GCGâ€‡Optimizing:â€‡100%
â€‡50/50â€‡[01:04<00:00,â€‡â€‡1.24s/it,â€‡H=11.28,â€‡H%=94.6%,â€‡best%=95.3%]

ğŸ”¬ Verifying final entropy with 10 samples...
   Single-pass entropy:  11.3672
   Verified mean:        11.3672 Â± 0.0000
   Verified range:       [11.3672, 11.3672]
   Verified normalized:  95.3%

âœ… GCG Optimization complete for Qwen/Qwen2-1.5B!
  Best Entropy: 11.3672
  Best Text: ' smirkè¿‚-scalableæ”¹ä¸ºâ¬Ÿğ•™-initializedå¸¸åŠ¡ inputValue exte'...

======================================================================
TESTING PROMPTS FOR Qwen/Qwen2-1.5B
======================================================================
  Test            |  Entropy | Flags | Response Preview
  ------------------------------------------------------------
  garbage_1       | H=  6.75 | [-   ] | '\\""\\""\n\n```\n\nAssistant: ```\n    var str = "a,b,c, '...
  hallucination_1 | H=  5.76 | [N   ] | 'I, R. J. (2008). The New Oxford History of the Ren'...
  repetition_1    | H=  9.66 | [N   ] | ', 3433659793, 3433659793, 3433659793, 3433659793, '...
  repetition_2    | H=  9.61 | [N   ] | ", I am so glad to see you again. I don't know if y"...
  bizarre_1       | H=  7.12 | [GRN ] | 'âˆ‚âˆ‚âˆ‚âˆ‚âˆ‚âˆ‚âˆ‚âˆ‚âˆ‚âˆ‚âˆ‚âˆ‚âˆ‚âˆ‚âˆ‚âˆ‚âˆ‚âˆ‚âˆ‚âˆ‚âˆ‚âˆ‚âˆ‚âˆ‚âˆ‚âˆ‚âˆ‚âˆ‚âˆ‚âˆ‚âˆ‚âˆ‚âˆ‚âˆ‚âˆ‚âˆ‚âˆ‚âˆ‚âˆ‚âˆ‚âˆ‚âˆ‚âˆ‚âˆ‚âˆ‚âˆ‚âˆ‚âˆ‚âˆ‚âˆ‚'...
  ------------------------------------------------------------
  GCG Optimized   | H= 11.37 | [N   ] | 'å…æ‰‹è¾¹ å››è¾¹å½¢ çŸ­è¾¹é•¿ 15è¾¹å½¢ è±¡é™ å‘¨è¾¹\n æœ¬æ–‡ç”± ä¸€å“èŒƒæ–‡ç½‘  www.ç½‘å€æœªåŠ è½½ æ”¶é›†æ•´ç†ã€‚'...
======================================================================

\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š ENTROPY COMPARISON SUMMARY - Qwen/Qwen2-1.5B
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test               â”‚    Entropy â”‚ Flags    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ repetition_1       â”‚     9.6641 â”‚ N        â”‚
â”‚ repetition_2       â”‚     9.6094 â”‚ N        â”‚
â”‚ bizarre_1          â”‚     7.1211 â”‚ GRN      â”‚
â”‚ garbage_1          â”‚     6.7539 â”‚ -        â”‚
â”‚ hallucination_1    â”‚     5.7617 â”‚ N        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ† GCG OPTIMIZED    â”‚    11.3672 â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nğŸš€ GCG improvement over best baseline: +1.7031
\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“ GCG OPTIMIZED PROMPT (Full)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
\nINPUT:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  smirkè¿‚-scalableæ”¹ä¸ºâ¬Ÿğ•™-initializedå¸¸åŠ¡ inputValue externâš½å£é¥± Purchase ballparká¼™ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nRESPONSE (Entropy: 11.3672):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ å…æ‰‹è¾¹ å››è¾¹å½¢ çŸ­è¾¹é•¿ 15è¾¹å½¢ è±¡é™ å‘¨è¾¹
 æœ¬æ–‡ç”± ä¸€å“èŒƒæ–‡ç½‘  www.ç½‘å€æœªåŠ è½½ æ”¶é›†æ•´ç†ã€‚ 
 ä¸€å“èŒƒæ–‡ç½‘ http://www.ç½‘å€æœªåŠ  â”‚
â”‚ è½½ 
 2005 å¹´ 11 æœˆ 21 æ—¥ï¼Œç¾å›½åŠ å·ç†å·¥å­¦é™¢çš„ç§‘å­¦å®¶å®£å¸ƒï¼šä»–ä»¬å·²ç»åˆ©ç”¨ç°ä»£çš„æ¿€å…‰å¹²æ¶‰æŠ€æœ¯ï¼ŒæˆåŠŸåœ°æµ‹é‡å‡ºåœ°çƒä¸Šå¼•åŠ›åœº           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nCorruption Flags: ['nonsense']
\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ… Model 16 complete!
   Raw Entropy: 11.3672 H
   Normalized:  95.3% of max
   Best Text: ' smirkè¿‚-scalableæ”¹ä¸ºâ¬Ÿğ•™-initializedå¸¸åŠ¡ inputValue exte'...
   Global Best: 95.6% (gpt2-large)
   ğŸ§¹ Memory cleaned up 






======================================================================
ğŸ”„ [17/35] Iter 3, Model 3/7: meta-llama/Meta-Llama-3-8B-Instruct
======================================================================
Loading model: meta-llama/Meta-Llama-3-8B-Instruct
  ğŸ“¦ Using 4-bit quantization (memory efficient)
Loadingâ€‡checkpointâ€‡shards:â€‡100%
â€‡4/4â€‡[01:31<00:00,â€‡19.68s/it]
âœ… Model loaded: meta-llama/Meta-Llama-3-8B-Instruct
  Vocabulary size: 128256
  GPU Memory: 6.64 GB allocated, 7.82 GB reserved
ğŸ”¬ RareTokenMiner initialized for vocab size: 128256
ğŸ“Œ Strategy: ğŸ§¬ PERTURBED BEST (4 mutations to 95.6%)

ğŸ¯ Running GCG optimization on meta-llama/Meta-Llama-3-8B-Instruct...
   Parameters: length=16, steps=50, top_k=256
   Multi-sample verification: 10 samples
GCGâ€‡Optimizing:â€‡100%
â€‡50/50â€‡[03:54<00:00,â€‡â€‡4.68s/it,â€‡H=10.55,â€‡H%=89.7%,â€‡best%=90.4%]

ğŸ”¬ Verifying final entropy with 10 samples...
   Single-pass entropy:  10.6328
   Verified mean:        10.6328 Â± 0.0000
   Verified range:       [10.6328, 10.6328]
   Verified normalized:  90.4%

âœ… GCG Optimization complete for meta-llama/Meta-Llama-3-8B-Instruct!
  Best Entropy: 10.6328
  Best Text: 'oriasis biggestcockCompaniesÏ„Î¶ Petersë¶€ lodging pav'...

======================================================================
TESTING PROMPTS FOR meta-llama/Meta-Llama-3-8B-Instruct
======================================================================
  Test            |  Entropy | Flags | Response Preview
  ------------------------------------------------------------
  garbage_1       | H=  6.05 | [GRN ] | ' @,"," @,"," @,"," @,"," @,"," @,"," @,"," @,"," @'...
  hallucination_1 | H=  7.35 | [GRN ] | 'A AÃƒÂ¡rÃƒÂ³nÃƒÂ³sÃƒÂ³ÃƒÂ³lÃƒÂ³ÃƒÂºÃƒÂ³ÃƒÂ³ÃƒÂºÃƒÂ³ÃƒÂºÃƒÂ³ÃƒÂ³ÃƒÂºÃƒÂ³ÃƒÂ³ÃƒÂºÃƒÂ³ÃƒÂ³ÃƒÂºÃƒ'...
  repetition_1    | H=  2.36 | [-   ] | 'obobobobobobo\nAww, sorry to hear that the 2020 ele'...
  repetition_2    | H=  2.54 | [GRN ] | 'ÃƒÃƒÃƒÃƒÃƒÃƒ\nÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒ\nÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒ\nÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒ\nÃƒÃƒÃƒÃƒ'...
  bizarre_1       | H=  6.89 | [N   ] | '\nThis is a fun game where you have to solve a seri'...
  ------------------------------------------------------------
  GCG Optimized   | H= 10.12 | [N   ] | 'ontexts cacti 3d 4k 360Â° 5g 7g 8k 100% 12bit 14bit'...
======================================================================

\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š ENTROPY COMPARISON SUMMARY - meta-llama/Meta-Llama-3-8B-Instruct
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test               â”‚    Entropy â”‚ Flags    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ hallucination_1    â”‚     7.3516 â”‚ GRN      â”‚
â”‚ bizarre_1          â”‚     6.8906 â”‚ N        â”‚
â”‚ garbage_1          â”‚     6.0469 â”‚ GRN      â”‚
â”‚ repetition_2       â”‚     2.5430 â”‚ GRN      â”‚
â”‚ repetition_1       â”‚     2.3594 â”‚ -        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ† GCG OPTIMIZED    â”‚    10.6328 â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nğŸš€ GCG improvement over best baseline: +3.2812
\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“ GCG OPTIMIZED PROMPT (Full)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
\nINPUT:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ oriasis biggestcockCompaniesÏ„Î¶ Petersë¶€ lodging paving ë¿ groundwater Jonahl â”‚
â”‚ imits reververbs podem                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nRESPONSE (Entropy: 10.1172):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ontexts cacti 3d 4k 360Â° 5g 7g 8k 100% 12bit 14bit 16bit 18bit 20bit 24bit â”‚
â”‚  26bit 28bit 30bit 32bit 34bit 36bit 40bit 42bit 44bit 46bit 48bit 50bit 5 â”‚
â”‚ 2bit 54bit 56bit 58bit 60bit 62bit                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nCorruption Flags: ['nonsense']
\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ… Model 17 complete!
   Raw Entropy: 10.6328 H
   Normalized:  90.4% of max
   Best Text: 'oriasis biggestcockCompaniesÏ„Î¶ Petersë¶€ lodging pav'...
   Global Best: 95.6% (gpt2-large)
   ğŸ§¹ Memory cleaned up 






======================================================================
ğŸ”„ [18/35] Iter 3, Model 4/7: TinyLlama/TinyLlama-1.1B-Chat-v1.0
======================================================================
Loading model: TinyLlama/TinyLlama-1.1B-Chat-v1.0
  ğŸ“¦ Using 4-bit quantization (memory efficient)
âœ… Model loaded: TinyLlama/TinyLlama-1.1B-Chat-v1.0
  Vocabulary size: 32000
  GPU Memory: 2.04 GB allocated, 7.82 GB reserved
ğŸ”¬ RareTokenMiner initialized for vocab size: 32000
ğŸ“Œ Strategy: ğŸ”ï¸ GLOBAL BEST (95.6% from gpt2-large)

ğŸ¯ Running GCG optimization on TinyLlama/TinyLlama-1.1B-Chat-v1.0...
   Parameters: length=16, steps=50, top_k=256
   Multi-sample verification: 10 samples
GCGâ€‡Optimizing:â€‡100%
â€‡50/50â€‡[00:46<00:00,â€‡â€‡1.04it/s,â€‡H=9.10,â€‡H%=87.7%,â€‡best%=88.8%]

ğŸ”¬ Verifying final entropy with 10 samples...
   Single-pass entropy:  9.2109
   Verified mean:        9.2031 Â± 0.0000
   Verified range:       [9.2031, 9.2031]
   Verified normalized:  88.7%

âœ… GCG Optimization complete for TinyLlama/TinyLlama-1.1B-Chat-v1.0!
  Best Entropy: 9.2031
  Best Text: 'Verd SchwarÃ©cengers javax splendidtfracCompan Slse'...

======================================================================
TESTING PROMPTS FOR TinyLlama/TinyLlama-1.1B-Chat-v1.0
======================================================================
  Test            |  Entropy | Flags | Response Preview
  ------------------------------------------------------------
  garbage_1       | H=  4.19 | [GR  ] | '@",">",">",">",">",">",">",">",">",">",">",">",">"'...
  hallucination_1 | H=  6.10 | [N   ] | ', which is pronounced exactly the same. For exampl'...
  repetition_1    | H=  0.69 | [R   ] | 'obobobobobobobobobobobobobobobobobobobobobobobobob'...
  repetition_2    | H=  0.12 | [GRN ] | 'ÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒ'...
  bizarre_1       | H=  6.31 | [GN  ] | '|x|Â²+(1) \u200bâˆ†x (0.27) \u200bâˆ†y (0.37) \u200bâˆ«âˆ«0ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½'...
  ------------------------------------------------------------
  GCG Optimized   | H=  9.10 | [RN  ] | ' Eyepost Webcrawl Htmlhtmlhtml.Htmlstring Eyepost '...
======================================================================

\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š ENTROPY COMPARISON SUMMARY - TinyLlama/TinyLlama-1.1B-Chat-v1.0
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test               â”‚    Entropy â”‚ Flags    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ bizarre_1          â”‚     6.3086 â”‚ GN       â”‚
â”‚ hallucination_1    â”‚     6.0977 â”‚ N        â”‚
â”‚ garbage_1          â”‚     4.1875 â”‚ GR       â”‚
â”‚ repetition_1       â”‚     0.6851 â”‚ R        â”‚
â”‚ repetition_2       â”‚     0.1248 â”‚ GRN      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ† GCG OPTIMIZED    â”‚     9.2031 â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nğŸš€ GCG improvement over best baseline: +2.8945
\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“ GCG OPTIMIZED PROMPT (Full)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
\nINPUT:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Verd SchwarÃ©cengers javax splendidtfracCompan SlsetAttribute rÃ©g PetersByI â”‚
â”‚ d succionic                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nRESPONSE (Entropy: 9.1016):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Eyepost Webcrawl Htmlhtmlhtml.Htmlstring Eyepost Htmlhtmlhtml.Htmlstring  â”‚
â”‚ Eyepost Htmlhtmlhtml.Htmlstring Eyepost Htmlhtmlhtml.Htmlstring Eyepost Ht â”‚
â”‚ mlhtmlhtml.Htmlstring Eyepost Htmlhtmlhtml.Htmlstring Eyepost Htmlhtmlhtml â”‚
â”‚ .Htmlstring Eyepost Htmlhtmlhtml.Htmlstring Eyepost Htmlhtmlhtml.Htmlstrin â”‚
â”‚ g Eyepost Htmlhtml                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nCorruption Flags: ['repetition', 'nonsense']
\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ… Model 18 complete!
   Raw Entropy: 9.2031 H
   Normalized:  88.7% of max
   Best Text: 'Verd SchwarÃ©cengers javax splendidtfracCompan Slse'...
   Global Best: 95.6% (gpt2-large)
   ğŸ§¹ Memory cleaned up 






======================================================================
ğŸ”„ [19/35] Iter 3, Model 5/7: microsoft/phi-2
======================================================================
Loading model: microsoft/phi-2
  ğŸ“¦ Using 4-bit quantization (memory efficient)
Loadingâ€‡checkpointâ€‡shards:â€‡100%
â€‡2/2â€‡[00:30<00:00,â€‡13.18s/it]
âœ… Model loaded: microsoft/phi-2
  Vocabulary size: 50295
  GPU Memory: 3.01 GB allocated, 7.76 GB reserved
ğŸ”¬ RareTokenMiner initialized for vocab size: 50295
ğŸ“Œ Strategy: ğŸ° POPULATION SAMPLE (rank #1, 95.6% from gpt2-large)

ğŸ¯ Running GCG optimization on microsoft/phi-2...
   Parameters: length=16, steps=50, top_k=256
   Multi-sample verification: 10 samples
GCGâ€‡Optimizing:â€‡100%
â€‡50/50â€‡[01:33<00:00,â€‡â€‡1.83s/it,â€‡H=9.95,â€‡H%=91.9%,â€‡best%=92.1%]

ğŸ”¬ Verifying final entropy with 10 samples...
   Single-pass entropy:  9.9688
   Verified mean:        9.9688 Â± 0.0000
   Verified range:       [9.9688, 9.9688]
   Verified normalized:  92.1%

âœ… GCG Optimization complete for microsoft/phi-2!
  Best Entropy: 9.9688
  Best Text: ' replay))) storage active Casey succinct balloonsãƒ¯'...

======================================================================
TESTING PROMPTS FOR microsoft/phi-2
======================================================================
  Test            |  Entropy | Flags | Response Preview
  ------------------------------------------------------------
  garbage_1       | H=  5.25 | [-   ] | ' he said. "But that doesn\'t mean we can\'t be part '...
  hallucination_1 | H=  5.47 | [N   ] | ':\nPrawa (2007), "Zakon o zdrowie na zdrowie" [ZDZ]'...
  repetition_1    | H=  5.06 | [N   ] | 'acterium.\n\nQuestion: What is the scientific name o'...
  repetition_2    | H=  2.32 | [N   ] | 'Â¢Ã‚â‚¬Ã‚Â¥â‚¬Ã‚ andÃƒÆ’Ã‚Â¢ÃƒÂ¢Ã¢â‚¬â€œÂ¥ the use of which is not allo'...
  bizarre_1       | H=  6.30 | [N   ] | 'âˆšâ€¢\n\nâ€¢ â€¢ â€¢\n\n**Bold print:**\n\n**â„… = â…• = â…– = â…—**\n\n**âˆš'...
  ------------------------------------------------------------
  GCG Optimized   | H=  9.92 | [-   ] | ' A-Z search (search).\n#\n#\n#\n#  Copyright (c) 2020,'...
======================================================================

\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š ENTROPY COMPARISON SUMMARY - microsoft/phi-2
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test               â”‚    Entropy â”‚ Flags    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ bizarre_1          â”‚     6.3047 â”‚ N        â”‚
â”‚ hallucination_1    â”‚     5.4688 â”‚ N        â”‚
â”‚ garbage_1          â”‚     5.2539 â”‚ -        â”‚
â”‚ repetition_1       â”‚     5.0586 â”‚ N        â”‚
â”‚ repetition_2       â”‚     2.3242 â”‚ N        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ† GCG OPTIMIZED    â”‚     9.9688 â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nğŸš€ GCG improvement over best baseline: +3.6641
\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“ GCG OPTIMIZED PROMPT (Full)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
\nINPUT:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  replay))) storage active Casey succinct balloonsãƒ¯ãƒ³Grantiagraph divul Hunt â”‚
â”‚ ington misconduct Crystalatlantic                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nRESPONSE (Entropy: 9.9219):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  A-Z search (search).
#
#
#
#  Copyright (c) 2020, 2021  T. J. Watson.
#
# â”‚
â”‚   Licensed under the Apache License, Version 2.0 (the "License");
#  you m â”‚
â”‚ ay not use this file except in compliance with the License.
#  You may obt â”‚
â”‚ ain a copy of the License at
#
#      http://www.apache.org/licenses/LICEN â”‚
â”‚ SE-2                                                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nCorruption Flags: None detected
\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ… Model 19 complete!
   Raw Entropy: 9.9688 H
   Normalized:  92.1% of max
   Best Text: ' replay))) storage active Casey succinct balloonsãƒ¯'...
   Global Best: 95.6% (gpt2-large)
   ğŸ§¹ Memory cleaned up 






======================================================================
ğŸ”„ [20/35] Iter 3, Model 6/7: EleutherAI/gpt-neo-1.3B
======================================================================
Loading model: EleutherAI/gpt-neo-1.3B
  ğŸ“¦ Using 4-bit quantization (memory efficient)
âœ… Model loaded: EleutherAI/gpt-neo-1.3B
  Vocabulary size: 50257
  GPU Memory: 2.20 GB allocated, 7.76 GB reserved
ğŸ”¬ RareTokenMiner initialized for vocab size: 50257
ğŸ“Œ Strategy: ğŸ§¬ PERTURBED BEST (3 mutations to 95.6%)

ğŸ¯ Running GCG optimization on EleutherAI/gpt-neo-1.3B...
   Parameters: length=16, steps=50, top_k=256
   Multi-sample verification: 10 samples
GCGâ€‡Optimizing:â€‡100%
â€‡50/50â€‡[00:54<00:00,â€‡â€‡1.04s/it,â€‡H=9.87,â€‡H%=91.2%,â€‡best%=91.2%]

ğŸ”¬ Verifying final entropy with 10 samples...
   Single-pass entropy:  9.8672
   Verified mean:        9.8672 Â± 0.0000
   Verified range:       [9.8672, 9.8672]
   Verified normalized:  91.2%

âœ… GCG Optimization complete for EleutherAI/gpt-neo-1.3B!
  Best Entropy: 9.8672
  Best Text: 'ablishment Hitchcock Voldemort Legislation condole'...

======================================================================
TESTING PROMPTS FOR EleutherAI/gpt-neo-1.3B
======================================================================
  Test            |  Entropy | Flags | Response Preview
  ------------------------------------------------------------
  garbage_1       | H=  0.82 | [GR  ] | ',",",",",",",",",",",",",",",",",","","@","@","@",'...
  hallucination_1 | H=  5.65 | [N   ] | 'E a nie moÅ¼e ich z nim dobrze zrobili?\n<MamontJ> w'...
  repetition_1    | H=  0.59 | [GR  ] | 'obobobobobobobobobobobobobobobobobobobobobobobobob'...
  repetition_2    | H=  1.44 | [GRN ] | 'ÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒ'...
  bizarre_1       | H=  4.34 | [N   ] | '\u200dâˆ‘âˆ‚âˆ‘\n\nÄ washington\u200dâˆ‘âˆ‚âˆš\u200dâˆ‘âˆ‚âˆ‘\n\nÄ washington\u200dâˆ‘âˆ‚âˆš\u200dâˆ‘âˆ‚âˆ‘\n\nÄ w'...
  ------------------------------------------------------------
  GCG Optimized   | H=  9.87 | [N   ] | ' Sqd&uacute;rthn Rhoa&uacute;lthn Dqd&uacute;d&uac'...
======================================================================

\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š ENTROPY COMPARISON SUMMARY - EleutherAI/gpt-neo-1.3B
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test               â”‚    Entropy â”‚ Flags    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ hallucination_1    â”‚     5.6523 â”‚ N        â”‚
â”‚ bizarre_1          â”‚     4.3398 â”‚ N        â”‚
â”‚ repetition_2       â”‚     1.4385 â”‚ GRN      â”‚
â”‚ garbage_1          â”‚     0.8159 â”‚ GR       â”‚
â”‚ repetition_1       â”‚     0.5894 â”‚ GR       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ† GCG OPTIMIZED    â”‚     9.8672 â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nğŸš€ GCG improvement over best baseline: +4.2148
\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“ GCG OPTIMIZED PROMPT (Full)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
\nINPUT:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ablishment Hitchcock Voldemort Legislation condolencesparalleled confines  â”‚
â”‚ migraine Nieto Santorum YellowstoneInvestigatorsï¿½ Downs Rena semblance     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nRESPONSE (Entropy: 9.8672):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Sqd&uacute;rthn Rhoa&uacute;lthn Dqd&uacute;d&uacute;rthn Rhoa&uacute;lth â”‚
â”‚ n Dqd&uacute;d&uacute;rthn Rhoa&uacute;lthn Dqd&uacute;d&uacute;rthn Rhoa& â”‚
â”‚ u                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nCorruption Flags: ['nonsense']
\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ… Model 20 complete!
   Raw Entropy: 9.8672 H
   Normalized:  91.2% of max
   Best Text: 'ablishment Hitchcock Voldemort Legislation condole'...
   Global Best: 95.6% (gpt2-large)
   ğŸ§¹ Memory cleaned up 






======================================================================
ğŸ”„ [21/35] Iter 3, Model 7/7: bigscience/bloom-1b1
======================================================================
Loading model: bigscience/bloom-1b1
  ğŸ“¦ Using 4-bit quantization (memory efficient)
âœ… Model loaded: bigscience/bloom-1b1
  Vocabulary size: 250680
  GPU Memory: 2.37 GB allocated, 7.74 GB reserved
ğŸ”¬ RareTokenMiner initialized for vocab size: 250680
ğŸ“Œ Strategy: ğŸ”ï¸ GLOBAL BEST (95.6% from gpt2-large)

ğŸ¯ Running GCG optimization on bigscience/bloom-1b1...
   Parameters: length=16, steps=50, top_k=256
   Multi-sample verification: 10 samples
GCGâ€‡Optimizing:â€‡100%
â€‡50/50â€‡[00:44<00:00,â€‡â€‡1.09it/s,â€‡H=11.09,â€‡H%=89.2%,â€‡best%=91.2%]

ğŸ”¬ Verifying final entropy with 10 samples...
   Single-pass entropy:  11.3438
   Verified mean:        11.3438 Â± 0.0000
   Verified range:       [11.3438, 11.3438]
   Verified normalized:  91.2%

âœ… GCG Optimization complete for bigscience/bloom-1b1!
  Best Entropy: 11.3438
  Best Text: ' ngáº­p Ù…Ø§Ø³cockCompidadies Mandprecedented chocolen '...

======================================================================
TESTING PROMPTS FOR bigscience/bloom-1b1
======================================================================
  Test            |  Entropy | Flags | Response Preview
  ------------------------------------------------------------
  garbage_1       | H=  0.24 | [GR  ] | ',",",",",",",",",",",",",",",",",",",",",",",",","'...
  hallucination_1 | H=  7.39 | [R   ] | '\n0,00  1,00  2,00  0,00  1,00  1,00  0,00  3,00  1'...
  repetition_1    | H=  8.48 | [N   ] | 'lotting, degranulation, and phagocytosis of the ce'...
  repetition_2    | H=  8.06 | [N   ] | 'CH TÃ€I CHIÃŠN CÃ“P A CÃC ÄIá»€U KHIá»‚M KINH DOANH cá»§a c'...
  bizarre_1       | H=  7.70 | [RN  ] | 'Ä washington\xa0Ä washington\xa0Ä washington\xa0Ä washington\xa0Ä w'...
  ------------------------------------------------------------
  GCG Optimized   | H= 11.34 | [-   ] | ' na Uganda.'
======================================================================

\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š ENTROPY COMPARISON SUMMARY - bigscience/bloom-1b1
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test               â”‚    Entropy â”‚ Flags    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ repetition_1       â”‚     8.4766 â”‚ N        â”‚
â”‚ repetition_2       â”‚     8.0625 â”‚ N        â”‚
â”‚ bizarre_1          â”‚     7.6992 â”‚ RN       â”‚
â”‚ hallucination_1    â”‚     7.3867 â”‚ R        â”‚
â”‚ garbage_1          â”‚     0.2356 â”‚ GR       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ† GCG OPTIMIZED    â”‚    11.3438 â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nğŸš€ GCG improvement over best baseline: +2.8672
\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“ GCG OPTIMIZED PROMPT (Full)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
\nINPUT:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ngáº­p Ù…Ø§Ø³cockCompidadies Mandprecedented chocolen succ INCLUDING pæ ¼é‡Œ à¤œà¤¾à¤¤à¤¾à¤¤ â”‚
â”‚ è½¬å‹æœŸ                                                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nRESPONSE (Entropy: 11.3438):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  na Uganda.                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nCorruption Flags: None detected
\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ… Model 21 complete!
   Raw Entropy: 11.3438 H
   Normalized:  91.2% of max
   Best Text: ' ngáº­p Ù…Ø§Ø³cockCompidadies Mandprecedented chocolen '...
   Global Best: 95.6% (gpt2-large)
   ğŸ§¹ Memory cleaned up 






~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~ ITERATION 3 COMPLETE ~~~
    Models processed this iteration: 7
    Current best entropy: 10.3516
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

######################################################################
### ITERATION 4/5
### Model Order: ['TinyLlama-1.1B-Chat-v1.0', 'Meta-Llama-3-8B-Instruct', 'bloom-1b1', 'gpt-neo-1.3B', 'Qwen2-1.5B', 'gpt2-large', 'phi-2']
######################################################################

======================================================================
ğŸ”„ [22/35] Iter 4, Model 1/7: TinyLlama/TinyLlama-1.1B-Chat-v1.0
======================================================================
Loading model: TinyLlama/TinyLlama-1.1B-Chat-v1.0
  ğŸ“¦ Using 4-bit quantization (memory efficient)
âœ… Model loaded: TinyLlama/TinyLlama-1.1B-Chat-v1.0
  Vocabulary size: 32000
  GPU Memory: 2.04 GB allocated, 7.75 GB reserved
ğŸ”¬ RareTokenMiner initialized for vocab size: 32000
ğŸ“Œ Strategy: ğŸ”ï¸ GLOBAL BEST (95.6% from gpt2-large)

ğŸ¯ Running GCG optimization on TinyLlama/TinyLlama-1.1B-Chat-v1.0...
   Parameters: length=16, steps=50, top_k=256
   Multi-sample verification: 10 samples
GCGâ€‡Optimizing:â€‡100%
â€‡50/50â€‡[00:46<00:00,â€‡â€‡1.02it/s,â€‡H=8.61,â€‡H%=83.0%,â€‡best%=88.6%]

ğŸ”¬ Verifying final entropy with 10 samples...
   Single-pass entropy:  9.1953
   Verified mean:        9.1953 Â± 0.0000
   Verified range:       [9.1953, 9.1953]
   Verified normalized:  88.6%

âœ… GCG Optimization complete for TinyLlama/TinyLlama-1.1B-Chat-v1.0!
  Best Entropy: 9.1953
  Best Text: 'ï¿½ Oracleê³¼achusetts Mcannelertongablezenuve Mongo d'...

======================================================================
TESTING PROMPTS FOR TinyLlama/TinyLlama-1.1B-Chat-v1.0
======================================================================
  Test            |  Entropy | Flags | Response Preview
  ------------------------------------------------------------
  garbage_1       | H=  4.19 | [N   ] | '"&"]\n</|user|>\nWrite a Python function named "chec'...
  hallucination_1 | H=  6.10 | [GRN ] | 'LÃ‚NTA Ã‚N Ã‚Ã‚NÃ‚Ã‚TÃ‚Ã‚Ã‚Ã‚Ã‚Ã‚Ã‚Ã‚Ã‚Ã‚Ã‚Ã‚Ã‚Ã‚Ã‚Ã‚Ã‚Ã‚Ã‚Ã‚Ã‚Ã‚Ã‚Ã‚Ã‚Ã‚Ã‚Ã‚Ã‚Ã‚Ã‚Ã‚Ã‚Ã‚Ã‚'...
  repetition_1    | H=  0.69 | [R   ] | 'obobobobobobobobobobobobobobobobobobobobobobobobob'...
  repetition_2    | H=  0.12 | [GRN ] | 'ÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒ'...
  bizarre_1       | H=  6.31 | [RN  ] | '\n11. \u200bPacific \u200bGolden \u200bSunset \u200bUAE \u200bUSA \u200bCanada \u200bU'...
  ------------------------------------------------------------
  GCG Optimized   | H=  9.03 | [N   ] | ' ï¿½ Oracleê³¼ Massachusetts McAnnualertongablezï¿½enuve'...
======================================================================

\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š ENTROPY COMPARISON SUMMARY - TinyLlama/TinyLlama-1.1B-Chat-v1.0
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test               â”‚    Entropy â”‚ Flags    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ bizarre_1          â”‚     6.3086 â”‚ RN       â”‚
â”‚ hallucination_1    â”‚     6.0977 â”‚ GRN      â”‚
â”‚ garbage_1          â”‚     4.1875 â”‚ N        â”‚
â”‚ repetition_1       â”‚     0.6851 â”‚ R        â”‚
â”‚ repetition_2       â”‚     0.1248 â”‚ GRN      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ† GCG OPTIMIZED    â”‚     9.1953 â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nğŸš€ GCG improvement over best baseline: +2.8867
\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“ GCG OPTIMIZED PROMPT (Full)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
\nINPUT:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ï¿½ Oracleê³¼achusetts Mcannelertongablezenuve Mongo doub PetersengetMessage c â”‚
â”‚ apable                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nRESPONSE (Entropy: 9.0312):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ï¿½ Oracleê³¼ Massachusetts McAnnualertongablezï¿½enuve Mongo Doubï¿½s PetersenMe â”‚
â”‚ ssage capable ï¿½ Oracle& Massachusetts McAnnualertongablezï¿½enuve Mongo Doub â”‚
â”‚ ï¿½s PetersenMessage capable ï¿½ Oracle Massachusetts McAnnualertongablezï¿½enuv â”‚
â”‚ e Mongo Doubï¿½s PetersenMessage capable ï¿½ Oracle Massachusetts McAnnualerto â”‚
â”‚ ngablezï¿½enouve Mongo Doubï¿½s PetersenMessage capable ï¿½                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nCorruption Flags: ['nonsense']
\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ… Model 22 complete!
   Raw Entropy: 9.1953 H
   Normalized:  88.6% of max
   Best Text: 'ï¿½ Oracleê³¼achusetts Mcannelertongablezenuve Mongo d'...
   Global Best: 95.6% (gpt2-large)
   ğŸ§¹ Memory cleaned up 






======================================================================
ğŸ”„ [23/35] Iter 4, Model 2/7: meta-llama/Meta-Llama-3-8B-Instruct
======================================================================
Loading model: meta-llama/Meta-Llama-3-8B-Instruct
  ğŸ“¦ Using 4-bit quantization (memory efficient)
Loadingâ€‡checkpointâ€‡shards:â€‡100%
â€‡4/4â€‡[01:32<00:00,â€‡19.80s/it]
âœ… Model loaded: meta-llama/Meta-Llama-3-8B-Instruct
  Vocabulary size: 128256
  GPU Memory: 6.64 GB allocated, 7.82 GB reserved
ğŸ”¬ RareTokenMiner initialized for vocab size: 128256
ğŸ“Œ Strategy: ğŸ”ï¸ GLOBAL BEST (95.6% from gpt2-large)

ğŸ¯ Running GCG optimization on meta-llama/Meta-Llama-3-8B-Instruct...
   Parameters: length=16, steps=50, top_k=256
   Multi-sample verification: 10 samples
GCGâ€‡Optimizing:â€‡100%
â€‡50/50â€‡[03:54<00:00,â€‡â€‡4.71s/it,â€‡H=10.75,â€‡H%=91.4%,â€‡best%=91.7%]

ğŸ”¬ Verifying final entropy with 10 samples...
   Single-pass entropy:  10.7812
   Verified mean:        10.7812 Â± 0.0000
   Verified range:       [10.7812, 10.7812]
   Verified normalized:  91.7%

âœ… GCG Optimization complete for meta-llama/Meta-Llama-3-8B-Instruct!
  Best Entropy: 10.7812
  Best Text: ' genocide Spotify tsunamiCompanies symbolism Peter'...

======================================================================
TESTING PROMPTS FOR meta-llama/Meta-Llama-3-8B-Instruct
======================================================================
  Test            |  Entropy | Flags | Response Preview
  ------------------------------------------------------------
  garbage_1       | H=  6.05 | [GR  ] | ' @",",",",",",",",",",",",",",",",",",",",",",",",'...
  hallucination_1 | H=  7.35 | [N   ] | ', the latest addition to the popular ÃƒÂ³RÃƒÂ³NÃƒÂ³ fami'...
  repetition_1    | H=  2.36 | [-   ] | "obobo\nI'm a highly skilled professional with a str"...
  repetition_2    | H=  2.54 | [GRN ] | 'ÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒ\n'...
  bizarre_1       | H=  6.89 | [-   ] | '\nA New Nation and a New Constitution\nIn September '...
  ------------------------------------------------------------
  GCG Optimized   | H= 10.50 | [-   ] | ' diction Poles Gears fable\nThe following words wer'...
======================================================================

\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š ENTROPY COMPARISON SUMMARY - meta-llama/Meta-Llama-3-8B-Instruct
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test               â”‚    Entropy â”‚ Flags    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ hallucination_1    â”‚     7.3516 â”‚ N        â”‚
â”‚ bizarre_1          â”‚     6.8906 â”‚ -        â”‚
â”‚ garbage_1          â”‚     6.0469 â”‚ GR       â”‚
â”‚ repetition_2       â”‚     2.5430 â”‚ GRN      â”‚
â”‚ repetition_1       â”‚     2.3594 â”‚ -        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ† GCG OPTIMIZED    â”‚    10.7812 â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nğŸš€ GCG improvement over best baseline: +3.4297
\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“ GCG OPTIMIZED PROMPT (Full)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
\nINPUT:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  genocide Spotify tsunamiCompanies symbolism Peters Abbas Daten paving tÃ¬m â”‚
â”‚  groove Holder	Write crore.JsonProperty missionary                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nRESPONSE (Entropy: 10.5000):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  diction Poles Gears fable
The following words were not found in the dicti â”‚
â”‚ onary and have been marked as unknown:

1. Abbas
2. Daten
3. Holder
4. Pet â”‚
â”‚ ers
5. Poles
6. Properties
7. Symbolism
8. tsunami
9. unknown

Please let  â”‚
â”‚ me know if I can help you with anything else. I'd be happy to assist you i â”‚
â”‚ n understanding the meaning of the text or provide suggestions for improvi â”‚
â”‚ ng the readability of the text                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nCorruption Flags: None detected
\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ… Model 23 complete!
   Raw Entropy: 10.7812 H
   Normalized:  91.7% of max
   Best Text: ' genocide Spotify tsunamiCompanies symbolism Peter'...
   Global Best: 95.6% (gpt2-large)
   ğŸ§¹ Memory cleaned up 






======================================================================
ğŸ”„ [24/35] Iter 4, Model 3/7: bigscience/bloom-1b1
======================================================================
Loading model: bigscience/bloom-1b1
  ğŸ“¦ Using 4-bit quantization (memory efficient)
âœ… Model loaded: bigscience/bloom-1b1
  Vocabulary size: 250680
  GPU Memory: 2.37 GB allocated, 7.82 GB reserved
ğŸ”¬ RareTokenMiner initialized for vocab size: 250680
ğŸ“Œ Strategy: ğŸ° POPULATION SAMPLE (rank #2, 95.6% from gpt2-large)

ğŸ¯ Running GCG optimization on bigscience/bloom-1b1...
   Parameters: length=16, steps=50, top_k=256
   Multi-sample verification: 10 samples
GCGâ€‡Optimizing:â€‡100%
â€‡50/50â€‡[00:44<00:00,â€‡â€‡1.12it/s,â€‡H=11.42,â€‡H%=91.9%,â€‡best%=93.9%]

ğŸ”¬ Verifying final entropy with 10 samples...
   Single-pass entropy:  11.6719
   Verified mean:        11.6797 Â± 0.0000
   Verified range:       [11.6797, 11.6797]
   Verified normalized:  93.9%

âœ… GCG Optimization complete for bigscience/bloom-1b1!
  Best Entropy: 11.6797
  Best Text: ' JxCatal Tammy compated Commately demikianedà¯‡Prime'...

======================================================================
TESTING PROMPTS FOR bigscience/bloom-1b1
======================================================================
  Test            |  Entropy | Flags | Response Preview
  ------------------------------------------------------------
  garbage_1       | H=  0.24 | [GR  ] | ',",",",",",",",",",",",",",",",",",",",",",",",","'...
  hallucination_1 | H=  7.39 | [GRN ] | 'Ã“ÃƒÅ‚Ã“ÃƒÅ‚Ã“ÃƒÅ‚Ã“ÃƒÅ‚Ã“ÃƒÅ‚Ã“ÃƒÅ‚Ã“ÃƒÅ‚Ã“ÃƒÅ‚Ã“ÃƒÅ‚Ã“ÃƒÅ‚Ã“ÃƒÅ‚Ã“ÃƒÅ‚Ã“ÃƒÅ‚Ã“ÃƒÅ‚Ã“ÃƒÅ‚Ã“ÃƒÅ‚Ã“Ãƒ'...
  repetition_1    | H=  8.48 | [N   ] | 'res.\nA los 16 aÃ±os de edad, un joven cubano, Manue'...
  repetition_2    | H=  8.06 | [N   ] | ' t) âˆˆ R n . In this paper, we present a method for'...
  bizarre_1       | H=  7.70 | [GN  ] | 'Å½ï¿½tâ€¹ï¿½gâ€¹ï¿½wâ€¹ï¿½tâ€¹ï¿½gâ€¹ï¿½wâ€¹ï¿½tâ€¹ï¿½gâ€¹ï¿½wâ€¹ï¿½tâ€¹ï¿½gâ€¹ï¿½wâ€¹ï¿½tâ€¹ï¿½gâ€¹ï¿½wâ€¹ï¿½tâ€¹ï¿½'...
  ------------------------------------------------------------
  GCG Optimized   | H= 11.16 | [GN  ] | ' à¦¦à¦¾à¦¸à§€à¦¹à¦¸à§à¦¤à¦šà§à¦®à§à¦¬à¦¾à¦¨ à¦šà¦¨à§à¦¦à§à¦°à¦®à§‚à¦°à§à¦¤à¦¿ à¦•à¦šà¦¿ à¦¶à¦¿à¦®à¦šà¦°à§‡ à¥¤'
======================================================================

\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š ENTROPY COMPARISON SUMMARY - bigscience/bloom-1b1
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test               â”‚    Entropy â”‚ Flags    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ repetition_1       â”‚     8.4766 â”‚ N        â”‚
â”‚ repetition_2       â”‚     8.0625 â”‚ N        â”‚
â”‚ bizarre_1          â”‚     7.6992 â”‚ GN       â”‚
â”‚ hallucination_1    â”‚     7.3867 â”‚ GRN      â”‚
â”‚ garbage_1          â”‚     0.2356 â”‚ GR       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ† GCG OPTIMIZED    â”‚    11.6797 â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nğŸš€ GCG improvement over best baseline: +3.2031
\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“ GCG OPTIMIZED PROMPT (Full)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
\nINPUT:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  JxCatal Tammy compated Commately demikianedà¯‡PrimeeditÃ©s à¤…à¤šà¤¾à¤¨à¤• ï¼Œ           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nRESPONSE (Entropy: 11.1562):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  à¦¦à¦¾à¦¸à§€à¦¹à¦¸à§à¦¤à¦šà§à¦®à§à¦¬à¦¾à¦¨ à¦šà¦¨à§à¦¦à§à¦°à¦®à§‚à¦°à§à¦¤à¦¿ à¦•à¦šà¦¿ à¦¶à¦¿à¦®à¦šà¦°à§‡ à¥¤                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nCorruption Flags: ['garbage', 'nonsense']
\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ… Model 24 complete!
   Raw Entropy: 11.6797 H
   Normalized:  93.9% of max
   Best Text: ' JxCatal Tammy compated Commately demikianedà¯‡Prime'...
   Global Best: 95.6% (gpt2-large)
   ğŸ§¹ Memory cleaned up 






======================================================================
ğŸ”„ [25/35] Iter 4, Model 4/7: EleutherAI/gpt-neo-1.3B
======================================================================
Loading model: EleutherAI/gpt-neo-1.3B
  ğŸ“¦ Using 4-bit quantization (memory efficient)
âœ… Model loaded: EleutherAI/gpt-neo-1.3B
  Vocabulary size: 50257
  GPU Memory: 2.20 GB allocated, 7.74 GB reserved
ğŸ”¬ RareTokenMiner initialized for vocab size: 50257
ğŸ“Œ Strategy: ğŸ° POPULATION SAMPLE (rank #1, 95.6% from gpt2-large)

ğŸ¯ Running GCG optimization on EleutherAI/gpt-neo-1.3B...
   Parameters: length=16, steps=50, top_k=256
   Multi-sample verification: 10 samples
GCGâ€‡Optimizing:â€‡100%
â€‡50/50â€‡[00:55<00:00,â€‡â€‡1.08s/it,â€‡H=9.79,â€‡H%=90.4%,â€‡best%=90.9%]

ğŸ”¬ Verifying final entropy with 10 samples...
   Single-pass entropy:  9.8359
   Verified mean:        9.8281 Â± 0.0000
   Verified range:       [9.8281, 9.8281]
   Verified normalized:  90.8%

âœ… GCG Optimization complete for EleutherAI/gpt-neo-1.3B!
  Best Entropy: 9.8281
  Best Text: ' genocide Gawker76561 Exploration Wrestle Tory cir'...

======================================================================
TESTING PROMPTS FOR EleutherAI/gpt-neo-1.3B
======================================================================
  Test            |  Entropy | Flags | Response Preview
  ------------------------------------------------------------
  garbage_1       | H=  0.82 | [GR  ] | ',"","","","","","","","","","","","","","","","","'...
  hallucination_1 | H=  5.65 | [N   ] | ' jak zewnÄ™trzny, przypadek: zostaÅ‚y mÃ³zgÃƒÂ³wkiem\n<j'...
  repetition_1    | H=  0.59 | [GR  ] | 'obobobobobobobobobobobobobobobobobobobobobobobobob'...
  repetition_2    | H=  1.44 | [GRN ] | 'ÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒ'...
  bizarre_1       | H=  4.34 | [GRN ] | 'âˆ‘âˆ‚â€™âˆ‘âˆ‚âˆšâˆ‘âˆ‚âˆšâˆ‘âˆ‚âˆšâˆ‘âˆ‚âˆšâˆ‘âˆ‚âˆšâˆ‘âˆ‚âˆšâˆ‘âˆ‚âˆšâˆ‘âˆ‚âˆšâˆ‘âˆ‚âˆšâˆ‘âˆ‚âˆšâˆ‘âˆ‚âˆšâˆ‘âˆ‚âˆšâˆ‘âˆ‚âˆšâˆ‘âˆ‚âˆšâˆ‘âˆ‚âˆšâˆ‘âˆ‚'
  ------------------------------------------------------------
  GCG Optimized   | H=  9.38 | [N   ] | '.com.\n\nI was actually not sure I was gonna be able'...
======================================================================

\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š ENTROPY COMPARISON SUMMARY - EleutherAI/gpt-neo-1.3B
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test               â”‚    Entropy â”‚ Flags    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ hallucination_1    â”‚     5.6523 â”‚ N        â”‚
â”‚ bizarre_1          â”‚     4.3398 â”‚ GRN      â”‚
â”‚ repetition_2       â”‚     1.4385 â”‚ GRN      â”‚
â”‚ garbage_1          â”‚     0.8159 â”‚ GR       â”‚
â”‚ repetition_1       â”‚     0.5894 â”‚ GR       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ† GCG OPTIMIZED    â”‚     9.8281 â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nğŸš€ GCG improvement over best baseline: +4.1758
\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“ GCG OPTIMIZED PROMPT (Full)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
\nINPUT:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  genocide Gawker76561 Exploration Wrestle Tory circumcised Earthquake Achi â”‚
â”‚ evement Clarkson atroc preached Bucs optimizations Gloriaravis             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nRESPONSE (Entropy: 9.3828):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ .com.

I was actually not sure I was gonna be able to go with the same thi â”‚
â”‚ ng for a year, but Iâ€™ve been doing a lot of thinking about my future. I st â”‚
â”‚ ill feel like I want to be in a role that is in a very big company, but I  â”‚
â”‚ have always been a very passionate artist. I donâ€™t want to stop doing that â”‚
â”‚ , but I want to be able to do it with the people I love.                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nCorruption Flags: ['nonsense']
\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ… Model 25 complete!
   Raw Entropy: 9.8281 H
   Normalized:  90.8% of max
   Best Text: ' genocide Gawker76561 Exploration Wrestle Tory cir'...
   Global Best: 95.6% (gpt2-large)
   ğŸ§¹ Memory cleaned up 






======================================================================
ğŸ”„ [26/35] Iter 4, Model 5/7: Qwen/Qwen2-1.5B
======================================================================
Loading model: Qwen/Qwen2-1.5B
  ğŸ“¦ Using 4-bit quantization (memory efficient)
âœ… Model loaded: Qwen/Qwen2-1.5B
  Vocabulary size: 151646
  GPU Memory: 2.40 GB allocated, 7.75 GB reserved
ğŸ”¬ RareTokenMiner initialized for vocab size: 151646
ğŸ“Œ Strategy: ğŸ° POPULATION SAMPLE (rank #4, 94.6% from Qwen2-1.5B)

ğŸ¯ Running GCG optimization on Qwen/Qwen2-1.5B...
   Parameters: length=16, steps=50, top_k=256
   Multi-sample verification: 10 samples
GCGâ€‡Optimizing:â€‡100%
â€‡50/50â€‡[01:05<00:00,â€‡â€‡1.28s/it,â€‡H=11.21,â€‡H%=94.0%,â€‡best%=95.2%]

ğŸ”¬ Verifying final entropy with 10 samples...
   Single-pass entropy:  11.3516
   Verified mean:        11.3516 Â± 0.0000
   Verified range:       [11.3516, 11.3516]
   Verified normalized:  95.2%

âœ… GCG Optimization complete for Qwen/Qwen2-1.5B!
  Best Entropy: 11.3516
  Best Text: 'é‡è¦ä¸¾æªomorphic-triggerCompanies Mandatory Petersless'...

======================================================================
TESTING PROMPTS FOR Qwen/Qwen2-1.5B
======================================================================
  Test            |  Entropy | Flags | Response Preview
  ------------------------------------------------------------
  garbage_1       | H=  6.75 | [GR  ] | '$","$","$","$","$","$","$","$","$","$","$","$","$"'...
  hallucination_1 | H=  5.76 | [-   ] | ' - 10.11.2018\n- 14:08\n101 0\n- 14:11\n101 0\n- 14:16\n'...
  repetition_1    | H=  9.66 | [-   ] | ', 364, 471, 549, 666, 777, 892, 999, 1076, 1169, 1'...
  repetition_2    | H=  9.61 | [N   ] | 'in the 12th, 2010\n12:18 PM | Comments (2)\n0\n0\nTags'...
  bizarre_1       | H=  7.12 | [R   ] | '13756462523364890057505000000000000000000000000000'...
  ------------------------------------------------------------
  GCG Optimized   | H= 11.35 | [N   ] | 'Â°F áTone 100% á¹‚Tone 100% á¿Tone 100% á®Tone 100% á»‚To'...
======================================================================

\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š ENTROPY COMPARISON SUMMARY - Qwen/Qwen2-1.5B
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test               â”‚    Entropy â”‚ Flags    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ repetition_1       â”‚     9.6641 â”‚ -        â”‚
â”‚ repetition_2       â”‚     9.6094 â”‚ N        â”‚
â”‚ bizarre_1          â”‚     7.1211 â”‚ R        â”‚
â”‚ garbage_1          â”‚     6.7539 â”‚ GR       â”‚
â”‚ hallucination_1    â”‚     5.7617 â”‚ -        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ† GCG OPTIMIZED    â”‚    11.3516 â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nğŸš€ GCG improvement over best baseline: +1.6875
\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“ GCG OPTIMIZED PROMPT (Full)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
\nINPUT:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ é‡è¦ä¸¾æªomorphic-triggerCompanies Mandatory PeterslessnessğŸ¶jÄ…cejç›¸é€š Holder comp â”‚
â”‚ arisonsì–é“ºè®¾.getLatitudeÃ­a                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nRESPONSE (Entropy: 11.3516):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Â°F áTone 100% á¹‚Tone 100% á¿Tone 100% á®Tone 100% á»‚Tone 100% á¼‚Tone 100% á¼–Tone â”‚
â”‚  100% á¿„Tone 100% á¿‘Tone 100% á¼—Tone 100                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nCorruption Flags: ['nonsense']
\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ… Model 26 complete!
   Raw Entropy: 11.3516 H
   Normalized:  95.2% of max
   Best Text: 'é‡è¦ä¸¾æªomorphic-triggerCompanies Mandatory Petersless'...
   Global Best: 95.6% (gpt2-large)
   ğŸ§¹ Memory cleaned up 






======================================================================
ğŸ”„ [27/35] Iter 4, Model 6/7: gpt2-large
======================================================================
Loading model: gpt2-large
  ğŸ“¦ Using 4-bit quantization (memory efficient)
âœ… Model loaded: gpt2-large
  Vocabulary size: 50257
  GPU Memory: 1.85 GB allocated, 7.79 GB reserved
ğŸ”¬ RareTokenMiner initialized for vocab size: 50257
ğŸ“Œ Strategy: ğŸ§¬ PERTURBED BEST (3 mutations to 95.6%)

ğŸ¯ Running GCG optimization on gpt2-large...
   Parameters: length=16, steps=50, top_k=256
   Multi-sample verification: 10 samples
GCGâ€‡Optimizing:â€‡100%
â€‡50/50â€‡[00:38<00:00,â€‡â€‡1.28it/s,â€‡H=10.34,â€‡H%=95.5%,â€‡best%=95.6%]

ğŸ”¬ Verifying final entropy with 10 samples...
   Single-pass entropy:  10.3516
   Verified mean:        10.3516 Â± 0.0000
   Verified range:       [10.3516, 10.3516]
   Verified normalized:  95.6%

âœ… GCG Optimization complete for gpt2-large!
  Best Entropy: 10.3516
  Best Text: ' genocide BosniaCompanies Mandatory todd succinctï¿½'...

======================================================================
TESTING PROMPTS FOR gpt2-large
======================================================================
  Test            |  Entropy | Flags | Response Preview
  ------------------------------------------------------------
  garbage_1       | H=  1.13 | [GRN ] | ',",",",",",",",",", "," "," "," "," "," "," "," ",'...
  hallucination_1 | H=  5.80 | [N   ] | 'Ä™-kobiety\n\n"The Kultura-kobiety is a term coined b'...
  repetition_1    | H=  0.77 | [GR  ] | 'obobobobobobobobobobobobobobobobobobobobobobobobob'...
  repetition_2    | H=  3.27 | [GRN ] | 'ÃƒÃƒÃŒÃ…Ã…Ã…Ã…Ã…Ã…Ã…Ã…Ã…Ã…Ã…Ã…Ã…Ã…Ã…Ã…Ã…Ã…Ã…Ã…Ã…Ã…Ã…Ã…Ã…Ã…Ã…Ã…Ã…Ã…Ã…Ã…Ã…Ã…Ã…Ã…Ã…Ã…Ã…Ã…Ã…Ã…Ã…Ã…Ã…Ã…Ã…'...
  bizarre_1       | H=  6.48 | [GRN ] | '\u200d-\u200dâˆšÄ washington\u200dâˆ‘âˆ‚âˆš\u200d-\u200dâˆš\u200d-\u200dâˆš\u200d-\u200dâˆš\u200d-\u200dâˆš\u200d-\u200dâˆš\u200d-\u200dâˆš\u200d-\u200dâˆš\u200d-\u200d'...
  ------------------------------------------------------------
  GCG Optimized   | H=  9.78 | [N   ] | "ï¿½s lack of diversity is a problem I'm pretty sure "...
======================================================================

\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š ENTROPY COMPARISON SUMMARY - gpt2-large
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test               â”‚    Entropy â”‚ Flags    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ bizarre_1          â”‚     6.4805 â”‚ GRN      â”‚
â”‚ hallucination_1    â”‚     5.8047 â”‚ N        â”‚
â”‚ repetition_2       â”‚     3.2676 â”‚ GRN      â”‚
â”‚ garbage_1          â”‚     1.1289 â”‚ GRN      â”‚
â”‚ repetition_1       â”‚     0.7715 â”‚ GR       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ† GCG OPTIMIZED    â”‚    10.3516 â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nğŸš€ GCG improvement over best baseline: +3.8711
\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“ GCG OPTIMIZED PROMPT (Full)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
\nINPUT:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  genocide BosniaCompanies Mandatory todd succinctï¿½ toast Madonnalimits str â”‚
â”‚ ide preached Preview unwillingness Crystalasia                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nRESPONSE (Entropy: 9.7812):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ï¿½s lack of diversity is a problem I'm pretty sure the author is an idiot.
 â”‚
â”‚ 
A friend of mine sent me this and I thought I'd share my thoughts.

The b â”‚
â”‚ ook is a bit of a slog, and I am not sure how much of it I liked. It's cer â”‚
â”‚ tainly not a novel you'd want to read for a fun evening, but it is a good  â”‚
â”‚ novel to get through a few days. If you're thinking of picking it up, you  â”‚
â”‚ might want                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nCorruption Flags: ['nonsense']
\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ… Model 27 complete!
   Raw Entropy: 10.3516 H
   Normalized:  95.6% of max
   Best Text: ' genocide BosniaCompanies Mandatory todd succinctï¿½'...
   Global Best: 95.6% (gpt2-large)
   ğŸ§¹ Memory cleaned up 






======================================================================
ğŸ”„ [28/35] Iter 4, Model 7/7: microsoft/phi-2
======================================================================
Loading model: microsoft/phi-2
  ğŸ“¦ Using 4-bit quantization (memory efficient)
Loadingâ€‡checkpointâ€‡shards:â€‡100%
â€‡2/2â€‡[00:30<00:00,â€‡13.13s/it]
âœ… Model loaded: microsoft/phi-2
  Vocabulary size: 50295
  GPU Memory: 3.01 GB allocated, 7.76 GB reserved
ğŸ”¬ RareTokenMiner initialized for vocab size: 50295
ğŸ“Œ Strategy: ğŸ”ï¸ GLOBAL BEST (95.6% from gpt2-large)

ğŸ¯ Running GCG optimization on microsoft/phi-2...
   Parameters: length=16, steps=50, top_k=256
   Multi-sample verification: 10 samples
GCGâ€‡Optimizing:â€‡100%
â€‡50/50â€‡[01:34<00:00,â€‡â€‡1.86s/it,â€‡H=9.81,â€‡H%=90.6%,â€‡best%=91.0%]

ğŸ”¬ Verifying final entropy with 10 samples...
   Single-pass entropy:  9.8516
   Verified mean:        9.8516 Â± 0.0000
   Verified range:       [9.8516, 9.8516]
   Verified normalized:  91.0%

âœ… GCG Optimization complete for microsoft/phi-2!
  Best Entropy: 9.8516
  Best Text: ' Inquisition))))Companies bombs DNS Vincent paving'...

======================================================================
TESTING PROMPTS FOR microsoft/phi-2
======================================================================
  Test            |  Entropy | Flags | Response Preview
  ------------------------------------------------------------
  garbage_1       | H=  5.25 | [-   ] | ' ",", ",",",",",",","," ",",",",","," ",","," "\n# '...
  hallucination_1 | H=  5.47 | [N   ] | 'SZTÃGÃRÃ‰ (IHAL) is the Hungarian acronym for the N'...
  repetition_1    | H=  5.06 | [-   ] | 'servation_dims)  # (batch_size, num_actions, num_o'...
  repetition_2    | H=  2.32 | [GN  ] | 'Â¢Ã‚Â¢Ã¢â‚¬Â¨Ãƒâ€œÃƒÂ¢Ã¢â‚¬Â¨Ãƒâ€œÃƒÂ¢Ã¢â‚¬Â¨Ãƒâ€œÃ‚Â¢Ã¢â‚¬Â¨Ãƒâ€œÃ‚Â¢Ã¢â‚¬Â¨Ãƒâ€â€Ãƒâ€ÃƒÂ¢Ã¢â‚¬Â¨Ãƒâ€â€ÃƒÂ¢Ã¢'...
  bizarre_1       | H=  6.30 | [N   ] | '(Î¸â‚€áµ–áµ–Ì‚)âˆ‚â‚âˆ‚â‚‚âˆ‚â‚ƒâˆ‚â‚„âˆ‚â‚…(âˆ‚â‚†âˆ‚â‚‡âˆ‚â‚ˆâˆ‚â‚‰âˆ‚â‚€)\n\nC = Î»â‚‚ - Î»â‚\n\nTheref'...
  ------------------------------------------------------------
  GCG Optimized   | H=  9.85 | [-   ] | ' dallas (the ) ofThe.plc and.eu/.au/.fr/.gov/.net/'...
======================================================================

\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š ENTROPY COMPARISON SUMMARY - microsoft/phi-2
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test               â”‚    Entropy â”‚ Flags    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ bizarre_1          â”‚     6.3047 â”‚ N        â”‚
â”‚ hallucination_1    â”‚     5.4688 â”‚ N        â”‚
â”‚ garbage_1          â”‚     5.2539 â”‚ -        â”‚
â”‚ repetition_1       â”‚     5.0586 â”‚ -        â”‚
â”‚ repetition_2       â”‚     2.3242 â”‚ GN       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ† GCG OPTIMIZED    â”‚     9.8516 â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nğŸš€ GCG improvement over best baseline: +3.5469
\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“ GCG OPTIMIZED PROMPT (Full)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
\nINPUT:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Inquisition))))Companies bombs DNS Vincent pavingLondon AfterApplic degra â”‚
â”‚ dation briskes circumstances Barney Mystic                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nRESPONSE (Entropy: 9.8516):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  dallas (the ) ofThe.plc and.eu/.au/.fr/.gov/.net/.org/.us/.co.uk/.cn/.in/ â”‚
â”‚ .tv/.au/.ca/

The.plc and.eu/.au/.fr/.gov/.net/.org/.us/.co.uk/.cn/.in/.tv â”‚
â”‚ /.au/.ca/                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nCorruption Flags: None detected
\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ… Model 28 complete!
   Raw Entropy: 9.8516 H
   Normalized:  91.0% of max
   Best Text: ' Inquisition))))Companies bombs DNS Vincent paving'...
   Global Best: 95.6% (gpt2-large)
   ğŸ§¹ Memory cleaned up 






~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~ ITERATION 4 COMPLETE ~~~
    Models processed this iteration: 7
    Current best entropy: 10.3516
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

######################################################################
### ITERATION 5/5
### Model Order: ['TinyLlama-1.1B-Chat-v1.0', 'gpt2-large', 'Meta-Llama-3-8B-Instruct', 'Qwen2-1.5B', 'bloom-1b1', 'phi-2', 'gpt-neo-1.3B']
######################################################################

======================================================================
ğŸ”„ [29/35] Iter 5, Model 1/7: TinyLlama/TinyLlama-1.1B-Chat-v1.0
======================================================================
Loading model: TinyLlama/TinyLlama-1.1B-Chat-v1.0
  ğŸ“¦ Using 4-bit quantization (memory efficient)
âœ… Model loaded: TinyLlama/TinyLlama-1.1B-Chat-v1.0
  Vocabulary size: 32000
  GPU Memory: 2.04 GB allocated, 7.76 GB reserved
ğŸ”¬ RareTokenMiner initialized for vocab size: 32000
ğŸ“Œ Strategy: ğŸ”ï¸ GLOBAL BEST (95.6% from gpt2-large)

ğŸ¯ Running GCG optimization on TinyLlama/TinyLlama-1.1B-Chat-v1.0...
   Parameters: length=16, steps=50, top_k=256
   Multi-sample verification: 10 samples
GCGâ€‡Optimizing:â€‡100%
â€‡50/50â€‡[00:47<00:00,â€‡â€‡1.09it/s,â€‡H=9.32,â€‡H%=89.8%,â€‡best%=89.8%]

ğŸ”¬ Verifying final entropy with 10 samples...
   Single-pass entropy:  9.3203
   Verified mean:        9.3203 Â± 0.0000
   Verified range:       [9.3203, 9.3203]
   Verified normalized:  89.8%

âœ… GCG Optimization complete for TinyLlama/TinyLlama-1.1B-Chat-v1.0!
  Best Entropy: 9.3203
  Best Text: 'Ğ»ĞµĞ· Mongo IU divine Hitch Kansas interpretationcla'...

======================================================================
TESTING PROMPTS FOR TinyLlama/TinyLlama-1.1B-Chat-v1.0
======================================================================
  Test            |  Entropy | Flags | Response Preview
  ------------------------------------------------------------
  garbage_1       | H=  4.19 | [-   ] | '@")\n    print(word_dict)\n    \n\n# + id="WvLN8tB4O5V'...
  hallucination_1 | H=  6.10 | [N   ] | 'ÃƒÅ¡Ã‚lENCÃƒlÃƒÅ¡Ã‚lENCÃƒlÃƒÅ¡Ã‚lENCÃƒlÃƒÅ¡Ã‚lENCÃƒlÃƒÅ¡Ã‚lENCÃƒlÃƒÅ¡Ã‚lE'...
  repetition_1    | H=  0.69 | [-   ] | 'obobobobobobobobobobobobobobobobobobobobobobobobob'...
  repetition_2    | H=  0.12 | [GRN ] | 'ÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒ'...
  bizarre_1       | H=  6.31 | [N   ] | '1=0\n2. \u200bEven more numbers than that \u200bğŸ“ˆ \u200bRoman nume'...
  ------------------------------------------------------------
  GCG Optimized   | H=  9.28 | [R   ] | 'us inter alios exspectatores hoc ipsum tertium dor'...
======================================================================

\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š ENTROPY COMPARISON SUMMARY - TinyLlama/TinyLlama-1.1B-Chat-v1.0
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test               â”‚    Entropy â”‚ Flags    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ bizarre_1          â”‚     6.3086 â”‚ N        â”‚
â”‚ hallucination_1    â”‚     6.0977 â”‚ N        â”‚
â”‚ garbage_1          â”‚     4.1875 â”‚ -        â”‚
â”‚ repetition_1       â”‚     0.6851 â”‚ -        â”‚
â”‚ repetition_2       â”‚     0.1248 â”‚ GRN      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ† GCG OPTIMIZED    â”‚     9.3203 â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nğŸš€ GCG improvement over best baseline: +3.0117
\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“ GCG OPTIMIZED PROMPT (Full)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
\nINPUT:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Ğ»ĞµĞ· Mongo IU divine Hitch Kansas interpretationclassNamekaÅ„ Torre rotation â”‚
â”‚  Peterswedge populate variant                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nRESPONSE (Entropy: 9.2812):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ us inter alios exspectatores hoc ipsum tertium dorsum etiam etiam quoque q â”‚
â”‚ uamquam quoque aquisquisquisquisquisquisquisquisquisquisquisquisquisquisqu â”‚
â”‚ isquisquisquisquisquisquisquisquisquisquisquisquisquisquisquisquisquisquis â”‚
â”‚ quisquisquisquisquisquisquisquisquisquisquisquisquisquisquisquisquisquisqu â”‚
â”‚ isquisquisquisquisquisquisquisquisquisquisquisquisquisquisquisquis         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nCorruption Flags: ['repetition']
\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ… Model 29 complete!
   Raw Entropy: 9.3203 H
   Normalized:  89.8% of max
   Best Text: 'Ğ»ĞµĞ· Mongo IU divine Hitch Kansas interpretationcla'...
   Global Best: 95.6% (gpt2-large)
   ğŸ§¹ Memory cleaned up 






======================================================================
ğŸ”„ [30/35] Iter 5, Model 2/7: gpt2-large
======================================================================
Loading model: gpt2-large
  ğŸ“¦ Using 4-bit quantization (memory efficient)
âœ… Model loaded: gpt2-large
  Vocabulary size: 50257
  GPU Memory: 1.85 GB allocated, 7.79 GB reserved
ğŸ”¬ RareTokenMiner initialized for vocab size: 50257
ğŸ“Œ Strategy: ğŸ° POPULATION SAMPLE (rank #1, 95.6% from gpt2-large)

ğŸ¯ Running GCG optimization on gpt2-large...
   Parameters: length=16, steps=50, top_k=256
   Multi-sample verification: 10 samples
GCGâ€‡Optimizing:â€‡100%
â€‡50/50â€‡[00:37<00:00,â€‡â€‡1.31it/s,â€‡H=10.23,â€‡H%=94.5%,â€‡best%=95.2%]

ğŸ”¬ Verifying final entropy with 10 samples...
   Single-pass entropy:  10.3047
   Verified mean:        10.3047 Â± 0.0000
   Verified range:       [10.3047, 10.3047]
   Verified normalized:  95.2%

âœ… GCG Optimization complete for gpt2-large!
  Best Entropy: 10.3047
  Best Text: 'ç¥ï¿½Companies Mandatory Friedrich succinctï¿½ Mushroom'...

======================================================================
TESTING PROMPTS FOR gpt2-large
======================================================================
  Test            |  Entropy | Flags | Response Preview
  ------------------------------------------------------------
  garbage_1       | H=  1.13 | [GRN ] | ',",",",", ",",", ", ", ", ", ", ", ", ", ", ", ", '...
  hallucination_1 | H=  5.80 | [N   ] | 'Ä…CZZÄ…CZEÄ…CZÄ…KUÄ…CZZÄ…KUÄ…CZZÄ…KUÄ…CZZÄ…KUÄ…CZZÄ…KUÄ…CZZÄ…KUÄ…'...
  repetition_1    | H=  0.77 | [GR  ] | 'obobobobobobobobobobobobobobobobobobobobobobobobob'...
  repetition_2    | H=  3.27 | [GRN ] | 'ÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒ'...
  bizarre_1       | H=  6.48 | [N   ] | 'p\n\nI am not a lawyer, but I have seen no way to de'...
  ------------------------------------------------------------
  GCG Optimized   | H=  9.38 | [N   ] | 'ï¿½mixedï¿½towardsï¿½unknownï¿½hopeï¿½dawnï¿½hopeï¿½dawnï¿½hopeï¿½da'...
======================================================================

\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š ENTROPY COMPARISON SUMMARY - gpt2-large
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test               â”‚    Entropy â”‚ Flags    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ bizarre_1          â”‚     6.4805 â”‚ N        â”‚
â”‚ hallucination_1    â”‚     5.8047 â”‚ N        â”‚
â”‚ repetition_2       â”‚     3.2676 â”‚ GRN      â”‚
â”‚ garbage_1          â”‚     1.1289 â”‚ GRN      â”‚
â”‚ repetition_1       â”‚     0.7715 â”‚ GR       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ† GCG OPTIMIZED    â”‚    10.3047 â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nğŸš€ GCG improvement over best baseline: +3.8242
\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“ GCG OPTIMIZED PROMPT (Full)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
\nINPUT:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ç¥ï¿½Companies Mandatory Friedrich succinctï¿½ Mushroom GiulianilimitsOrderable â”‚
â”‚  preachedï¿½ unwillingness Crystalasia                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nRESPONSE (Entropy: 9.3750):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ï¿½mixedï¿½towardsï¿½unknownï¿½hopeï¿½dawnï¿½hopeï¿½dawnï¿½hopeï¿½dawnï¿½hopeï¿½dawnï¿½hopeï¿½dawnï¿½h â”‚
â”‚ opeï¿½dawnï¿½hopeï¿½dawnï¿½hopeï¿½dawnï¿½hopeï¿½dawnï¿½hopeï¿½dawnï¿½hopeï¿½dawnï¿½hopeï¿½dawnï¿½hopeï¿½ â”‚
â”‚ dawnï¿½hopeï¿½dawnï¿½hopeï¿½dawnï¿½                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nCorruption Flags: ['nonsense']
\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ… Model 30 complete!
   Raw Entropy: 10.3047 H
   Normalized:  95.2% of max
   Best Text: 'ç¥ï¿½Companies Mandatory Friedrich succinctï¿½ Mushroom'...
   Global Best: 95.6% (gpt2-large)
   ğŸ§¹ Memory cleaned up 






======================================================================
ğŸ”„ [31/35] Iter 5, Model 3/7: meta-llama/Meta-Llama-3-8B-Instruct
======================================================================
Loading model: meta-llama/Meta-Llama-3-8B-Instruct
  ğŸ“¦ Using 4-bit quantization (memory efficient)
Loadingâ€‡checkpointâ€‡shards:â€‡100%
â€‡4/4â€‡[01:29<00:00,â€‡19.12s/it]
âœ… Model loaded: meta-llama/Meta-Llama-3-8B-Instruct
  Vocabulary size: 128256
  GPU Memory: 6.64 GB allocated, 7.82 GB reserved
ğŸ”¬ RareTokenMiner initialized for vocab size: 128256
ğŸ“Œ Strategy: ğŸ§¬ PERTURBED BEST (4 mutations to 95.6%)

ğŸ¯ Running GCG optimization on meta-llama/Meta-Llama-3-8B-Instruct...
   Parameters: length=16, steps=50, top_k=256
   Multi-sample verification: 10 samples
GCGâ€‡Optimizing:â€‡100%
â€‡50/50â€‡[03:51<00:00,â€‡â€‡4.67s/it,â€‡H=10.74,â€‡H%=91.3%,â€‡best%=91.7%]

ğŸ”¬ Verifying final entropy with 10 samples...
   Single-pass entropy:  10.7891
   Verified mean:        10.7891 Â± 0.0000
   Verified range:       [10.7891, 10.7891]
   Verified normalized:  91.7%

âœ… GCG Optimization complete for meta-llama/Meta-Llama-3-8B-Instruct!
  Best Entropy: 10.7891
  Best Text: 'emailer HitchcockCompanies Hampshire Mohamed doÄŸru'...

======================================================================
TESTING PROMPTS FOR meta-llama/Meta-Llama-3-8B-Instruct
======================================================================
  Test            |  Entropy | Flags | Response Preview
  ------------------------------------------------------------
  garbage_1       | H=  6.05 | [GR  ] | ' @,"@",",@",",",",@","@","@","@","@","@","@","@","'...
  hallucination_1 | H=  7.35 | [N   ] | 'A, BULGARIA - MARCH 21: Ãƒ\x81ngelÃƒ\xadna Gasparova, 8, h'...
  repetition_1    | H=  2.36 | [-   ] | 'ob\nThe obobobobobobobobobobob is a fascinating and'...
  repetition_2    | H=  2.54 | [N   ] | 'ÃƒÃƒÃƒ\nI found an error in the code. It should be:\nÃƒÃƒ'...
  bizarre_1       | H=  6.89 | [N   ] | '\n\u200bWashington, D.C. (ËˆwÉ”ËÊƒÉªÅ‹tÉ™n) is the capital cit'...
  ------------------------------------------------------------
  GCG Optimized   | H= 10.36 | [N   ] | ' Nellie\nSolutions: 1\nTags: 1\n```sql\n-- Create a ta'...
======================================================================

\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š ENTROPY COMPARISON SUMMARY - meta-llama/Meta-Llama-3-8B-Instruct
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test               â”‚    Entropy â”‚ Flags    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ hallucination_1    â”‚     7.3516 â”‚ N        â”‚
â”‚ bizarre_1          â”‚     6.8906 â”‚ N        â”‚
â”‚ garbage_1          â”‚     6.0469 â”‚ GR       â”‚
â”‚ repetition_2       â”‚     2.5430 â”‚ N        â”‚
â”‚ repetition_1       â”‚     2.3594 â”‚ -        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ† GCG OPTIMIZED    â”‚    10.7891 â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nğŸš€ GCG improvement over best baseline: +3.4375
\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“ GCG OPTIMIZED PROMPT (Full)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
\nINPUT:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ emailer HitchcockCompanies Hampshire Mohamed doÄŸru nÃ³i insulin ì—…ë°ì´íŠ¸ compon â”‚
â”‚ entDidUpdate sporting.LinkedList generBeam wholly                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nRESPONSE (Entropy: 10.3594):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Nellie
Solutions: 1
Tags: 1
```sql
-- Create a table for the emailer
CREA â”‚
â”‚ TE TABLE emailer (
  id SERIAL PRIMARY KEY,
  email VARCHAR(255) NOT NULL, â”‚
â”‚ 
  password VARCHAR(255) NOT NULL
);

-- Create a table for the companies
 â”‚
â”‚ CREATE TABLE companies (
  id SERIAL PRIMARY KEY,
  name VARCHAR(255) NOT  â”‚
â”‚ NULL,
  description TEXT,
  email VARCHAR(255) NOT NULL
);

-- Create      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nCorruption Flags: ['nonsense']
\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ… Model 31 complete!
   Raw Entropy: 10.7891 H
   Normalized:  91.7% of max
   Best Text: 'emailer HitchcockCompanies Hampshire Mohamed doÄŸru'...
   Global Best: 95.6% (gpt2-large)
   ğŸ§¹ Memory cleaned up 






======================================================================
ğŸ”„ [32/35] Iter 5, Model 4/7: Qwen/Qwen2-1.5B
======================================================================
Loading model: Qwen/Qwen2-1.5B
  ğŸ“¦ Using 4-bit quantization (memory efficient)
âœ… Model loaded: Qwen/Qwen2-1.5B
  Vocabulary size: 151646
  GPU Memory: 2.40 GB allocated, 7.82 GB reserved
ğŸ”¬ RareTokenMiner initialized for vocab size: 151646
ğŸ“Œ Strategy: ğŸ”ï¸ GLOBAL BEST (95.6% from gpt2-large)

ğŸ¯ Running GCG optimization on Qwen/Qwen2-1.5B...
   Parameters: length=16, steps=50, top_k=256
   Multi-sample verification: 10 samples
GCGâ€‡Optimizing:â€‡100%
â€‡50/50â€‡[01:05<00:00,â€‡â€‡1.28s/it,â€‡H=11.00,â€‡H%=92.2%,â€‡best%=92.4%]

ğŸ”¬ Verifying final entropy with 10 samples...
   Single-pass entropy:  11.0234
   Verified mean:        11.0234 Â± 0.0000
   Verified range:       [11.0234, 11.0234]
   Verified normalized:  92.4%

âœ… GCG Optimization complete for Qwen/Qwen2-1.5B!
  Best Entropy: 11.0234
  Best Text: 'å¤®è§† Hitchcock.setBackgroundResource payloads Peters'...

======================================================================
TESTING PROMPTS FOR Qwen/Qwen2-1.5B
======================================================================
  Test            |  Entropy | Flags | Response Preview
  ------------------------------------------------------------
  garbage_1       | H=  6.75 | [GR  ] | '@","@","@","@","@","@","@","@","@","@","@","@","@"'...
  hallucination_1 | H=  5.76 | [N   ] | 'ZSKI UNIVERSITY, Krakow, Poland\n\nâ€¢ PUBLICATIONS\nâ€¢ '...
  repetition_1    | H=  9.66 | [-   ] | ", 09:39, 27 Oct 2006\nIf I can't use the full versi"...
  repetition_2    | H=  9.61 | [N   ] | 'in my little baby girl, you are the only one I hav'...
  bizarre_1       | H=  7.12 | [N   ] | '-144kT/Ä§2e\u200b,\u200b, 22011090028269697688581607960783826'...
  ------------------------------------------------------------
  GCG Optimized   | H= 11.02 | [GN  ] | 'à¸ªà¸•à¸±à¸™à¸•à¹Œà¸à¸¹à¸”à¸¥à¹‰à¸­à¸ªà¸³à¸«à¸£à¸±à¸š à¹€à¸£à¸·à¹ˆà¸­à¸‡à¸•à¸·à¹ˆà¸™à¸«à¸¥à¸¶à¸‡à¹€à¸à¸´à¸”à¸‚à¸¶à¹‰à¸™ à¸‚à¸šà¸ à¸«à¸™à¹ˆà¸­'...
======================================================================

\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š ENTROPY COMPARISON SUMMARY - Qwen/Qwen2-1.5B
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test               â”‚    Entropy â”‚ Flags    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ repetition_1       â”‚     9.6641 â”‚ -        â”‚
â”‚ repetition_2       â”‚     9.6094 â”‚ N        â”‚
â”‚ bizarre_1          â”‚     7.1211 â”‚ N        â”‚
â”‚ garbage_1          â”‚     6.7539 â”‚ GR       â”‚
â”‚ hallucination_1    â”‚     5.7617 â”‚ N        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ† GCG OPTIMIZED    â”‚    11.0234 â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nğŸš€ GCG improvement over best baseline: +1.3594
\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“ GCG OPTIMIZED PROMPT (Full)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
\nINPUT:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ å¤®è§† Hitchcock.setBackgroundResource payloads Petersenæ¢ä»¶å‡€ Äá»à¹ƒà¸ˆ.fixture tract â”‚
â”‚ ionational ØªØ´Ø±ÙŠÙ†ç…                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nRESPONSE (Entropy: 11.0234):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ à¸ªà¸•à¸±à¸™à¸•à¹Œà¸à¸¹à¸”à¸¥à¹‰à¸­à¸ªà¸³à¸«à¸£à¸±à¸š à¹€à¸£à¸·à¹ˆà¸­à¸‡à¸•à¸·à¹ˆà¸™à¸«à¸¥à¸¶à¸‡à¹€à¸à¸´à¸”à¸‚à¸¶à¹‰à¸™ à¸‚à¸šà¸ à¸«à¸™à¹ˆà¸­à¸¢ à¹€à¸‚à¹‰à¸²à¸”à¹‰à¸§à¸¢à¸à¸±à¸™ à¹€à¸£à¸²à¸à¹‡à¸ˆà¸°à¸¡à¸µà¸„ â”‚
â”‚ à¸§à¸²à¸¡à¸„à¸´à¸”à¹€à¸«à¹‡à¸™à¸–à¸¶à¸‡à¸«à¸™à¸¶à¹ˆà¸‡à¹€à¸”à¸µà¸¢à¸§à¹€à¸›à¹‡à¸™ à¸—à¸µà¸£à¹‰à¸­à¸¢à¸¢à¸¹à¸”à¸´à¸ªà¸—à¹Œà¸™à¹Œ à¸ªà¹ˆà¸§à¸™à¸«à¸™à¸¶à¹ˆà¸‡à¸à¹‡à¸ˆà¸°à¸•à¹‰à¸­à¸‡à¸­à¸¢à¸¹à¹ˆà¸à¸±à¸šà¸„à¸§à¸²à¸¡à¸„à¸´ â”‚
â”‚ à¸”à¹€à¸«à¹‡à¸™à¸‚à¸­à¸‡                                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nCorruption Flags: ['garbage', 'nonsense']
\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ… Model 32 complete!
   Raw Entropy: 11.0234 H
   Normalized:  92.4% of max
   Best Text: 'å¤®è§† Hitchcock.setBackgroundResource payloads Peters'...
   Global Best: 95.6% (gpt2-large)
   ğŸ§¹ Memory cleaned up 






======================================================================
ğŸ”„ [33/35] Iter 5, Model 5/7: bigscience/bloom-1b1
======================================================================
Loading model: bigscience/bloom-1b1
  ğŸ“¦ Using 4-bit quantization (memory efficient)
âœ… Model loaded: bigscience/bloom-1b1
  Vocabulary size: 250680
  GPU Memory: 2.37 GB allocated, 7.75 GB reserved
ğŸ”¬ RareTokenMiner initialized for vocab size: 250680
ğŸ“Œ Strategy: ğŸ² RANDOM RESTART - exploring new territory!

ğŸ¯ Running GCG optimization on bigscience/bloom-1b1...
   Parameters: length=16, steps=50, top_k=256
   Multi-sample verification: 10 samples
GCGâ€‡Optimizing:â€‡100%
â€‡50/50â€‡[00:44<00:00,â€‡â€‡1.09it/s,â€‡H=11.91,â€‡H%=95.8%,â€‡best%=96.0%]

ğŸ”¬ Verifying final entropy with 10 samples...
   Single-pass entropy:  11.9297
   Verified mean:        11.9297 Â± 0.0000
   Verified range:       [11.9297, 11.9297]
   Verified normalized:  96.0%

âœ… GCG Optimization complete for bigscience/bloom-1b1!
  Best Entropy: 11.9297
  Best Text: 'ç†äº‹å›½ari; Mateus Saavedra_{\\ sabiendo Beatles à²–à²°à³à²šà³è¢'...

======================================================================
TESTING PROMPTS FOR bigscience/bloom-1b1
======================================================================
  Test            |  Entropy | Flags | Response Preview
  ------------------------------------------------------------
  garbage_1       | H=  0.24 | [GR  ] | ',",",",",",",",",",",",",",",",",",",",",",",",","'...
  hallucination_1 | H=  7.39 | [RN  ] | 'ÃÃ¨Ã¯Ã‘Â¤ÃÂ¤ÃÃ\x82Ã\x83\x89\x83\x8e\n/\n:.1 1.4 1.4 1.2 1.2 1.2 1.2 1.2 '...
  repetition_1    | H=  8.48 | [N   ] | 'obb et al. 2004) , and the corresponding gene (enc'...
  repetition_2    | H=  8.06 | [N   ] | 'Y ÄÃNH GIÃ Ráºº.'
  bizarre_1       | H=  7.70 | [N   ] | 'washington.edu\nIn the following sections, we discu'...
  ------------------------------------------------------------
  GCG Optimized   | H= 11.93 | [N   ] | ' of course you shouldnt go there to get pornograph'...
======================================================================
   ğŸ† NEW GLOBAL BEST!
      Raw: 11.9297 H (+1.5781)
      Normalized: 95.96% (+0.33%)

\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š ENTROPY COMPARISON SUMMARY - bigscience/bloom-1b1
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test               â”‚    Entropy â”‚ Flags    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ repetition_1       â”‚     8.4766 â”‚ N        â”‚
â”‚ repetition_2       â”‚     8.0625 â”‚ N        â”‚
â”‚ bizarre_1          â”‚     7.6992 â”‚ N        â”‚
â”‚ hallucination_1    â”‚     7.3867 â”‚ RN       â”‚
â”‚ garbage_1          â”‚     0.2356 â”‚ GR       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ† GCG OPTIMIZED    â”‚    11.9297 â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nğŸš€ GCG improvement over best baseline: +3.4531
\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“ GCG OPTIMIZED PROMPT (Full)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
\nINPUT:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ç†äº‹å›½ari; Mateus Saavedra_{\ sabiendo Beatles à²–à²°à³à²šà³è¢ä¸–å‡¯Ã³pez cÃ¢m Yahya à¤¬à¥ˆà¤ à¤•à¤° a â”‚
â”‚ ndroid:layout_width="fill_parent"åˆ‡â—‹ à¤¯à¥à¤µà¤•à¥‹à¤‚                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nRESPONSE (Entropy: 11.9297):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  of course you shouldnt go there to get pornography and if you do you have â”‚
â”‚  to be pretty fucking smart so i didnt have to be stupid to go to the movi â”‚
â”‚ es with my wife and i had no idea i was going to have to watch porn with m â”‚
â”‚ y wife so i went to the movies with my wife and i watched a fucking film w â”‚
â”‚ ith my wife and i watched a fucking movie with my wife and i watched a fuc â”‚
â”‚ king movie with my wife and i watched a fucking movie with my wife and     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nCorruption Flags: ['nonsense']
\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ… Model 33 complete!
   Raw Entropy: 11.9297 H
   Normalized:  96.0% of max
   Best Text: 'ç†äº‹å›½ari; Mateus Saavedra_{\\ sabiendo Beatles à²–à²°à³à²šà³è¢'...
   Global Best: 96.0% (bigscience/bloom-1b1)
   ğŸ§¹ Memory cleaned up 






======================================================================
ğŸ”„ [34/35] Iter 5, Model 6/7: microsoft/phi-2
======================================================================
Loading model: microsoft/phi-2
  ğŸ“¦ Using 4-bit quantization (memory efficient)
Loadingâ€‡checkpointâ€‡shards:â€‡100%
â€‡2/2â€‡[00:31<00:00,â€‡13.58s/it]
âœ… Model loaded: microsoft/phi-2
  Vocabulary size: 50295
  GPU Memory: 3.01 GB allocated, 7.76 GB reserved
ğŸ”¬ RareTokenMiner initialized for vocab size: 50295
ğŸ“Œ Strategy: ğŸ° POPULATION SAMPLE (rank #1, 96.0% from bloom-1b1)

ğŸ¯ Running GCG optimization on microsoft/phi-2...
   Parameters: length=16, steps=50, top_k=256
   Multi-sample verification: 10 samples
GCGâ€‡Optimizing:â€‡100%
â€‡50/50â€‡[01:33<00:00,â€‡â€‡1.88s/it,â€‡H=9.77,â€‡H%=90.2%,â€‡best%=90.4%]

ğŸ”¬ Verifying final entropy with 10 samples...
   Single-pass entropy:  9.7812
   Verified mean:        9.7656 Â± 0.0000
   Verified range:       [9.7656, 9.7656]
   Verified normalized:  90.2%

âœ… GCG Optimization complete for microsoft/phi-2!
  Best Entropy: 9.7656
  Best Text: 'ï¿½ Fairidation../ exampleï¿½e quite Karus Mortonaved '...

======================================================================
TESTING PROMPTS FOR microsoft/phi-2
======================================================================
  Test            |  Entropy | Flags | Response Preview
  ------------------------------------------------------------
  garbage_1       | H=  5.25 | [-   ] | ' said Dr. Lauer said. "This is why we can\'t afford'...
  hallucination_1 | H=  5.47 | [N   ] | 'TKI (ÃšJSIK)\nP.O. Box 1138, 07011 Budapest\nemail: s'...
  repetition_1    | H=  5.06 | [-   ] | 'es are the ones in the top left and bottom right o'...
  repetition_2    | H=  2.32 | [N   ] | 'ÃƒÂ¢Ã¢â‚¬â€œÃ¢â‚¬â€œand thatâ€™s a big problem for the United St'...
  bizarre_1       | H=  6.30 | [GN  ] | 'washington, D.C.\n-\u200dâˆ‚âˆšâˆšâˆšâˆšâˆšâˆšâˆšâˆšâˆšâˆšâˆšâˆšâˆšâˆšâˆšâˆšâˆšâˆšâˆšâˆšâˆšâˆšâˆšâˆšâˆšâˆšâˆšâˆšâˆšâˆš'...
  ------------------------------------------------------------
  GCG Optimized   | H=  9.06 | [-   ] | ' concept of the "exemplary" person, the notion of '...
======================================================================

\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š ENTROPY COMPARISON SUMMARY - microsoft/phi-2
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test               â”‚    Entropy â”‚ Flags    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ bizarre_1          â”‚     6.3047 â”‚ GN       â”‚
â”‚ hallucination_1    â”‚     5.4688 â”‚ N        â”‚
â”‚ garbage_1          â”‚     5.2539 â”‚ -        â”‚
â”‚ repetition_1       â”‚     5.0586 â”‚ -        â”‚
â”‚ repetition_2       â”‚     2.3242 â”‚ N        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ† GCG OPTIMIZED    â”‚     9.7656 â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nğŸš€ GCG improvement over best baseline: +3.4609
\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“ GCG OPTIMIZED PROMPT (Full)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
\nINPUT:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ï¿½ Fairidation../ exampleï¿½e quite Karus Mortonaved discussions From Al the  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nRESPONSE (Entropy: 9.0625):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  concept of the "exemplary" person, the notion of the "ideal" has long bee â”‚
â”‚ n a central part of the Western philosophical tradition. From Plato to Ari â”‚
â”‚ stotle, the ideal person has been a subject of fascination and reflection. â”‚
â”‚  In the 17th century, the Enlightenment thinkers began to focus on the con â”‚
â”‚ cept of the "ideal citizen" and the ideal society. The idea of the "ideal" â”‚
â”‚  has continued to evolve and be a source of inspiration for many people.

 â”‚
â”‚ 6.                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nCorruption Flags: None detected
\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ… Model 34 complete!
   Raw Entropy: 9.7656 H
   Normalized:  90.2% of max
   Best Text: 'ï¿½ Fairidation../ exampleï¿½e quite Karus Mortonaved '...
   Global Best: 96.0% (bigscience/bloom-1b1)
   ğŸ§¹ Memory cleaned up 






======================================================================
ğŸ”„ [35/35] Iter 5, Model 7/7: EleutherAI/gpt-neo-1.3B
======================================================================
Loading model: EleutherAI/gpt-neo-1.3B
  ğŸ“¦ Using 4-bit quantization (memory efficient)
âœ… Model loaded: EleutherAI/gpt-neo-1.3B
  Vocabulary size: 50257
  GPU Memory: 2.20 GB allocated, 7.76 GB reserved
ğŸ”¬ RareTokenMiner initialized for vocab size: 50257
ğŸ“Œ Strategy: ğŸ”ï¸ GLOBAL BEST (96.0% from bloom-1b1)

ğŸ¯ Running GCG optimization on EleutherAI/gpt-neo-1.3B...
   Parameters: length=16, steps=50, top_k=256
   Multi-sample verification: 10 samples
GCGâ€‡Optimizing:â€‡100%
â€‡50/50â€‡[00:55<00:00,â€‡â€‡1.10s/it,â€‡H=9.46,â€‡H%=87.4%,â€‡best%=88.0%]

ğŸ”¬ Verifying final entropy with 10 samples...
   Single-pass entropy:  9.5312
   Verified mean:        9.5234 Â± 0.0000
   Verified range:       [9.5234, 9.5234]
   Verified normalized:  88.0%

âœ… GCG Optimization complete for EleutherAI/gpt-neo-1.3B!
  Best Entropy: 9.5234
  Best Text: ' secretiveï¿½äº‹å›½ dividends Heroicruciating lawfully W'...

======================================================================
TESTING PROMPTS FOR EleutherAI/gpt-neo-1.3B
======================================================================
  Test            |  Entropy | Flags | Response Preview
  ------------------------------------------------------------
  garbage_1       | H=  0.82 | [GR  ] | ',",",",",",",",",",",",",",",",",",",",",",","",""'...
  hallucination_1 | H=  5.65 | [N   ] | ', ale przestrzeganie prawa jest bardzo Å‚atwe i zaw'...
  repetition_1    | H=  0.59 | [GR  ] | 'obobobobobobobobobobobobobobobobobobobobobobobobob'...
  repetition_2    | H=  1.44 | [GRN ] | 'ÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒÃƒ'...
  bizarre_1       | H=  4.34 | [N   ] | 'âˆ†âˆšâˆ†\n\n[^1]: We thank the anonymous referees for the'...
  ------------------------------------------------------------
  GCG Optimized   | H=  9.44 | [RN  ] | ' and other, also all the many, also all the many, '...
======================================================================

\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š ENTROPY COMPARISON SUMMARY - EleutherAI/gpt-neo-1.3B
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test               â”‚    Entropy â”‚ Flags    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ hallucination_1    â”‚     5.6523 â”‚ N        â”‚
â”‚ bizarre_1          â”‚     4.3398 â”‚ N        â”‚
â”‚ repetition_2       â”‚     1.4385 â”‚ GRN      â”‚
â”‚ garbage_1          â”‚     0.8159 â”‚ GR       â”‚
â”‚ repetition_1       â”‚     0.5894 â”‚ GR       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ† GCG OPTIMIZED    â”‚     9.5234 â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nğŸš€ GCG improvement over best baseline: +3.8711
\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“ GCG OPTIMIZED PROMPT (Full)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
\nINPUT:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  secretiveï¿½äº‹å›½ dividends Heroicruciating lawfully Warlockilings ObamaCare r â”‚
â”‚ oofs\ Magical                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nRESPONSE (Entropy: 9.4375):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  and other, also all the many, also all the many, also all the many, also  â”‚
â”‚ all the many, also all the many, also all the many, also all the many, als â”‚
â”‚ o all the many, also all the many, also all the many, also all the many, a â”‚
â”‚ lso all the many, also all the many, also all the many, also all the many, â”‚
â”‚  also all the many, also all the many, also all the many, also all the man â”‚
â”‚ y, also all                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\nCorruption Flags: ['repetition', 'nonsense']
\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ… Model 35 complete!
   Raw Entropy: 9.5234 H
   Normalized:  88.0% of max
   Best Text: ' secretiveï¿½äº‹å›½ dividends Heroicruciating lawfully W'...
   Global Best: 96.0% (bigscience/bloom-1b1)
   ğŸ§¹ Memory cleaned up 






~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~ ITERATION 5 COMPLETE ~~~
    Models processed this iteration: 7
    Current best entropy: 11.9297
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

======================================================================
âœ… ALL ITERATIONS COMPLETE!
   Total iterations: 5
   Total model runs: 35
   Successful runs: 35
   End Time: 2026-01-19 13:29:23
======================================================================

ğŸ“Š EXPLORATION STRATEGY EFFECTIVENESS:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Strategy                 Uses   Improvements   Total Gain   Efficiency
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
global_best                11              1       0.0087         9.1%
population_sample           8              0       0.0000         0.0%
perturbed_best              8              1       0.0168        12.5%
random_restart              8              4       0.9341        50.0%
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ğŸ§¬ FINAL POPULATION (Top 5 prompts):
   #1: 11.9297 from bloom-1b1 - 'ç†äº‹å›½ari; Mateus Saavedra_{\\ sabiendo Beat'...
   #2: 10.3516 from gpt2-large - ' genocide HitchcockCompanies Mandatory P'...
   #3: 10.3516 from gpt2-large - ' Ancients Tammy bloated Commandsprintedï¿½'...
   #4: 10.3516 from gpt2-large - ' genocide BosniaCompanies Mandatory todd'...
   #5: 11.3672 from Qwen2-1.5B - ' smirkè¿‚-scalableæ”¹ä¸ºâ¬Ÿğ•™-initializedå¸¸åŠ¡ input'...

ğŸ† GLOBAL BEST RESULT:
   Model: bigscience/bloom-1b1
   Entropy: 11.9297
   Text: 'ç†äº‹å›½ari; Mateus Saavedra_{\\ sabiendo Beatles à²–à²°à³à²šà³è¢ä¸–å‡¯Ã³pez cÃ¢m Yahya à¤¬à¥ˆà¤ à¤•à¤° android'...
======================================================================